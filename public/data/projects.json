[
  {
    "slug": "project-4-4-wazuh-nessus-integration",
    "title": "Project 4.4: Integrating Wazuh SIEM/XDR and Nessus in a Cybersecurity Home Lab",
    "description": "A comprehensive walkthrough of deploying Wazuh SIEM/XDR for log correlation and Nessus for vulnerability scanning in a segmented cybersecurity homelab environment.",
    "date": "2025-08-03",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "",
    "solution": "",
    "results": [],
    "category": "blue",
    "tags": [
      "Wazuh",
      "SIEM",
      "XDR",
      "Nessus",
      "Vulnerability Scanning",
      "Security Monitoring",
      "OPNsense",
      "Docker",
      "Parrot OS",
      "Ubuntu",
      "Proxmox",
      "VLAN",
      "Homelab",
      "Blue Team"
    ],
    "content": "\n## Project 4.4: Integrating Wazuh SIEM/XDR and Nessus in a Cybersecurity Home Lab\n\n### Building the SIEM Foundation: Wazuh Server Deployment\n\nContinuing from the previous episodes of my cybersecurity home lab journey, I entered the next to introduce Wazuh as the SIEM and XDR solution for telemetry collection, log correlation, and detection engineering. I provisioned a new Ubuntu server virtual machine on Proxmox with 4 vCPUs, 8GB of RAM, and 160GB of disk space, ensuring it resided within VLAN 5 (my security tools network) using the IP 10.10.5.51/24. The Wazuh installation process was straightforward. After setting a static IP and configuring DNS and gateway entries, I initiated a basic update and upgrade cycle, then ran the official Wazuh installation script from their GitHub repository.\n\nOnce the installation was completed, I accessed the Wazuh dashboard via HTTPS at https://10.10.5.51, authenticated using the auto-generated credentials, and confirmed a successful deployment. With the Wazuh manager operational, the next step was deploying agents across key systems in the lab.\n\n<InlineGallery images={wazuh-server-deployment} title=\"Wazuh Server Deployment\" />\n\n### Deploying Agents: Parrot OS and Docker Server Integration\n\nThe first endpoint I configured was my Parrot OS. I elevated to root and ran the prescribed commands to add the Wazuh repository, perform an update, and install the agent. I edited the agent configuration to point it at the Wazuh manager IP and verified connectivity. Upon launching the agent, it registered on the Wazuh dashboard and began transmitting logs shortly after.\n\nI replicated the same process on my Ubuntu Docker server (10.10.30.100), again ensuring root privileges, repository addition, and agent configuration. I initiated the agent and confirmed its visibility on the Wazuh interface. To extend observability into containerised environments, I proceeded to install the Wazuh Docker Listener and configured the Docker API for telemetry ingestion. I appended the required JSON configuration into the agent's config file, restarted the service, and enabled the module on the Wazuh dashboard under Settings > Modules > Docker Listener. Container-level logs began appearing as I restarted a few test containers to validate.\n\n<InlineGallery images={agent-installation} title=\"Agent Installation Process\" />\n\n### OPNsense Firewall Agent Issues: Encountering the PID File Roadblock\n\nWith both endpoint systems operational in Wazuh, I turned my attention to integrating my OPNsense firewall (192.168.1.1) running on dedicated hardware. This step diverged significantly from the Linux-based agents, as it required enabling FreeBSD repositories and handling configuration in a constrained BSD environment. I SSHed into OPNsense, enabled SSH under System > Advanced, and modified the FreeBSD.conf file to set enabled=YES. Unlike the tutorial, I found only the freebsd.conf file available, not pfsense.conf, due to architectural differences between OPNsense and pfSense.\n\nFollowing the installation instructions, I attempted to run the agent-auth binary to register the agent with the manager. However, I encountered a persistent error: agent-auth: CRITICAL (1212): Unable to create PID file. This indicated a permission or filesystem-level issue preventing the Wazuh agent from properly initialising. Further troubleshooting revealed that the ossec user and group did not exist by default. Attempts to assign ownership using chown -R ossec:ossec /var/ossec returned \"illegal group name\" errors.\n\nI manually verified write permissions by creating and removing test files under /var/ossec, which confirmed basic functionality. Despite that, the Wazuh agent daemon (wazuh-agentd) consistently failed to start. Configuration and log file reviews pointed to missing or incompatible startup routines specific to FreeBSD. I eventually confirmed that even after enabling FreeBSD package support and properly configuring ossec.conf to include the manager IP, the agent appeared on the Wazuh dashboard but failed to show \"Active\" status.\n\nAt this point, I decided to temporarily pause work on the OPNsense agent integration. The issue remained unresolved, likely due to deeper compatibility mismatches or required kernel parameters not present on the OPNsense BSD environment. I plan to revisit this with a custom-built FreeBSD agent installation script or by manually creating missing users and startup routines. But if anyone has encountered this issue, please reach out to me with suggestions, I'll really appreciate.\n\n<InlineGallery images={opnsense-setup} title=\"OPNsense Firewall Configuration\" />\n\n### Deploying Nessus: Introducing Vulnerability Scanning to the Lab\n\nWith the SIEM side in partial production, I progressed to deploying Nessus for vulnerability scanning. I created a new Ubuntu VM on Proxmox with 4 vCPUs, 4 GB RAM, and 40 GB disk, assigning it the IP address 10.10.5.52/24 within VLAN 5. After configuring static networking and enabling SSH, I logged in and ran the commands to download the latest Nessus Debian package. I installed it using dpkg and started the nessusd service.\n\nAccessing Nessus via the browser at https://10.10.5.52:8834 allowed me to register for the Essentials version and input the activation key. The platform then began downloading its full set of plugins and signature files. Once installation was completed, I created a quick scan targeting the Metasploitable2 VM. Even with the basic scan template, the results after the scan show that it was successful even with limited information, confirming its functionality.\n\n<InlineGallery images={nessus-deployment} title=\"Nessus Vulnerability Scanner Setup\" />\n\n### Conclusion\n\nAt this point, I had a partially complete security monitoring stack within my home lab. Wazuh was successfully collecting logs from my Parrot OS and Docker machines and even parsing Docker container activity. Nessus was active and ready to scan targets across VLAN 5. However, OPNsense integration remained incomplete due to agent startup issues tied to BSD permission handling. I plan to circle back to this issue later with a deeper understanding of BSD service management or possibly using Syslog forwarding as a temporary workaround.\n\nThis project showcases the real-world challenges of building a hybrid monitoring environment, integrating both Linux and BSD-based systems into a centralised SIEM. It's a valuable case study for anyone deploying Wazuh in a segmented network and dealing with heterogeneous operating systems. My next step will be to document the resolution of the OPNsense agent issue and expand Wazuh's use to include alert rule tuning and dashboard customisation.\n\nStay tuned for the next stage of this project as we integrate more detection and response tools.\n\n**Credits:** This walkthrough is based on Episode 2 of the Ultimate Cybersecurity Lab YouTube series by Gerard O'Brien. While the steps closely followed his guidance, the project was independently implemented by Samson Otori, with custom network configurations and host assignments tailored to fit a pre-existing VLAN-segmented lab environment.\n\nHere's a link to his YouTube channels:\n\n[Gerard O'Brien's Channel](https://www.youtube.com/watch?v=ytWZ6OrFEQE&list=PL3ljjyal211AbTqlxSo6CGBiVqsXw8wrp&index=9) ",
    "image": "/images/projects/hardware-lab/Image-header-for-project-4.4.jpeg",
    "technologies": [],
    "images": [],
    "series": {
      "name": "Project 4.4: Integrating Wazuh SIEM/XDR and Nessus in a Cybersecurity Home Lab",
      "part": 1,
      "totalParts": 1
    }
  },
  {
    "slug": "upgrade-1-4tb-sata-hard-drive-proxmox",
    "title": "Upgrade 1: Installing a 4TB SATA Hard Drive in My Proxmox Server",
    "description": "A detailed walkthrough of expanding Proxmox VE storage with a 4TB SATA drive, including troubleshooting detection issues and proper system integration.",
    "date": "2025-07-18",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "",
    "solution": "",
    "results": [],
    "category": "Infrastructure",
    "tags": [
      "Proxmox",
      "Storage",
      "Hardware",
      "SATA",
      "Linux",
      "System Administration",
      "Troubleshooting",
      "Infrastructure",
      "Homelab"
    ],
    "content": "\r\n## Installing a 4TB SATA Hard Drive in My Proxmox Server\r\n\r\n### Overview\r\n\r\nTo expand my Proxmox VE bare-metal server's storage, I installed a 4TB SATA 3.5\" hard drive. Although the hardware was correctly connected, the drive initially failed to appear in Proxmox or in the system's disk utilities. This write-up documents how I diagnosed and resolved the issue.\r\n\r\n### Initial Symptoms\r\n\r\nAfter physically installing the drive with both SATA power and data cables connected to the motherboard, the system did not detect the disk. Tools like `lsblk`, `fdisk -l`, and the Proxmox GUI showed no sign of it.\r\n\r\nDespite this, the drive was powered—audibly spinning—and `dmesg` logs showed that SATA link negotiation occurred at 6.0 Gbps. However, there was no device registered as `/dev/sdX`, suggesting a failure in initialization.\r\n\r\n### Diagnostic Process\r\n\r\nI confirmed the SATA cable and power lines were functional by testing them with other working drives. Swapping ports on the motherboard yielded no change. BIOS settings were inspected to confirm that AHCI mode was enabled and that all SATA ports were active.\r\n\r\nI then tested the drive using a USB-to-SATA adapter. While a smaller 2.5\" drive was successfully detected through the adapter, the 3.5\" drive failed to power up correctly—implying insufficient power delivery via USB.\r\n\r\n### Resolution\r\n\r\nA full system reboot with the drive plugged into a known-good SATA port allowed proper detection. Upon restart, the disk appeared in `fdisk -l` and `lsblk` as `/dev/sdX`.\r\n\r\nWith the device now detected, I wiped previous signatures using `wipefs -a`, then formatted it using `mkfs.ext4`. I mounted the drive under `/mnt/4tbdrive` and added the appropriate entry to `/etc/fstab` for persistence.\r\n\r\n### Conclusion\r\n\r\nThis issue highlighted how a drive may appear to function at the hardware level while still failing OS-level detection due to incomplete initialisation. A simple reboot can often trigger proper enumeration. It's a reminder to combine physical verification with system-level diagnostics and to never overlook the importance of full reboots in hardware troubleshooting.\r\n\r\n### CREDIT\r\n\r\nThis project was independently researched, designed, and implemented by me, Samson Otori, as part of my hands-on journey in cybersecurity.\r\n\r\n---\r\n\r\n**Tags:** #Proxmox #Storage #Hardware #SATA #Linux #SystemAdministration #Troubleshooting #Infrastructure #Homelab #HardwareUpgrade #StorageExpansion #ProxmoxVE #BareMetal #DiskManagement ",
    "image": "/images/projects/hardware-lab/20250712_133828.jpg",
    "technologies": [],
    "images": [
      {
        "src": "/images/projects/hardware-lab/20250712_133903.jpg",
        "alt": "4TB SATA hard drive installation process"
      },
      {
        "src": "/images/projects/hardware-lab/20250712_133922.jpg",
        "alt": "Hardware connection verification"
      },
      {
        "src": "/images/projects/hardware-lab/20250712_141335.jpg",
        "alt": "System detection troubleshooting"
      },
      {
        "src": "/images/projects/hardware-lab/20250712_133957.jpg",
        "alt": "Drive mounting and configuration"
      },
      {
        "src": "/images/projects/hardware-lab/20250712_141450.jpg",
        "alt": "Final system integration"
      },
      {
        "src": "/images/projects/hardware-lab/New 4 TB HArd drive.png",
        "alt": "New 4TB hard drive overview"
      }
    ],
    "series": {
      "name": "Upgrade 1: Installing a 4TB SATA Hard Drive in My Proxmox Server",
      "part": 1,
      "totalParts": 1
    }
  },
  {
    "slug": "vulnerable-machines-installation",
    "title": "Vulnerable Machines Installation (Metasploitable2, DVWA, bWAPP, WebGoat)",
    "description": "A comprehensive guide to installing and configuring vulnerable machines and applications in a segmented cybersecurity homelab for penetration testing and security training.",
    "date": "2025-07-05",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "",
    "solution": "",
    "results": [],
    "category": "red",
    "tags": [
      "Metasploitable2",
      "DVWA",
      "bWAPP",
      "WebGoat",
      "Vulnerable Machines",
      "Penetration Testing",
      "Docker",
      "MacVLAN",
      "VLAN",
      "Homelab",
      "Proxmox",
      "Cybersecurity",
      "Security Training",
      "Web Vulnerabilities",
      "Containerization"
    ],
    "content": "\r\n## Project 4.3: Vulnerable Machines Installation (Metasploitable2, DVWA, bWAPP, WebGoat)\r\n\r\nFollowing the successful deployment of Docker and Portainer within VLAN 5 of my home lab, the next step in my cybersecurity lab project was to populate the environment with intentionally vulnerable systems. These systems will serve as practical targets for future testing, detection, and simulation scenarios. In this post, I document the installation and configuration of four key vulnerable systems: Metasploitable2, Damn Vulnerable Web Application (DVWA), bWAPP (Buggy Web Application), and WebGoat.\r\n\r\n## Installing Metasploitable2 (MSF2)\r\n\r\nMetasploitable2, a vulnerable Linux VM maintained by Rapid7, is designed for penetration testing training and exploits development. It's a go-to machine for beginners looking to understand service-level vulnerabilities.\r\n\r\nTo begin, I created a new VM in Proxmox with the following details:\r\n- VM ID: 105\r\n- VM Name: Meta-Sploit-Able2\r\n- Media Type: No media\r\n- Disk Interface: IDE\r\n- Network VLAN: VLAN 10 (Vulnerable Machines)\r\n\r\nAfter provisioning the VM shell, I SSHed into the Proxmox server from my Parrot OS laptop and navigated to `/var/lib/vz/images/`. Inside this directory, I created a folder named `105`, matching the VM ID. The reason for SSH access instead of using Proxmox's UI was to maintain an isolated and secure management workflow.\r\n\r\nUsing wget, I attempted to download the Metasploitable2 image. After resolving a few download errors, I extracted the ZIP file and located the necessary VMDK disk image. This image had to be converted to the QCOW2 format, which is preferred in Proxmox for virtual disk usage. The conversion was done using the qemu-img convert command:\r\n\r\n```bash\r\nqemu-img convert -f vmdk -O qcow2 Metasploitable2-Linux.vmdk Metasploitable2-Linux.qcow2\r\n```\r\n\r\nNext, I edited the configuration file of VM 105 (`/etc/pve/qemu-server/105.conf`) and pointed the VM to the newly converted QCOW2 disk image. I saved and verified the change from the Proxmox UI under \"Hardware.\"\r\n\r\nAfter powering on the VM, I logged in using the default Metasploitable credentials (`msfadmin` / `msfadmin`). I confirmed the system had joined VLAN 10 correctly by checking its IP address: `10.10.10.100`. I also validated DHCP functionality, DNS resolution, and connectivity to my firewall.\r\n\r\nTo finish this section, I browsed to the Metasploitable2 IP from my parrot OS and confirmed that its web interface, including DVWA (which comes preinstalled), was accessible.\r\n\r\n## Setting Up Docker Networking with MacVLAN\r\n\r\nBefore continuing to deploy the rest of the vulnerable apps as containers, I had to address Docker's default behavior of assigning container IPs behind a bridge. This would prevent each container from having its own IP on the subnet, which was necessary for scanning them individually with tools like Nessus later on.\r\n\r\nTo solve this, I logged into Portainer and configured custom Docker networks using MacVLAN. I created two networks:\r\n\r\n1. `vlan30-config` (on `10.10.30.0/24`): Provided the container IP range using MACVLAN driver.\r\n2. `vlan30`: Attached directly to VLAN 30 (Docker-Containers).\r\n\r\nI retrieved the correct network adapter name using `ip a` command on the Ubuntu Docker host and configured gateway and subnet ranges carefully. This configuration allowed containers to pull individual IPs within VLAN 30, just like physical devices.\r\n\r\nTo test the new network configuration, I deployed a test Nginx container and confirmed it received a proper IP within the range (e.g., `10.10.30.128`) and was accessible via browser.\r\n\r\n## Deploying bWAPP (Buggy Web Application)\r\n\r\nbWAPP, which stands for Buggy Web Application, is a PHP/MySQL-based deliberately insecure web app developed for educational purposes. It contains over 100 web vulnerabilities.\r\n\r\nInside Portainer, I added a new container:\r\n- Name: `prod-bwapp`\r\n- Image: Pulled from Docker Hub\r\n- Network: Attached to `vlan30` (configured earlier with MacVLAN)\r\n\r\nAfter deployment, I copied its assigned IP and accessed it via browser. The bWAPP interface loaded successfully. I followed the on-screen prompt to complete the installation, setting up the database via the `/install.php` page. Once installed, the login screen confirmed successful setup.\r\n\r\n## Deploying Damn Vulnerable Web Application (DVWA)\r\n\r\nDVWA, or Damn Vulnerable Web Application, is another PHP/MySQL web app with known vulnerabilities. It's widely used to practice web-based attacks such as SQL injection, XSS, CSRF, etc.\r\n\r\nJust like with bWAPP, I deployed DVWA through Portainer:\r\n- Name: `prod-dvwa`\r\n- Image: Pulled from Docker Hub\r\n- Network: Connected to `vlan30`\r\n\r\nUpon deployment, I accessed the IP in the browser. DVWA was reachable, and the default login screen appeared. All services were running correctly within the expected Docker environment.\r\n\r\n## Deploying WebGoat\r\n\r\nWebGoat is a deliberately insecure Java-based web application maintained by OWASP to teach application security lessons.\r\n\r\nFollowing the same container deployment process:\r\n- Name: `prod-webgoat`\r\n- Image: Pulled from Docker Hub\r\n- Network: Connected to `vlan30`\r\n\r\nAfter the container started, I accessed it via the browser using the assigned IP and port 8080 (e.g., `http://10.10.30.135:8080`). WebGoat loaded successfully, providing access to a series of vulnerable coding labs that simulate real-world scenarios.\r\n\r\n## Conclusion\r\n\r\nAt this point, my Vulnerable Machines segment is fully functional. The following systems are now live and operating on VLAN 10 and VLAN 30:\r\n\r\n- Metasploitable2 (IP: `10.10.10.51`) on VLAN 10\r\n- bWAPP, DVWA, and WebGoat as Docker containers with unique IPs on VLAN 30\r\n\r\nThese machines will now serve as valuable assets for upcoming simulations, scanning, alerting, and response workflows in the lab. Their intentional vulnerabilities are essential for testing detection tools like Wazuh and Nessus, which will be covered in future posts.\r\n\r\nIf you're following along with this project, make sure your VLAN segmentation, DHCP assignment, and Docker networking are properly configured. Having each container accessible via its own IP is key to realistic and scalable security testing.\r\n\r\nStay tuned for the next stage of this project as we integrate more detection and response tools.\r\n\r\nCredits: This walkthrough is based on Episode 2 of the Ultimate Cybersecurity Lab YouTube series by Gerard O'Brien. While the steps closely followed his guidance, the project was independently implemented by Samson Otori, with custom network configurations and host assignments tailored to fit a pre-existing VLAN-segmented lab environment.\r\n\r\nHere's a link to his YouTube channels:\r\n- [Gerard O'Brien's Channel](https://www.youtube.com/@techwithgerard)\r\n\r\n---\r\n\r\n**Tags:** #Metasploitable2 #DVWA #bWAPP #WebGoat #VulnerableMachines #PenetrationTesting #Docker #MacVLAN #VLAN #Homelab #Proxmox #Cybersecurity #SecurityTraining #WebVulnerabilities #Containerization ",
    "image": "/images/projects/hardware-lab/Vulnerable machines installation.jpeg",
    "technologies": [],
    "images": [
      {
        "src": "/images/projects/hardware-lab/1 Metasploitable Installation started.png",
        "alt": "1 Metasploitable Installation started"
      },
      {
        "src": "/images/projects/hardware-lab/2 Not using any installation media.png",
        "alt": "2 Not using any installation media"
      },
      {
        "src": "/images/projects/hardware-lab/3 leave all as is.png",
        "alt": "3 leave all as is"
      },
      {
        "src": "/images/projects/hardware-lab/4 CPU.png",
        "alt": "4 CPU"
      },
      {
        "src": "/images/projects/hardware-lab/5 RAM.png",
        "alt": "5 RAM"
      },
      {
        "src": "/images/projects/hardware-lab/6 Placing it in the right segment of my network vlan10.png",
        "alt": "6 Placing it in the right segment of my network vlan10"
      },
      {
        "src": "/images/projects/hardware-lab/7 Summary of the configuration.png",
        "alt": "7 Summary of the configuration"
      },
      {
        "src": "/images/projects/hardware-lab/8 SSHed into my proxmox server  from parrot OS.png",
        "alt": "8 SSHed into my proxmox server from parrot OS"
      },
      {
        "src": "/images/projects/hardware-lab/9 downloading metasploitable 2.png",
        "alt": "9 downloading metasploitable 2"
      },
      {
        "src": "/images/projects/hardware-lab/10 downloading of the metasploitable 2 in progress.png",
        "alt": "10 downloading of the metasploitable 2 in progress"
      },
      {
        "src": "/images/projects/hardware-lab/11 Metasploitable downloaded successfully.png",
        "alt": "11 Metasploitable downloaded successfully"
      },
      {
        "src": "/images/projects/hardware-lab/12 renaming metasploitable and trying to extract.png",
        "alt": "12 renaming metasploitable and trying to extract"
      },
      {
        "src": "/images/projects/hardware-lab/13 installing unzip for extraction of metasploitable.png",
        "alt": "13 installing unzip for extraction of metasploitable"
      },
      {
        "src": "/images/projects/hardware-lab/14 extracted matasploitable.png",
        "alt": "14 extracted matasploitable"
      },
      {
        "src": "/images/projects/hardware-lab/15 converted metasploitable to another type.png",
        "alt": "15 converted metasploitable to another type"
      },
      {
        "src": "/images/projects/hardware-lab/16 changing the highlighted to point to metasploitable.png",
        "alt": "16 changing the highlighted to point to metasploitable"
      },
      {
        "src": "/images/projects/hardware-lab/17 changing the file to point to metasploitable.png",
        "alt": "17 changing the file to point to metasploitable"
      },
      {
        "src": "/images/projects/hardware-lab/18 AFTER PARROT back to proxmox to confirm insertation of metasploitable vm on created vm MAIN.png",
        "alt": "18 AFTER PARROT back to proxmox to confirm insertation of metasploitable vm on created vm MAIN"
      },
      {
        "src": "/images/projects/hardware-lab/19 AFTER PARROT Error when trying to start the VM.png",
        "alt": "19 AFTER PARROT Error when trying to start the VM"
      },
      {
        "src": "/images/projects/hardware-lab/20 AFTER WINDOWS Editing the storageCFG file to fix the VM not starting issue.png",
        "alt": "20 AFTER WINDOWS Editing the storageCFG file to fix the VM not starting issue"
      },
      {
        "src": "/images/projects/hardware-lab/21 AFTER PARROT metasploitable now started properly.png",
        "alt": "21 AFTER PARROT metasploitable now started properly"
      },
      {
        "src": "/images/projects/hardware-lab/22 AFTER PARROT Confirming the IP address of the metasploitable machine.png",
        "alt": "22 AFTER PARROT Confirming the IP address of the metasploitable machine"
      },
      {
        "src": "/images/projects/hardware-lab/23 AFTER PARROT Pinged my firewall and google and all worked properly.png",
        "alt": "23 AFTER PARROT Pinged my firewall and google and all worked properly"
      },
      {
        "src": "/images/projects/hardware-lab/24 AFTER WINDOWS Accessing Metasploitable dashboard via ip address on parrot os.png",
        "alt": "24 AFTER WINDOWS Accessing Metasploitable dashboard via ip address on parrot os"
      },
      {
        "src": "/images/projects/hardware-lab/25 Creating a test container in docker nginx.png",
        "alt": "25 Creating a test container in docker nginx"
      },
      {
        "src": "/images/projects/hardware-lab/26 nginx deployed.png",
        "alt": "26 nginx deployed"
      },
      {
        "src": "/images/projects/hardware-lab/27 nginx accessed and working.png",
        "alt": "27 nginx accessed and working"
      },
      {
        "src": "/images/projects/hardware-lab/28 confirming my network adapter.png",
        "alt": "28 confirming my network adapter"
      },
      {
        "src": "/images/projects/hardware-lab/29 Network Configuration Complet for vlan30 on portainer.png",
        "alt": "29 Network Configuration Complet for vlan30 on portainer"
      },
      {
        "src": "/images/projects/hardware-lab/30 Vlan30 Config has been created.png",
        "alt": "30 Vlan30 Config has been created"
      },
      {
        "src": "/images/projects/hardware-lab/31 Creating another network and selecting the initially created vlan30 config.png",
        "alt": "31 Creating another network and selecting the initially created vlan30 config"
      },
      {
        "src": "/images/projects/hardware-lab/32 Creating another containder to be under vlan30.png",
        "alt": "32 Creating another containder to be under vlan30"
      },
      {
        "src": "/images/projects/hardware-lab/33 nginx now deplored and having its own dedicated ip address.png",
        "alt": "33 nginx now deplored and having its own dedicated ip address"
      },
      {
        "src": "/images/projects/hardware-lab/34 creating contianer for bwapp.png",
        "alt": "34 creating contianer for bwapp"
      },
      {
        "src": "/images/projects/hardware-lab/35 bwapp login page after installation.png",
        "alt": "35 bwapp login page after installation"
      },
      {
        "src": "/images/projects/hardware-lab/36 dvwa installation.png",
        "alt": "36 dvwa installation"
      },
      {
        "src": "/images/projects/hardware-lab/37 dvwa installed login page accessed.png",
        "alt": "37 dvwa installed login page accessed"
      },
      {
        "src": "/images/projects/hardware-lab/38 webgoat intsallation process.png",
        "alt": "38 webgoat intsallation process"
      },
      {
        "src": "/images/projects/hardware-lab/39 webgoat loging page accessed.png",
        "alt": "39 webgoat loging page accessed"
      }
    ],
    "series": {
      "name": "Project 4.3: Vulnerable Machines Installation (Metasploitable2, DVWA, bWAPP, WebGoat)",
      "part": 1,
      "totalParts": 1
    }
  },
  {
    "slug": "ubuntu-server-docker-portainer",
    "title": "Ubuntu Server, Docker and Portainer Installation in My Homelab",
    "description": "A detailed walkthrough of deploying Ubuntu Server with Docker and Portainer in my segmented cybersecurity homelab, including remote SSH management and VLAN integration.",
    "date": "2025-07-03",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "",
    "solution": "",
    "results": [],
    "category": "blue",
    "tags": [
      "Ubuntu Server",
      "Docker",
      "Portainer",
      "SSH",
      "VLAN",
      "Containerization",
      "Homelab",
      "Proxmox",
      "Remote Management"
    ],
    "content": "\r\n## Ubuntu Server, Docker and Portainer Installation in My Homelab\r\n\r\nAfter successfully segmenting my home lab using VLANs, the next major step was to deploy an Ubuntu Server dedicated to containerized tools using Docker and Portainer. Instead of using the Proxmox console directly throughout the process, I took a more modular and realistic approach: I SSHed into the Ubuntu server remotely from another laptop running Parrot OS. This Parrot OS laptop was physically connected to my Cisco switch using an RJ45 cable and had already been assigned to VLAN 5, the dedicated Security Tools segment in my lab.\r\n\r\nThe entire flow unfolded like this:\r\n\r\nFirst, I logged into Proxmox and created a new virtual machine. I named it something like UbuntuServer-docker and assigned it to VLAN 30, which is where all my Docker/container workloads reside. I used the Ubuntu Server live image, selected ZFS as the storage type, and allocated 16GB RAM to ensure smooth performance.\r\n\r\nDuring the Ubuntu installation, I carefully observed the DHCP setup, a critical step. I confirmed that the system automatically received an IP address, which meant my OPNsense DHCP service was working flawlessly across VLAN 30. This gave me confidence that VLAN isolation and interconnectivity were functioning as intended.\r\n\r\nAs I proceeded through the installer, I enabled OpenSSH so I could manage the server from my Parrot OS machine instead of using the Proxmox console. Once the installation was complete and the VM rebooted, I tested connectivity from Parrot OS by running a simple ping to the new server. It responded successfully.\r\n\r\nI then established an SSH session using:\r\n\r\n```bash\r\nssh <pilotvader>@<10.10.30.100>\r\n```\r\n\r\nInside the SSH session, I manually installed Docker. This included:\r\n\r\n1. Removing conflicting packages (if any)\r\n2. Setting up the Docker repository\r\n3. Installing Docker Engine\r\n4. Verifying with `sudo docker run hello-world`\r\n\r\nThe confirmation message \"Hello from Docker!\" appeared, a satisfying sign that the installation was successful. Running `sudo docker ps` showed no running containers, just as expected.\r\n\r\nNext, I proceeded to install Portainer (Community Edition) by:\r\n\r\n1. Creating a Docker volume:\r\n\r\n```bash\r\nsudo docker volume create portainer_data\r\n```\r\n\r\n2. Running the Portainer container:\r\n\r\n```bash\r\nsudo docker run -d -p 8000:8000 -p 9443:9443 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce:latest\r\n```\r\n\r\nOnce the container was running, I opened a browser on my Parrot OS laptop and navigated to:\r\n\r\n```\r\nhttps://<10.10.30.100>:9443\r\n```\r\n\r\nThere, I set my Portainer admin password and accessed the local environment, where I could already see two containers:\r\n\r\n1. The Portainer container itself\r\n2. The hello-world container Docker had used for verification\r\n\r\nTo clean up, I deleted the hello-world container via the Portainer interface.\r\n\r\nAt this point, my Ubuntu Server in VLAN 30 was now a fully functional Docker host, securely managed over VLAN 5 from my Parrot OS laptop. The whole setup reflected a real-world SOC design, segmentation, remote management, container orchestration, and will serve as the backbone for deploying security tools like Wazuh, TheHive, and Arkime in future phases.\r\n\r\n## Conclusion\r\n\r\nThe installation of Ubuntu Server, Docker, and Portainer has laid a solid foundation for the Security Tools section of my home lab. A notable part of this setup was accessing the Ubuntu Server via SSH from a Parrot OS laptop that was physically connected, via RJ45 cable, to a specifically configured port on my Cisco switch assigned to VLAN 5 (Security Tools). This deliberate port configuration allowed the laptop to join the segmented network, and the successful DHCP assignment from my OPNsense firewall confirmed that the VLAN setup and network services were functioning properly. This mirrored the physical isolation strategy used by Gerard O'Brien and demonstrated secure out-of-band management in a segmented environment.\r\n\r\nWith Portainer deployed on top of Docker, I now have a streamlined interface to manage containers across different network zones. This sets the stage for the next phase, where I'll deploy vulnerable applications like Metasploitable2, DVWA, and WebGoat for simulation and detection exercises. Before moving forward, it's crucial to ensure all infrastructure components, network segmentation, firewall configurations, and remote management, are fully operational. This step-by-step approach highlights the value of building a secure and modular lab environment from the ground up.\r\n\r\nCredits: This project was independently implemented by Samson Otori, drawing conceptual inspiration from Gerard O'Brien's Ultimate Cybersecurity Lab series.\r\n\r\nHere's a link to his YouTube channels:\r\n- [Gerard O'Brien's Channel](https://www.youtube.com/@techwithgerard)\r\n\r\n---\r\n\r\n**Tags:** #UbuntuServer #Docker #Portainer #SSH #VLAN #Containerization #Homelab #Proxmox #Cybersecurity #Infrastructure #Virtualization #NetworkSegmentation #SecurityTools #RemoteManagement #ContainerOrchestration ",
    "image": "/images/projects/hardware-lab/ubuntu-docker-portainer.jpeg",
    "technologies": [],
    "images": [
      {
        "src": "/images/projects/hardware-lab/Assigning cpu cores for processor.png",
        "alt": "Assigning cpu cores for processor"
      },
      {
        "src": "/images/projects/hardware-lab/assigning internal network vlan30.png",
        "alt": "Assigning internal network vlan30"
      },
      {
        "src": "/images/projects/hardware-lab/assigning ram.png",
        "alt": "Assigning ram"
      },
      {
        "src": "/images/projects/hardware-lab/assigning storage.png",
        "alt": "Assigning storage"
      },
      {
        "src": "/images/projects/hardware-lab/During server installation this shows our dhcp is active with right ip address.png",
        "alt": "During server installation this shows our dhcp is active with right ip address"
      },
      {
        "src": "/images/projects/hardware-lab/Installing ubuntu server to create docker.png",
        "alt": "Installing ubuntu server to create docker"
      },
      {
        "src": "/images/projects/hardware-lab/Logged into ubuntu server on proxmox.png",
        "alt": "Logged into ubuntu server on proxmox"
      },
      {
        "src": "/images/projects/hardware-lab/Selecting ubuntu server image.png",
        "alt": "Selecting ubuntu server image"
      },
      {
        "src": "/images/projects/hardware-lab/Starting ubuntu server installation.png",
        "alt": "Starting ubuntu server installation"
      },
      {
        "src": "/images/projects/hardware-lab/summary of setup.png",
        "alt": "Summary of setup"
      },
      {
        "src": "/images/projects/hardware-lab/Ubuntu server installation process running .png",
        "alt": "Ubuntu server installation process running"
      },
      {
        "src": "/images/projects/hardware-lab/Pinging ubuntu server from my parrot OS.png",
        "alt": "Pinging ubuntu server from my parrot OS"
      },
      {
        "src": "/images/projects/hardware-lab/SSHed into my ubuntu server from parrot OS.png",
        "alt": "SSHed into my ubuntu server from parrot OS"
      },
      {
        "src": "/images/projects/hardware-lab/Docker installation from parrot OS on ubuntu server .png",
        "alt": "Docker installation from parrot OS on ubuntu server"
      },
      {
        "src": "/images/projects/hardware-lab/Sudo docker run hello world test which shows docker installed.png",
        "alt": "Sudo docker run hello world test which shows docker installed"
      },
      {
        "src": "/images/projects/hardware-lab/Portainer volume creation and installation.png",
        "alt": "Portainer volume creation and installation"
      },
      {
        "src": "/images/projects/hardware-lab/sudo docker ps to see the port its running on.png",
        "alt": "Sudo docker ps to see the port its running on"
      },
      {
        "src": "/images/projects/hardware-lab/accessing portainer dashboard in browser.png",
        "alt": "Accessing portainer dashboard in browser"
      },
      {
        "src": "/images/projects/hardware-lab/Portainer dashboard.png",
        "alt": "Portainer dashboard"
      },
      {
        "src": "/images/projects/hardware-lab/portainer dashboard 2.png",
        "alt": "Portainer dashboard 2"
      }
    ],
    "series": {
      "name": "Project 4.2: Ubuntu Server, Docker and Portainer Installation",
      "part": 1,
      "totalParts": 1
    }
  },
  {
    "slug": "vlans-segmentation-homelab",
    "title": "Segmenting My Cybersecurity Homelab Using VLANs",
    "description": "A detailed walkthrough of implementing VLAN segmentation in my cybersecurity homelab using OPNsense, Cisco switches, and Proxmox for better traffic control and security isolation.",
    "date": "2025-06-29",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "",
    "solution": "",
    "results": [],
    "category": "Infrastructure",
    "tags": [
      "VLAN",
      "Network Segmentation",
      "OPNsense",
      "Cisco Switch",
      "Proxmox",
      "Infrastructure",
      "Homelab"
    ],
    "content": "\r\n## Segmenting My Cybersecurity Homelab Using VLANs\r\n\r\nAfter completing the initial build of my cybersecurity homelab, I knew the next big milestone was network segmentation. I wanted to separate my environment into distinct VLANs for better traffic control, improved security, and a more organized deployment of my tools and virtual machines. The concept was simple in theory, separate traffic logically while maintaining complete control from a single pane.\r\n\r\nMy initial spark for this came from Gerard O'Brien, whose breakdown of homelab network segmentation introduced me to the idea of creating isolated VLANs for each category of devices or services. It made perfect sense: isolate your security tools, isolate vulnerable machines, isolate test environments, all while routing through a central firewall. Along the way, I hit several roadblocks. That's where Koroma Tech came in. His YouTube series covered VLAN segmentation using OPNsense, Cisco switches, and Proxmox, the exact gear I had. His breakdown helped untangle many of the issues I ran into and became an invaluable guide during troubleshooting.\r\n\r\n## Initial Vision\r\n\r\nI began with a vision of building an enterprise-style segmented lab. The goal was to use OPNsense as my central router and firewall, Proxmox to host all VMs, and a Cisco switch to trunk the VLANs across the environment. I planned four main VLANs:\r\n\r\nA VLAN for security tools, which would house platforms like Wazuh and TheHive. A separate VLAN for vulnerable machines, which I could target with Kali Linux and test detection pipelines. Another VLAN would be reserved for a Windows environment, where I could simulate real endpoints and domain controllers. Finally, I wanted a VLAN for Docker containers, to explore containerized security tools and microservices.\r\n\r\nAll of this was connected by a Cisco SG500X-24 switch, a Proxmox server with multiple bonded NICs, and an OPNsense firewall running on a dedicated thin client. Internet was shared into the lab via Ethernet from a laptop using a Wi-Fi uplink, serving as a temporary ISP connection.\r\n\r\n## Configuring the Cisco Switch\r\n\r\nThe first step was to configure VLANs on the Cisco switch. Inside the VLAN Management interface, I created VLANs 1 (default), 5, 10, 20, and 30. I used port GE1 as the trunk port connected to the Proxmox server and port GE2 as the uplink to the OPNsense firewall.\r\n\r\nTrunking configuration was critical. GE1 needed to be tagged for VLANs 5, 10, 20, and 30. This would allow Proxmox to forward VLAN-tagged traffic into the switch and out toward the firewall. Cisco switches, however, require each port to have one untagged VLAN. I initially attempted to remove all untagged VLANs but was met with an error. It turns out VLAN 1 must remain as the untagged VLAN by default. I left it in place and tagged the rest.\r\n\r\nPorts assigned to VM-specific devices were configured as access ports, tagged only for their respective VLANs. For example, GE5 might be an access port for VLAN 20 (Windows), and GE6 for VLAN 10 (Kali Linux).\r\n\r\n## VLAN Interface Setup in OPNsense\r\n\r\nOn the OPNsense firewall, the VLAN interfaces were built on top of the physical NIC (RE2) connected to the Cisco switch. For each VLAN, I created a corresponding virtual interface, such as RE2_vlan20 for VLAN 20, and then assigned it inside the OPNsense GUI.\r\n\r\nEach VLAN interface was given a static IP address, for example, 10.10.20.1/24 for VLAN 20, and a DHCP server was configured to assign IPs within that range. I added basic allow-all rules in the firewall for each VLAN subnet to ensure traffic could flow during testing. One misstep I encountered was related to firewall rules: DHCP leases weren't being issued at first, and I later discovered that a deny rule was taking precedence above my allow rule. Once I reordered them, DHCP worked flawlessly.\r\n\r\n## Bridging and Bonding in Proxmox\r\n\r\nThis was one of the trickiest parts of the build. My Proxmox server had three network interfaces, enp10s0, enp9s0, and enp6s0, which were originally bonded into a single interface, bond0. This bond0 wasn't attached to vmbr0, my default Linux bridge, which wasn't VLAN-aware.\r\n\r\nInspired by Koroma Tech's video, I thought I needed to separate one NIC and create a new Linux bridge, vmbr1, for the VLANs. I detached enp6s0 from the bond and attached it to vmbr1. This led to chaos: Proxmox VMs could no longer reach the internet, static IPs weren't being assigned, DHCP requests failed, and the web interface became intermittently unreachable. I had to access the server via shell and manually fix /etc/network/interfaces. A simple ifreload -a command even took the network down temporarily.\r\n\r\nThe realization hit after consulting Koroma Tech and rewatching his video (Thanks for his response): I never needed a second bridge. The original vmbr0, was to be made to point to bond0, and that would have been perfectly capable of handling VLAN-tagged traffic, provided the VLAN-aware checkbox was enabled, which I eventually did. So I reverted everything. I re-added enp6s0 to the bond, reset the bridge to vmbr0, and things began to work.\r\n\r\n## Assigning VLANs to VMs in Proxmox\r\n\r\nWith vmbr0 correctly configured, the next step was assigning VLAN tags to the VMs. In each VM configuration, I went to Hardware → Network Device, edited the NIC, and added the VLAN tag that matched the desired segment. For instance, the Windows VM was given VLAN 20, Kali got VLAN 10, and my Docker VM received VLAN 30.\r\n\r\nOnce this was done, I rebooted the VMs and ran ipconfig or ifconfig to verify the network settings. To my satisfaction, each VM pulled the correct IP address from its respective VLAN subnet, configured on OPNsense and trunked through the Cisco switch.\r\n\r\n## The Debugging Journey\r\n\r\nI ran into every possible issue: Proxmox network down, static IP not picked, DHCP not working, OPNsense not receiving traffic, and even Cisco switch ports refusing certain configs. I spent hours running packet captures on OPNsense to see if DHCP DISCOVER packets were even hitting the firewall, in many cases, they weren't, due to tagging or misassigned switch ports.\r\n\r\nIt wasn't until I fully understood how each layer, Proxmox, the switch, and OPNsense, handled tagged traffic that things started to align. The concept of trunk ports, access ports, tagging at the VM level, VLAN-aware bridges, and proper interface assignment all had to be in perfect harmony.\r\n\r\n## Conclusion\r\n\r\nThis project pushed me. I'm proud of how it turned out, not just because everything is now working, but because I truly understand the system I built. VLANs are no longer just theory to me. I've lived the chaos, the packet loss, the empty DHCP leases, and the recovery.\r\n\r\nMassive thanks to Gerard O'Brien for the foundational inspiration and to Koroma Tech for the actionable guidance and video breakdowns that helped me debug when things went south. He even took time to respond to my messages, and that helped keep me grounded.\r\n\r\nIf you're reading this and planning to segment your own lab: take it slow, understand each component, and know that breaking things is part of the journey. My next steps will be building services like Wazuh, TheHive, and Arkime inside their respective VLANs, and expanding the lab even further, now with a proper backbone in place.\r\n\r\nCredits: This project was independently implemented by Samson Otori, with conceptual inspiration from Gerard O'Brien and valuable technical guidance from Koroma Tech, whose content and support were instrumental in shaping and troubleshooting the VLAN segmentation setup.\r\n\r\nHere's a link to their YouTube channels:\r\n- [Gerard O'Brien's Channel](https://www.youtube.com/@techwithgerard)\r\n- [Koroma Tech Channel](https://www.youtube.com/@KoromaTech)\r\n\r\n---\r\n\r\n**Tags:** #VLAN #NetworkSegmentation #OPNsense #CiscoSwitch #Proxmox #Infrastructure #Homelab #Cybersecurity #NetworkSecurity #Virtualization #Firewall #DHCP #Trunking #AccessPorts #VLANAware #NetworkConfiguration #SecurityTools #WindowsEnvironment #KaliLinux #DockerContainers ",
    "image": "/images/projects/hardware-lab/home-lab-image.jpeg",
    "technologies": [],
    "images": [
      {
        "src": "/images/projects/hardware-lab/Homelab Project V117.png",
        "alt": "Homelab Project V117 Overview"
      },
      {
        "src": "/images/projects/hardware-lab/Navigating to VLAN Management and VLAN Setting in Cisco Switch.png",
        "alt": "Navigating to VLAN Management and VLAN Setting in Cisco Switch"
      },
      {
        "src": "/images/projects/hardware-lab/Adding new VLAN rule in cisco switch.png",
        "alt": "Adding new VLAN rule in cisco switch"
      },
      {
        "src": "/images/projects/hardware-lab/Trying to set up Port VLAN Membership.png",
        "alt": "Trying to set up Port VLAN Membership"
      },
      {
        "src": "/images/projects/hardware-lab/Assigning Trunk and access VLANs to Infrastructure and physical ports or system.png",
        "alt": "Assigning Trunk and access VLANs to Infrastructure and physical ports or system"
      },
      {
        "src": "/images/projects/hardware-lab/Setting PVID Primary VLAN ID of Physical Parrot OS and Windows OS to ensure Untagged traffic is treated as part of that VLAN.png",
        "alt": "Setting PVID Primary VLAN ID of Physical Parrot OS and Windows OS to ensure Untagged traffic is treated as part of that VLAN"
      },
      {
        "src": "/images/projects/hardware-lab/Navigating to create VLAN Interface on OPNSense.png",
        "alt": "Navigating to create VLAN Interface on OPNSense"
      },
      {
        "src": "/images/projects/hardware-lab/Creating VLAN Interface on OPNSense.png",
        "alt": "Creating VLAN Interface on OPNSense"
      },
      {
        "src": "/images/projects/hardware-lab/Assigning Interface on OPNSense.png",
        "alt": "Assigning Interface on OPNSense"
      },
      {
        "src": "/images/projects/hardware-lab/Interface Assigned on OPNSense firewall.png",
        "alt": "Interface Assigned on OPNSense firewall"
      },
      {
        "src": "/images/projects/hardware-lab/chatgpt.png",
        "alt": "ChatGPT assistance"
      },
      {
        "src": "/images/projects/hardware-lab/Setting up Static IPs and DHCP For all Interface.png",
        "alt": "Setting up Static IPs and DHCP For all Interface"
      },
      {
        "src": "/images/projects/hardware-lab/Enabling DHCP Server for static IP.png",
        "alt": "Enabling DHCP Server for static IP"
      },
      {
        "src": "/images/projects/hardware-lab/DHCP Set for all Static IPs.png",
        "alt": "DHCP Set for all Static IPs"
      },
      {
        "src": "/images/projects/hardware-lab/Creating Firewall rules for Each Interface.png",
        "alt": "Creating Firewall rules for Each Interface"
      },
      {
        "src": "/images/projects/hardware-lab/Adding Firewall rules for first Interface.png",
        "alt": "Adding Firewall rules for first Interface"
      },
      {
        "src": "/images/projects/hardware-lab/Firewall rules Added for all Interface.png",
        "alt": "Firewall rules Added for all Interface"
      },
      {
        "src": "/images/projects/hardware-lab/Creating new linux bridge.png",
        "alt": "Creating new linux bridge"
      },
      {
        "src": "/images/projects/hardware-lab/Configuring VLAN In Proxmox to Make it VLAN Aware.png",
        "alt": "Configuring VLAN In Proxmox to Make it VLAN Aware"
      },
      {
        "src": "/images/projects/hardware-lab/Configuring VM interface with VLAN Tags on Proxmox.png",
        "alt": "Configuring VM interface with VLAN Tags on Proxmox"
      },
      {
        "src": "/images/projects/hardware-lab/Kali on proxmox now having internet.png",
        "alt": "Kali on proxmox now having internet"
      },
      {
        "src": "/images/projects/hardware-lab/Windows 10 on proxmox having internet access.png",
        "alt": "Windows 10 on proxmox having internet access"
      },
      {
        "src": "/images/projects/hardware-lab/running ip show link on proxmox to know how to go about creating linux bridge.png",
        "alt": "Running ip show link on proxmox to know how to go about creating linux bridge"
      },
      {
        "src": "/images/projects/hardware-lab/CHATGPTSHELL.png",
        "alt": "ChatGPT shell assistance"
      }
    ],
    "series": {
      "name": "Project 4.1: VLANs Segmentation In My Homelab",
      "part": 1,
      "totalParts": 1
    }
  },
  {
    "slug": "building-full-hardware-cybersecurity-homelab",
    "title": "Building a Full Hardware Cybersecurity Home Lab",
    "description": "A comprehensive guide on transitioning from VirtualBox to building a fully equipped hardware cybersecurity home lab, complete with network design, hardware choices, and virtual machine configurations.",
    "date": "2025-05-15",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "",
    "solution": "",
    "results": [],
    "category": "Infrastructure",
    "tags": [
      "Home Lab",
      "Hardware",
      "Networking",
      "Infrastructure",
      "Virtualization"
    ],
    "content": "\r\n## Levelling Up: From VirtualBox to a Full Hardware Cybersecurity Home Lab (Project V117)\r\n\r\nIf there's one thing that's been both my playground as a cybersecurity enthusiast, it's my home lab. I didn't just throw hardware together, I engineered a mini datacenter that lets me break things, fix them, and build skills that go beyond the classroom or certification paths.\r\n\r\nSo let me walk you through how I set it all up, from network design, hardware choices, and wiring, to the virtual machines running inside.\r\n\r\n## The Blueprint\r\n\r\nBefore buying a single cable, I sat down and mapped out what I needed:\r\n- A solid core network\r\n- A powerful, reliable server\r\n- A firewall/router to control traffic\r\n- A proper switch to interconnect everything\r\n- And most importantly: internet access without having to buy a new broadband plan\r\n\r\n## The Physical Stack\r\n\r\nHere's the physical breakdown of what I used:\r\n\r\n### The Switch\r\nAt the heart of my lab sits a Cisco SG500X-24, a 24-port managed switch with RJ45 1GbE ports. This switch gives me full control over VLANs, trunking, port security, and QoS, which is perfect for mimicking enterprise-level setups. I got this because later in future I plan to manually configure VLANs for different zones (e.g., management, attack, internal, DMZ), so I could isolate traffic and simulate real-world networks.\r\n\r\n### The Server\r\nThen comes my main server, which I affectionately call the Node-V117.\r\n- CPU: Intel Xeon E5-2689 (8 cores, 16 threads)\r\n- RAM: 64 GB ECC (Error Correcting Code)\r\n- Storage: 3 SSDs for fast I/O\r\n- GPU: NVIDIA Quadro card, mostly used for potential GPU passthrough and future ML experiments\r\n\r\nThis beast runs Proxmox VE, a Type-1 hypervisor that gives me the power to run several virtual machines and containers. If you're serious about virtualisation, Proxmox is the real deal.\r\n\r\n### The OPNsense Firewall\r\nFor routing and security experimentation, I installed OPNsense on an HP T730 Thin Client. It's a sleek, fanless device that runs silently and comes equipped with a dual 2.5GbE NIC, perfect for future networking experiments. I configured the interfaces for WAN (connected to my laptop for internet) and LAN (connected to the switch), giving me complete control over firewall rules, NAT, and traffic shaping. Right now, it's sitting in place and connected, ready to be the core of my network security setup when I begin more advanced testing.\r\n\r\n## The Wiring and Internet Hack\r\n\r\nOne of the most interesting parts of my setup was getting the entire homelab online, without a dedicated internet line. For now, I bridged my laptop's internet connection to the firewall as a temporary workaround. It works for basic connectivity and testing, but I'm already seeing its limitations in bandwidth, stability, and accessibility. Eventually, I plan to set up a dedicated internet line for the lab to unlock more advanced use cases, such as remote access, persistent services, and uninterrupted updates.\r\n\r\nHere's how I did it:\r\n\r\n1. Laptop Internet Sharing\r\n   - My laptop connects to Wi-Fi\r\n   - I shared this connection through the Ethernet port using Windows' Internet Sharing feature\r\n\r\n2. Cable Run\r\n   - I plugged an Ethernet cable from the laptop into the WAN port of the HP T730 running OPNsense\r\n\r\n3. Firewall Setup\r\n   - In OPNsense, I configured the WAN interface to get an IP via DHCP (coming from the laptop)\r\n   - Then set the LAN IP range (e.g., 192.168.100.1/24) and turned on DHCP for internal devices\r\n\r\n4. Switch Cabling\r\n   - The LAN port of the firewall connects to port 1 on the Cisco switch\r\n   - My server's NIC connects to port 2\r\n   - The remaining ports were available for VMs or any other device I want to simulate\r\n\r\n## Virtual Machines\r\n\r\nOn Proxmox, I spun up multiple VMs, each serving a different purpose:\r\n- Windows 10 & 11: For endpoint security testing, malware analysis, and AD simulations\r\n- Ubuntu Server: Hosting lightweight services, honeypots, and ELK stack\r\n- Kali Linux: My offensive workstation, preloaded with tools like Burp Suite, Metasploit, and Nmap\r\n\r\nLater, as I expand my knowledge, I would place each VM on its own VLAN or subnet, and intentionally misconfigure some for security testing, because what's a lab without vulnerabilities?\r\n\r\n## Use Cases and Next Steps\r\n\r\nWith this lab, I can:\r\n- Simulate red vs. blue team scenarios\r\n- Build and monitor logs from Windows endpoints\r\n- Train with SIEM tools like Wazuh\r\n- Set up phishing simulations and response workflows\r\n- Test firewall rules, intrusion detection, and segmentation\r\n\r\nThe plan is to keep building on this, maybe add Active Directory, integrate SOAR tools like Shuffle(which I'm already working on currently), and even try deploying a Kubernetes cluster on Ubuntu.\r\n\r\n## Conclusion\r\n\r\nSetting up this lab wasn't just about putting hardware together, it was about creating an environment where I could think like an attacker, build like an engineer, and defend like a blue teamer. Every time I boot up a VM, I'm building muscle memory for real-world problem solving.\r\n\r\nIf you're thinking of building your own lab, start small but think big. And don't wait for the perfect setup. I started out running labs in VirtualBox, just trying to get a feel for the tools and workflows. But eventually, I knew I needed to experience real hardware and full network environments. So I made this work, with shared internet and repurposed gear. It's not about perfection; it's about progress.\r\n\r\nGot questions or thinking of building your own lab? I'd be happy to chat or help, just click on the \"Contact Me\" button anywhere on this site to reach out to me on LinkedIn. \r\n\r\n*NOTE: This project was independently researched, designed, and implemented by me, Samson Otori, as part of my hands-on journey in cybersecurity.* ",
    "image": "/images/projects/home-lab.png",
    "technologies": [],
    "images": [
      {
        "src": "/images/projects/hardware-lab/1-router.jpg",
        "alt": "Router Configuration - Initial Setup"
      },
      {
        "src": "/images/projects/hardware-lab/2-router.jpg",
        "alt": "Router Configuration - Network Settings"
      },
      {
        "src": "/images/projects/hardware-lab/3-router.jpg",
        "alt": "Router Configuration - Final Setup"
      },
      {
        "src": "/images/projects/hardware-lab/4-switch.jpg",
        "alt": "Switch Installation - Hardware View"
      },
      {
        "src": "/images/projects/hardware-lab/5-switch.jpg",
        "alt": "Switch Configuration - Port Setup"
      },
      {
        "src": "/images/projects/hardware-lab/6-server.jpg",
        "alt": "Server Hardware - Front View"
      },
      {
        "src": "/images/projects/hardware-lab/7-server.jpg",
        "alt": "Server Hardware - Internal Components"
      },
      {
        "src": "/images/projects/hardware-lab/8-devices-connection.png",
        "alt": "Network Devices Connection Diagram"
      },
      {
        "src": "/images/projects/hardware-lab/9-connection.jpg",
        "alt": "Physical Network Connections - Setup 1"
      },
      {
        "src": "/images/projects/hardware-lab/10-connection.jpg",
        "alt": "Physical Network Connections - Setup 2"
      },
      {
        "src": "/images/projects/hardware-lab/11-connection.jpg",
        "alt": "Physical Network Connections - Setup 3"
      },
      {
        "src": "/images/projects/hardware-lab/12-connection.jpg",
        "alt": "Physical Network Connections - Setup 4"
      },
      {
        "src": "/images/projects/hardware-lab/13-setup.jpg",
        "alt": "Complete Lab Setup - View 1"
      },
      {
        "src": "/images/projects/hardware-lab/14-setup.jpg",
        "alt": "Complete Lab Setup - View 2"
      },
      {
        "src": "/images/projects/hardware-lab/15-proxmox.png",
        "alt": "Proxmox VE - Installation"
      },
      {
        "src": "/images/projects/hardware-lab/16-proxmox.png",
        "alt": "Proxmox VE - Configuration"
      },
      {
        "src": "/images/projects/hardware-lab/17-proxmox.png",
        "alt": "Proxmox VE - VM Setup"
      },
      {
        "src": "/images/projects/hardware-lab/18-proxmox.png",
        "alt": "Proxmox VE - Network Configuration"
      },
      {
        "src": "/images/projects/hardware-lab/19-OPNSense.png",
        "alt": "OPNSense Firewall Dashboard"
      },
      {
        "src": "/images/projects/hardware-lab/20-switch.png",
        "alt": "Switch Management Interface"
      }
    ],
    "series": {
      "name": "Project 4: Building a Full Hardware Cybersecurity Home Lab",
      "part": 1,
      "totalParts": 1
    }
  },
  {
    "slug": "soc-automation-project-part2",
    "title": "Part 3: Generating and Ingesting Telemetry",
    "description": "Setting up telemetry generation and ingestion in our SOC environment using Mimikatz and configuring Wazuh for detection",
    "date": "2025-03-21",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "",
    "solution": "",
    "results": [],
    "category": "blue",
    "tags": [
      "Blue Team",
      "SOC",
      "Automation",
      "SIEM",
      "Telemetry"
    ],
    "content": "\r\n# Part 3: Generating and Ingesting Telemetry\r\n\r\n## Introduction\r\n\r\nIn this third part of the MYDFIR SOC Automation Project home lab series, I dive into the critical process of generating telemetry from a Windows 10 machine and ensuring it is correctly ingested into Wazuh. By the end of this session, I would have successfully configured my system to log events, including activity from Mimikatz, and triggered a custom alert. This hands-on process not only enhances my understanding of SIEM operations but also strengthens my ability to detect and analyze security incidents effectively.\r\n\r\n## Configuring Wazuh to Ingest Sysmon Logs\r\n\r\nTo begin, I access the Wazuh configuration settings on my Windows 10 machine. When Wazuh is installed, its configuration files are located under Program Files (x86), specifically within the ek-agent folder. The key file I need to modify is ossec.conf. This file governs how logs are processed and which events are included or excluded from analysis. By default, certain event IDs are excluded using the != operator. However, for my purpose, I need to monitor processes related to Mimikatz, which requires Sysmon to be installed or Windows Security Event ID 4688 to be enabled. Since Sysmon was installed in part two of this series, I opt for that method.\r\n\r\nBefore making changes, I first create a backup of ossec.conf to safeguard against errors. This allows me to revert back if needed. I then modify the configuration to ingest Sysmon logs by adding a new entry under the localfile section. To locate the correct Sysmon channel name, I open the Windows Event Viewer, navigate to Applications and Services > Microsoft > Windows > Sysmon, and retrieve the operational log name from the properties section. This name is then inserted into my ossec.conf file in place of the existing application log configuration.\r\n\r\n## Adjusting Log Categories and Restarting Services\r\n\r\nNext, I remove other log categories such as Application, Security, and System, ensuring that only Sysmon logs are forwarded to the Wazuh manager. Once the changes are saved, administrative privileges are required to replace the existing configuration file. After this, I restart the Wazuh service, as any configuration changes must be followed by a service restart to take effect.\r\n\r\n## Testing Telemetry with Mimikatz\r\n\r\nWith the updated configuration in place, I verify the ingestion of Sysmon logs in the Wazuh dashboard. Searching for \"Sysmon\" in the Alerts index may take some time before logs appear. To test this setup, I download and execute Mimikatz. Since Windows Defender would block this file, I must first exclude the Downloads folder from virus scanning. This is done through Windows Security settings by adding an exclusion for the Downloads directory. Also, Google Chrome may prevent the download, so I disable Safe Browsing under Privacy and Security settings in Chrome before proceeding.\r\n\r\nOnce Mimikatz is downloaded and extracted, I run it via an administrative PowerShell session and monitor Wazuh for related alerts. If no alerts appear, it is likely because Wazuh only logs events when a predefined rule is triggered. To address this, I modify the ossec.conf file on the Wazuh manager to log all events by default. This is done by enabling the logall and logall_json options in the configuration file. After saving these changes, I restart the Wazuh manager service.\r\n\r\n## Enhancing Log Archiving and Indexing\r\n\r\nTo ensure that all logs are archived and ingested into Wazuh, I also update Filebeat's configuration. This involves navigating to the Filebeat YAML configuration file and changing the archives_enabled setting from false to true. As always, after modifying configurations, I restart the Filebeat service to apply the changes.\r\n\r\nOnce the configurations are updated, I proceed to create a new index in the Wazuh dashboard for archived logs. This is done through the Stack Management section, where I define a new index pattern named wazuh-archives-*. After setting the timestamp field, I finalize the index creation. Now, when navigating to the Discover section of Wazuh, I can select my newly created index and search for logs related to Mimikatz.\r\n\r\n## Troubleshooting Log Ingestion Issues\r\n\r\nIf events are still not visible, I perform troubleshooting by inspecting the archived log files in the Wazuh manager's CLI. By navigating to /var/ossec/logs/archives/, I list the available log files and use cat and grep commands to search for Mimikatz activity. If the logs are present in the archive but not appearing in the dashboard, it indicates a delay in ingestion, which resolves over time.\r\n\r\n## Conclusion\r\n\r\nThis session underscores the importance of proper log configuration and SIEM tuning. By ensuring that all relevant events are captured and making necessary adjustments, I enhance my detection capabilities. With my telemetry now successfully feeding into Wazuh, I am well-prepared for the final part of the series, where I will further refine my detection rules and automation workflows.\r\n\r\nStay Tuned.\r\n\r\nHere's the link to follow along: [SOC Automation Project](https://www.youtube.com/watch?v=amTtlN3uvFU&list=PLG6KGSNK4PuBWmX9NykU0wnWamjxdKhDJ&index=9)\r\n\r\n*Credit: This project was originally created by the MYDFIR YouTube channel. All structure and content was inspired by MYDFIR. Check his channel out: [@MyDFIR](https://www.youtube.com/@MyDFIR)*\r\n\r\n#CyberSecurity #SOCAnalyst #MYDFIR #HandsOnExperience #SecurityMonitoring #IncidentResponse ",
    "image": "/images/projects/soc-automation/soc-automation-project.png",
    "technologies": [],
    "images": [
      {
        "src": "/images/projects/soc-automation/part3/1 Editing ossec config file to ingest sysmon logs.png",
        "alt": "Editing Wazuh ossec.conf File to Ingest Sysmon Logs"
      },
      {
        "src": "/images/projects/soc-automation/part3/2 Sysmon service running on windows for telemetary generation.png",
        "alt": "Sysmon Service Running on Windows for Telemetry Generation"
      },
      {
        "src": "/images/projects/soc-automation/part3/3 Mimikatz downloaded and running on client pc.png",
        "alt": "Mimikatz Downloaded and Running on Client PC"
      },
      {
        "src": "/images/projects/soc-automation/part3/4 Creating index for archives to enable us search all ingested logs.png",
        "alt": "Creating Index for Archives to Search All Ingested Logs"
      },
      {
        "src": "/images/projects/soc-automation/part3/5 Configuring the wazuh ossec.conf file to take all logs of everything happening.png",
        "alt": "Configuring Wazuh to Log All Events"
      },
      {
        "src": "/images/projects/soc-automation/part3/6 changing filebeat config in order for wazuh to ingest logs into archives.png",
        "alt": "Modifying Filebeat Configuration for Log Archiving"
      },
      {
        "src": "/images/projects/soc-automation/part3/7 Mimikatz events logs now ingested into archives and visible on wazuh dashboard.png",
        "alt": "Mimikatz Event Logs Visible in Wazuh Dashboard"
      },
      {
        "src": "/images/projects/soc-automation/part3/8 Rule creation through sysmon targeting event id 1.png",
        "alt": "Creating Sysmon Rule for Event ID 1"
      },
      {
        "src": "/images/projects/soc-automation/part3/9 Crafting rule to detect mimikatz (RULE CRAFTED).png",
        "alt": "Crafting Detection Rule for Mimikatz"
      },
      {
        "src": "/images/projects/soc-automation/part3/10 Alert generated on wazuh on mimikatz usage.png",
        "alt": "Wazuh Alert Generated for Mimikatz Usage"
      }
    ],
    "series": {
      "name": "Project 2: SOC Automation Project",
      "part": 3,
      "totalParts": 3
    }
  },
  {
    "slug": "soc-automation-project-part1",
    "title": "Part 2: Infrastructure Setup",
    "description": "Setting up the core infrastructure components for our SOC automation environment including Wazuh, Windows client, and TheHive",
    "date": "2025-03-05",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "",
    "solution": "",
    "results": [],
    "category": "blue",
    "tags": [
      "Blue Team",
      "SOC",
      "Automation",
      "SIEM"
    ],
    "content": "\r\n# Part 2: Infrastructure Setup\r\n\r\nMy focus has shifted to establishing the core infrastructure and generating telemetry data for analysis, a critical foundation for any Security Operations Center (SOC). This phase involves setting up essential components including a Windows client, Wazuh server, and TheHive for comprehensive security monitoring and incident response.\r\n\r\n## Setting Up the Windows Environment\r\n\r\nI began the infrastructure deployment with a Windows 10 virtual machine, ensuring I had a proper endpoint for monitoring. Using VirtualBox to create the VM, I allocated appropriate resources and installed Windows 10 with the necessary configurations to support my security tools.\r\n\r\nSysmon, a critical component for endpoint monitoring, was installed using PowerShell with administrative privileges. This installation required careful attention to the placement of the configuration file and proper execution of the installation commands on Windows PowerShell. After installation, I verified Sysmon's presence through the Services console and Event Viewer, confirming it was actively monitoring system events.\r\n\r\n## Deploying Wazuh Server\r\n\r\nWith the endpoint ready, I moved to setting up the Wazuh server, my primary security monitoring platform. On the same VirtualBox, I deployed the Ubuntu 22.04 virtual machine. I also configured VirtualBox's network settings and set it to a bridged adapter to allow communication with my endpoint (Windows 10 OS).\r\n\r\nThe Wazuh installation process involved running their official installation script, which automatically configured the basic components. These included the indexer, server, and dashboard components, which form the core of Wazuh's security monitoring capabilities. The installation provided secure credentials for accessing the dashboard, which I carefully documented for future use.\r\n\r\nWazuh serves as the log manager and intrusion detection system. The setup begins by accessing the Wazuh dashboard and retrieving the necessary credentials for configuration. To integrate a Windows client, the agent configuration command is generated from the Wazuh dashboard, tailored to the server's IP. This command is then executed on the Windows machine, establishing a connection with the Wazuh server. Although this method didn't work for me after so many trials, I eventually had to use another method where I had to generate a key through the Wazuh agent manager on my Ubuntu terminal by running `/var/ossec/bin/manage_agents`. I then used the agent manager desktop interface on my Windows 10 to register the windows as an endpoint using the key generated. The client's status was then monitored and was active, and I could confirm telemetry was being successfully transmitted.\r\n\r\n## Configuring TheHive with Cassandra\r\n\r\nTheHive's efficiency depends heavily on its backend database, Cassandra. The configuration starts with modifying the Cassandra settings to align with the lab setup. This includes navigating to the configuration file and updating parameters like the cluster name and listen address to ensure proper connectivity. Restarting the Cassandra service and confirming its active status are crucial steps to ensure everything runs smoothly.\r\n\r\nTo integrate theHive with Cassandra, adjustments to the application settings file are required. This involves specifying the cluster name and database connection details. To avoid operational issues, it is vital to ensure that TheHive has the correct permissions to access necessary directories. Once configured, TheHive services are started, and the application becomes accessible through its designated URL.\r\n\r\nFor this section, I used a separate machine running Parrot operating system.\r\n\r\n## Establishing Connectivity\r\n\r\nAfter configuring all components, and confirming my endpoint status on my Wazuh dashboard as \"Active\", I focused on establishing proper connectivity between systems. The Windows agent was deployed to my Wazuh server, creating a secure communication channel for transmitting security events. Wazuh's role in the lab setup revolves around monitoring and alert generation. By installing Wazuh and connecting it to TheHive, alerts become actionable incidents for investigation. This is what I'll explore in further episodes of this post.\r\n\r\nI decided to test telemetry ingestion on my Wazuh server by creating a file document on my endpoint to see if I could see any alert related to the action, and it was a success.\r\n\r\n## Conclusion\r\n\r\nThrough these exercises, I've established a robust foundation for security monitoring and incident response. In the next chapter of this series, I will be going more in-depth with telemetry generation using Mimikatz, which is a powerful tool used for extracting credentials from Windows systems, I will learn how to send telemetry containing mimikatz, configure Wazuh to log all telemetry and craft custom rule to detect mimikatz usage. In further chapter, I will also explore the use of TheHive which I've just set up in the chapter.\r\n\r\nStay tuned.\r\n\r\nHere's the link to follow along: [SOC Automation Project](https://www.youtube.com/watch?v=VuSKMPRXN1M&list=PLG6KGSNK4PuBWmX9NykU0wnWamjxdKhDJ&index=8)\r\n\r\n*Credit: This project was originally created by the MYDFIR YouTube channel. All structure and content was inspired by MYDFIR. Check his channel out: [@MyDFIR](https://www.youtube.com/@MyDFIR)*\r\n\r\n#CyberSecurity #SOCAnalyst #MYDFIR #HandsOnExperience #SecurityMonitoring #IncidentResponse ",
    "image": "/images/projects/soc-automation/soc-automation-project.png",
    "technologies": [],
    "images": [
      {
        "src": "/images/projects/soc-automation/part2/1 Windows 10 virtual machine properties.png",
        "alt": "Windows 10 Virtual Machine Setup Properties"
      },
      {
        "src": "/images/projects/soc-automation/part2/2 Ubuntu OS Virtual Machine properties.png",
        "alt": "Ubuntu OS Virtual Machine Properties"
      },
      {
        "src": "/images/projects/soc-automation/part2/3 Wazuh Installation.png",
        "alt": "Wazuh Installation Process"
      },
      {
        "src": "/images/projects/soc-automation/part2/4 Deploying New Agent To Wazuh MAIN.png",
        "alt": "Deploying New Agent to Wazuh"
      },
      {
        "src": "/images/projects/soc-automation/part2/5 Generating Key For Newly Created Agent.png",
        "alt": "Generating Key for New Wazuh Agent"
      },
      {
        "src": "/images/projects/soc-automation/part2/6 Adding Agent Key to my wazuh manager on windows machine MAIN.png",
        "alt": "Adding Agent Key to Wazuh Manager on Windows"
      },
      {
        "src": "/images/projects/soc-automation/part2/7 Wazuh Login Page.png",
        "alt": "Wazuh Dashboard Login Page"
      },
      {
        "src": "/images/projects/soc-automation/part2/8 The Hive Installation in Parrot.png",
        "alt": "TheHive Installation in Parrot OS"
      },
      {
        "src": "/images/projects/soc-automation/part2/9 Cassandra Installation in Parrot.png",
        "alt": "Cassandra Installation in Parrot OS"
      },
      {
        "src": "/images/projects/soc-automation/part2/10 TheHive Configuration.png",
        "alt": "TheHive Configuration Setup"
      },
      {
        "src": "/images/projects/soc-automation/part2/11 Changing RPC Address in Cassandra.png",
        "alt": "Configuring RPC Address in Cassandra"
      },
      {
        "src": "/images/projects/soc-automation/part2/12 Changing Listening address in Cassandra.png",
        "alt": "Setting Cassandra Listening Address"
      },
      {
        "src": "/images/projects/soc-automation/part2/13 Thehive service started.png",
        "alt": "TheHive Service Successfully Started"
      },
      {
        "src": "/images/projects/soc-automation/part2/14 TheHive Loginpage.png",
        "alt": "TheHive Login Page"
      },
      {
        "src": "/images/projects/soc-automation/part2/15 Wazuh agent dashboard with Active agent MAIN.png",
        "alt": "Wazuh Agent Dashboard Showing Active Agent"
      },
      {
        "src": "/images/projects/soc-automation/part2/16 Sample file creation for FILE MONITORING.png",
        "alt": "Testing File Monitoring with Sample File Creation"
      },
      {
        "src": "/images/projects/soc-automation/part2/17 Alert for file added to endpoint on wazuh.png",
        "alt": "Wazuh Alert for File Addition on Endpoint"
      }
    ],
    "series": {
      "name": "Project 2: SOC Automation Project",
      "part": 2,
      "totalParts": 3
    }
  },
  {
    "slug": "soc-automation-project",
    "title": "Part 1: Planning the Infrastructure",
    "description": "Building a home lab SOC environment for hands-on experience with SOAR tools like Wazuh, The Hive, and Shuffle.",
    "date": "2024-11-30",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "Gaining practical experience in SOC tasks like alert management, response actions, and data enrichment using a functional SOAR setup.",
    "solution": "Building a home lab environment from scratch, diagramming the architecture, and planning the deployment of Wazuh, The Hive, and Shuffle for event logging, alert triggering/enrichment, and case management.",
    "results": [
      "Planned the SOC lab infrastructure",
      "Created a logical flow diagram using Draw.io",
      "Outlined the main workflow from event generation to case management",
      "Mapped alert flow using color-coded connections"
    ],
    "category": "blue",
    "tags": [
      "Blue Team",
      "SIEM",
      "SOAR"
    ],
    "content": "\r\n# Part 1: Planning the Infrastructure\r\n\r\nAs I continue my journey into cybersecurity, I've embarked on a SOC Automation Project aimed at building a home lab environment from scratch. The ultimate goal is to create a fully functional Security Orchestration, Automation, and Response (SOAR) setup, with tools like Wazuh, The Hive, and Shuffle for case management and automation. This project will enable hands-on experience critical for Security Operations Center (SOC) tasks, providing a foundation for alert management, response actions, and data enrichment.\r\n\r\n## Diagramming the Lab Environment\r\n\r\nThis week, I began by visualizing the lab's architecture, which will guide deploying various SOC components. Using Draw.io, I created a logical flow diagram, depicting the interaction of key elements like a Windows 10 client with Wazuh and SOAR tools (The Hive and Shuffle) across different network layers. This visual roadmap is crucial, as many cybersecurity interviews require candidates to whiteboard a secure lab setup—a skill that this project will reinforce.\r\n\r\n## The main workflow consists of:\r\n\r\n1. **Event Generation**: The Windows 10 client will send event logs to Wazuh, acting as the lab's SIEM system. This data flow simulates the information-sharing pipeline from the endpoint to SIEM.\r\n2. **Alert Triggering and Enrichment**: Wazuh will analyze these events and generate alerts, which are then forwarded to Shuffle for enrichment with open-source intelligence (OSINT).\r\n3. **Case Management**: Finally, the enriched data and actionable alerts will be logged in The Hive, streamlining incident tracking and case management.\r\n\r\n## Connecting the Dots\r\n\r\nTo logically map how alerts will flow, color-coded connections will be implemented in the diagram to track data from generation, through analysis, to final case management. For example, alerts from Wazuh to Shuffle are labeled in blue, indicating a \"send alert\" action, while OSINT data flows in green to enrich the incident context. These connections provide a cohesive view of how data travels within the SOC environment, aligning the diagram to real-world incident workflows.\r\n\r\n## Future Plans\r\n\r\nIn my upcoming posts, I'll move into deploying these tools on virtual machines, configuring Wazuh and The Hive, and connecting them with my local workstation. This setup will allow me to simulate common security alerts, test case management processes, and refine my incident response workflows.\r\n\r\nStay tuned as I document each stage, including implementation challenges, configurations, and SOC analysis techniques.\r\n\r\nHere's the link to follow along: [SOC Automation Project](https://www.youtube.com/watch?v=XR3eamn8ydQ&list=PLG6KGSNK4PuBWmX9NykU0wnWamjxdKhDJ&index=6)\r\n\r\n*Credit: This project was originally created by the MYDFIR YouTube channel. All structure and content was inspired by MYDFIR. Check his channel out: [@MyDFIR](https://www.youtube.com/@MyDFIR)*\r\n\r\n#MYDFIR #CyberSecurity #SOCAnalyst #HomeLab #Automation #HandsOnExperience\r\n\\`",
    "image": "/images/projects/soc-automation/soc-automation-project.png",
    "technologies": [
      "Wazuh",
      "The Hive",
      "Shuffle",
      "Windows 10",
      "Draw.io"
    ],
    "images": [
      {
        "src": "/images/projects/soc-automation/detailed-workflow.png",
        "alt": "Detailed SOC Automation Workflow showing connections between Wazuh, Shuffle, TheHive and other components"
      },
      {
        "src": "/images/projects/soc-automation/simple-workflow.png",
        "alt": "Simplified SOC Automation Workflow diagram showing the basic data flow between components"
      }
    ],
    "series": {
      "name": "Project 2: SOC Automation Project",
      "part": 1,
      "totalParts": 3
    }
  },
  {
    "slug": "30-day-soc-analyst-challenge-part30",
    "title": "Part 30: Conclusion of the 30-Day MyDFIR SOC Analyst Challenge",
    "description": "Day 30 of the 30-Day MYDFIR SOC Analyst Challenge: Reflecting on the journey and key learnings in SOC operations and cybersecurity.",
    "date": "2024-11-30",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "",
    "solution": "",
    "results": [],
    "category": "blue",
    "tags": [
      "Conclusion",
      "SOC",
      "Security",
      "Learning",
      "Career Development"
    ],
    "content": "\r\n## Day 30 of the 30-Day MyDFIR SOC Analyst Challenge: Conclusion\r\n\r\n## Overview\r\n\r\nAs I complete the 30-Day MyDFIR SOC Analyst Challenge, the journey has significantly deepened my understanding of SOC operations and cybersecurity best practices. Over these 30 days, I've worked with key tools, investigated real-world threats, and honed my incident response skills. Here's a recap of the most valuable lessons from this experience.\r\n\r\n## Setting Up the Foundation: Elasticsearch, Kibana, and OS Ticket\r\n\r\nThe challenge began with setting up the core tools for a functional SOC environment: Elasticsearch and Kibana. These tools allowed me to collect, visualize, and analyze security data. I learned how to create dashboards that provided real-time insights into:\r\n- Brute-force attacks\r\n- Login attempts\r\n- Suspicious RDP activity\r\n\r\nIntegrating OS Ticket into my environment was a significant milestone, as it automated incident management, ensuring every alert was systematically tracked and addressed.\r\n\r\n## Advanced Detection and Response\r\n\r\nAs the challenge progressed, I encountered various real-world attack simulations. Investigating brute-force attacks—both SSH and RDP—taught me the importance of:\r\n- Log analysis\r\n- IP reputation checking\r\n- Using tools like AbuseIPDB and GreyNoise\r\n\r\nI gained hands-on experience in identifying and responding to malicious activity. Automating ticket creation for brute-force alerts streamlined the incident-handling process, reinforcing how crucial automation is in a fast-paced SOC environment.\r\n\r\n## Command and Control (C2) Detection\r\n\r\nA key highlight of the challenge was investigating the Mythic C2 framework, which provided insight into how attackers use Command and Control (C2) agents to maintain access to compromised systems. I utilized:\r\n- Network telemetry\r\n- Tools like RITA to identify beaconing behavior\r\n- Process creation logs\r\n\r\nThis experience demonstrated the importance of understanding network traffic and process creation logs in detecting persistent threats.\r\n\r\n## Endpoint Security with Elastic Defend\r\n\r\nOne of the most critical components of the challenge was deploying Elastic Defend for endpoint detection and response (EDR). By testing:\r\n- Malware detection\r\n- Host isolation\r\n- Telemetry data analysis\r\n\r\nI experienced firsthand how EDR solutions play a vital role in securing endpoints. I explored Elastic's telemetry data to investigate threats more deeply and learned how to prevent and mitigate attacks by quarantining malicious files and isolating compromised hosts.\r\n\r\n## Looking Ahead\r\n\r\nA big thank you to [@MyDFIR](https://www.youtube.com/@MyDFIR) for creating this challenge. It provided invaluable hands-on experience, deepened my technical skills, and gave me valuable insights into the day-to-day work of a SOC analyst. The challenge has equipped me with practical skills in:\r\n- Threat detection\r\n- Incident response\r\n- Endpoint security\r\n\r\nThis journey has reinforced my passion for cybersecurity, and I'm eager to continue growing as a SOC analyst.\r\n\r\n*Credit: This project was originally created by the MYDFIR YouTube channel. All structure and content was inspired by MYDFIR. Check his channel out: [@MyDFIR](https://www.youtube.com/@MyDFIR)*\r\n\r\n#MyDFIR #SOCAnalyst #MYDFIRChallenge ",
    "image": "/images/projects/30-day-soc-analyst-challenge.png",
    "technologies": [],
    "images": [
      {
        "src": "/images/projects/30-day-challenge/30Days-MYDFIR-Challenge.png",
        "alt": "30 Days MYDFIR SOC Analyst Challenge"
      }
    ],
    "series": {
      "name": "Project 3: 30-Day MYDFIR SOC Analyst Challenge",
      "part": 30,
      "totalParts": 30
    }
  },
  {
    "slug": "30-day-soc-analyst-challenge-part29",
    "title": "Part 29: Installing and Exploring Elastic Defend on Windows Server",
    "description": "Day 29 of the 30-Day MYDFIR SOC Analyst Challenge: Setting up and testing Elastic Defend EDR solution for comprehensive endpoint protection.",
    "date": "2024-11-29",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "",
    "solution": "",
    "results": [],
    "category": "blue",
    "tags": [
      "Elastic Defend",
      "EDR",
      "SOC",
      "Security",
      "Windows Server"
    ],
    "content": "\r\n## Day 29 of the 30-Day MyDFIR SOC Analyst Challenge: Installing and Exploring Elastic Defend on Windows Server\r\n\r\n## Overview\r\n\r\nOn Day 29, I focused on Elastic's Endpoint Detection and Response (EDR) tool—Elastic Defend. This powerful EDR solution offers comprehensive endpoint protection and valuable telemetry to help monitor and respond to threats.\r\n\r\n## Setting Up Elastic Defend\r\n\r\nElastic Defend is part of the Elastic Stack, and with the free 30-day trial, I could unlock additional features like full telemetry and host isolation. To get started, I accessed the Integrations section in Elastic, From there, I added Elastic Defend to my environment. Elastic Defend offers several configuration options, including:\r\n- Data Collection\r\n- Next-Gen Antivirus\r\n- Essential EDR\r\n- Complete EDR\r\n\r\nFor this challenge, I chose Complete EDR, I then deployed Elastic Defend to my Windows Server using a Fleet server, allowing centralized management of multiple endpoints.\r\n\r\n## Monitoring and Testing\r\n\r\nWith Elastic Defend successfully installed, I checked the Security section in Kibana to ensure the endpoint appeared, confirming the agent was active. Elastic Defend offers multiple actions, including the ability to isolate the host, which is available with the trial version.\r\n\r\nI wanted to test Elastic Defend's malware detection capabilities, so I ran the pilotvader.exe process on my Windows Server, simulating a malicious action. As expected, Elastic Defend instantly flagged and blocked the file. A message appeared stating that the operation couldn't be completed because the file contained a virus, and I received a malware prevention alert confirming the file had been quarantined.\r\n\r\n## Investigating Telemetry\r\n\r\nTo dive deeper, I went into the Discover tab in Kibana and filtered the logs to view recent events. There, I found the malware prevention alert with detailed information about the malicious file, including:\r\n- File hash\r\n- Quarantine path\r\n- Directory (C:\\Users\\Public\\Downloads)\r\n\r\nIn the Security tab, I also explored the process tree, which showed the relationship between the legitimate explorer.exe process and the blocked pilotvader.exe. If the malware had spawned other processes, they would have also appeared here.\r\n\r\n## Isolating the Host\r\n\r\nNext, I tested Elastic Defend's host isolation feature. After initiating an infinite ping to Google's DNS (8.8.8.8), I re-downloaded the malicious file, which Elastic Defend promptly quarantined again. Soon after, the host was isolated, demonstrating Elastic Defend's ability to take responsive action against threats.\r\n\r\n## Conclusion\r\n\r\nDay 29 was a valuable deep dive into Elastic Defend. I learned how to install, monitor, and test its EDR capabilities, reinforcing its importance for endpoint security. I'll wrap up the challenge tomorrow by reviewing troubleshooting techniques and fine-tuning detection strategies.\r\n\r\nHere's the link to follow along: [30-Day MYDFIR SOC Analyst Challenge](https://www.youtube.com/watch?v=Ec-Ab8TbJKs&list=PLG6KGSNK4PuBWmX9NykU0wnWamjxdKhDJ&index=56)\r\n\r\n*Credit: This project was originally created by the MYDFIR YouTube channel. All structure and content was inspired by MYDFIR. Check his channel out: [@MyDFIR](https://www.youtube.com/@MyDFIR)*\r\n\r\n#CyberSecurity #SOCAnalyst #MYDFIRChallenge #HandsOnExperience #Day29 ",
    "image": "/images/projects/30-day-soc-analyst-challenge.png",
    "technologies": [],
    "images": [
      {
        "src": "/images/projects/30-day-challenge/30-days-day-29.png",
        "alt": "30 Days MYDFIR SOC Analyst Challenge Day 29"
      }
    ],
    "series": {
      "name": "Project 3: 30-Day MYDFIR SOC Analyst Challenge",
      "part": 29,
      "totalParts": 30
    }
  },
  {
    "slug": "30-day-soc-analyst-challenge-part28",
    "title": "Part 28: Investigating the Mythic C2 Framework",
    "description": "Day 28 of the 30-Day MYDFIR SOC Analyst Challenge: Analyzing and investigating Command and Control (C2) framework activities using network telemetry and process logs.",
    "date": "2024-11-28",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "",
    "solution": "",
    "results": [],
    "category": "blue",
    "tags": [
      "C2",
      "Mythic",
      "SOC",
      "Security",
      "Investigation"
    ],
    "content": "\r\n## Day 28 of the 30-Day MyDFIR SOC Analyst Challenge: Investigating the Mythic C2 Framework\r\n\r\n## Overview\r\n\r\nOn Day 28 of the 30-Day MyDFIR SOC Analyst Challenge, I shifted my focus to the Mythic Command and Control (C2) framework. Attackers widely use this framework to maintain control over compromised systems, allowing them to execute commands, steal data, and conduct other malicious activities without detection. My task was to investigate how the Mythic agent svchost_pilotvader.exe operated and how its communication could be detected.\r\n\r\n## Tracing the Mythic C2 Agent\r\n\r\nMy investigation's first step was locating the Mythic C2 agent on one of the compromised systems. Armed with the knowledge of the agent's name, I used the Kibana Discover tool to search through the logs, narrowing the time range to the past 30 days. This allowed me to pinpoint 25 distinct events associated with the agent. Sorting these events chronologically, I was able to reconstruct the timeline of the agent's activity, gaining critical insight into how it interacted with the system over time.\r\n\r\n## Identifying C2 Traffic Through Network Telemetry\r\n\r\nIn cases where the agent's name isn't known, identifying suspicious traffic can be challenging. Network telemetry analysis plays a critical role in detecting C2 activity. I began by analyzing network logs to identify the \"top talkers\"—the machines that generated the most traffic. Since Mythic, like most C2 frameworks, relies on consistent communication between the infected host and the attacker's server, unusual traffic patterns often stand out.\r\n\r\nTo refine my detection, I utilized RITA (Real Intelligence Threat Analytics), a tool designed to detect beaconing behavior in C2 traffic. Beaconing occurs when an infected machine regularly checks in with a C2 server, and identifying these intervals allowed me to isolate Mythic's communication patterns. The detection of this regular network activity provided strong evidence of the C2 framework's presence.\r\n\r\n## Investigating Process Creation Logs\r\n\r\nBeyond network traffic, process creation analysis was essential for tracing the agent's activity. By examining these logs, I could see the exact processes initiated by the Mythic agent and track the attacker's movement within the system. These logs offer a detailed view of how the agent behaves, from its initial execution to spawning other processes critical to maintaining control over the system.\r\n\r\n## Conclusion\r\n\r\nDay 28's deep dive into the Mythic C2 framework offered valuable lessons in tracking adversary behavior. By leveraging network telemetry, beaconing detection, and process creation logs, I was able to uncover the activities of the Mythic agent and better understand its communication patterns. As the challenge nears its end, these investigations continue to hone my skills in threat detection and incident response.\r\n\r\nHere's the link to follow along: [30-Day MYDFIR SOC Analyst Challenge](https://www.youtube.com/watch?v=b11TuDx_CjU&list=PLG6KGSNK4PuBWmX9NykU0wnWamjxdKhDJ&index=55)\r\n\r\n*Credit: This project was originally created by the MYDFIR YouTube channel. All structure and content was inspired by MYDFIR. Check his channel out: [@MyDFIR](https://www.youtube.com/@MyDFIR)*\r\n\r\n#CyberSecurity #SOCAnalyst #MYDFIRChallenge #HandsOnExperience #Day28 ",
    "image": "/images/projects/30-day-soc-analyst-challenge.png",
    "technologies": [],
    "images": [
      {
        "src": "/images/projects/30-day-challenge/30-days-day-28.png",
        "alt": "30 Days MYDFIR SOC Analyst Challenge Day 28"
      }
    ],
    "series": {
      "name": "Project 3: 30-Day MYDFIR SOC Analyst Challenge",
      "part": 28,
      "totalParts": 30
    }
  },
  {
    "slug": "30-day-soc-analyst-challenge-part27",
    "title": "Part 27: Investigating an RDP Brute Force Attack",
    "description": "Day 27 of the 30-Day MYDFIR SOC Analyst Challenge: Analyzing and investigating RDP brute force attacks using security tools and automated ticketing.",
    "date": "2024-11-27",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "",
    "solution": "",
    "results": [],
    "category": "blue",
    "tags": [
      "RDP",
      "Brute Force",
      "SOC",
      "Security",
      "Investigation"
    ],
    "content": "\r\n## Day 27 of the 30-Day MYDFIR SOC Analyst Challenge: Investigating an RDP Brute Force Attack\r\n\r\n## Overview\r\n\r\nOn Day 27 of my 30-Day MYDFIR SOC Analyst Challenge, I shifted focus to investigating an RDP brute force attack alert. The process follows a similar methodology to investigating an SSH brute force attack, with the only major difference being the protocol in question. Here's how I broke it down.\r\n\r\n## Reviewing the Alert\r\n\r\nI started by navigating to the alerts section in my web interface, filtering for RDP brute force alerts. Out of 327 total alerts, I found 5 related to RDP brute force. I selected one of the alerts and also took note of the source IP, which had a username attempt of \"administrator.\" There were 5 events in total, so I dug deeper into the details.\r\n\r\n## Automating Ticket Creation in OS Ticket\r\n\r\nBecause I had already set up an automated ticket creation system for SSH brute force alerts, I decided to replicate the process for this RDP alert. Using the existing SSH rule, I copied the webhook details and applied them to the RDP brute force rule. This allowed me to automatically generate a ticket within OS Ticket whenever an RDP brute force attack is detected.\r\n\r\n## Investigating the IP Address\r\n\r\nFor the next steps, I wanted to gather more information about the attacking IP address. First, I used AbuseIPDB, which revealed that the IP had been reported 71 times, with a 63% confidence score of malicious activity, mostly relating to RDP brute force attempts. Then, I checked GreyNoise, which classified the IP as \"unknown intent,\" meaning it was engaged in internet-wide scanning but not specifically targeting my environment. This data gave me enough confidence to mark the IP as associated with RDP brute force activity.\r\n\r\n## Analyzing for Affected Users\r\n\r\nI next wanted to see if any other users were targeted by the attacker. After filtering my logs for the past 30 days, I found 271 events related to this IP, but all of them were focused on the \"administrator\" account. This confirmed that no other user accounts had been affected.\r\n\r\n## Checking for Successful Logins\r\n\r\nA crucial part of any brute force investigation is determining whether the attacker was successful. In this case, I looked for Windows event code 4624, which indicates a successful login. Fortunately, there were no successful authentication attempts from this IP address, so I could confirm that the attack had failed.\r\n\r\n## Conclusion\r\n\r\nEven though there were no successful logins in this case, the investigation served as a good reminder of the importance of thorough log review and automated alerting. In the next step of this challenge, I'll be diving deeper into another investigation, this time analyzing activity from the Mythic C2 agent. Stay tuned for more insights!\r\n\r\nHere's the link to follow along: [30-Day MYDFIR SOC Analyst Challenge](https://www.youtube.com/watch?v=l9KA6dPdOs8&list=PLG6KGSNK4PuBWmX9NykU0wnWamjxdKhDJ&index=54)\r\n\r\n*Credit: This project was originally created by the MYDFIR YouTube channel. All structure and content was inspired by MYDFIR. Check his channel out: [@MyDFIR](https://www.youtube.com/@MyDFIR)*\r\n\r\n#CyberSecurity #SOCAnalyst #MYDFIRChallenge #HandsOnExperience #Day27 ",
    "image": "/images/projects/30-day-soc-analyst-challenge.png",
    "technologies": [],
    "images": [
      {
        "src": "/images/projects/30-day-challenge/30-days-day-27.png",
        "alt": "30 Days MYDFIR SOC Analyst Challenge Day 27"
      }
    ],
    "series": {
      "name": "Project 3: 30-Day MYDFIR SOC Analyst Challenge",
      "part": 27,
      "totalParts": 30
    }
  },
  {
    "slug": "30-day-soc-analyst-challenge-part26",
    "title": "Part 26: Investigating an SSH Brute Force Alert",
    "description": "Day 26 of the 30-Day MYDFIR SOC Analyst Challenge: Analyzing and investigating SSH brute force attacks using security tools and threat intelligence.",
    "date": "2024-11-26",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "",
    "solution": "",
    "results": [],
    "category": "blue",
    "tags": [
      "SSH",
      "Brute Force",
      "SOC",
      "Security",
      "Investigation"
    ],
    "content": "\r\n## Day 26 of the 30-Day MyDFIR SOC Analyst Challenge: Investigating an SSH Brute Force Alert\r\n\r\n## Overview\r\n\r\nOn Day 26 of the 30-Day MyDFIR SOC Analyst Challenge, I focused on investigating an SSH Brute Force alert, which is a common attack that tries to gain unauthorized access to a server by repeatedly guessing login credentials. This was a great opportunity to apply some detection tools I've set up throughout this challenge.\r\n\r\n## Investigating the SSH Brute Force Alert\r\n\r\nThe first step in my investigation was to navigate to the \"Alerts\" section in Kibana under the security tab. I had several alerts, so I selected the most recent one, which occurred on September 17th. This alert flagged multiple failed login attempts to the root account from a specific IP address. The next step was to investigate the context behind this alert and understand whether this was a serious threat or just background noise.\r\n\r\n## Checking the IP Address Reputation\r\n\r\nTo determine if the IP address in question was known for malicious activity, I used AbuseIPDB, a reliable source for checking the reputation of IP addresses. Sure enough, the IP had been flagged for abusive behavior over 2000 times, and the reports highlighted failed password attempts, indicating brute-force activity. I also turned to GreyNoise, which further confirmed that the IP was malicious, labeling it as an SSH brute-forcer and showing associated tags for malicious behavior. This gave me enough confidence to mark the IP as a known attacker.\r\n\r\n## Analyzing Affected Users\r\n\r\nNext, I needed to understand if the IP had targeted other users. I ran a query in Kibana to see the scope of the attack over the past 30 days. The results showed that the IP had attempted to brute force multiple users, including:\r\n- Root account\r\n- Oracle account\r\n- Guest account\r\n- Test accounts\r\n\r\nKnowing which accounts were targeted helped me gauge the scale of the attack.\r\n\r\n## Checking for Successful Logins\r\n\r\nA critical step in the investigation was checking if any of the brute-force attempts had been successful. I searched the logs for successful login attempts but found none. This was a relief because, if successful, the attacker could have caused significant damage by executing commands or downloading malicious scripts.\r\n\r\n## Conclusion\r\n\r\nWith no successful login attempts and the IP flagged as malicious, I felt confident in closing the alert. In a real-world environment, I would document all my findings in the ticketing system and follow up with any necessary changes to ensure similar alerts are handled promptly. This investigation helped reinforce my understanding of SSH brute-force attacks and the importance of monitoring for suspicious activity.\r\n\r\nHere's the link to follow along: [30-Day MYDFIR SOC Analyst Challenge](https://www.youtube.com/watch?v=sXQ1hsAFX7U&list=PLG6KGSNK4PuBWmX9NykU0wnWamjxdKhDJ&index=53)\r\n\r\n*Credit: This project was originally created by the MYDFIR YouTube channel. All structure and content was inspired by MYDFIR. Check his channel out: [@MyDFIR](https://www.youtube.com/@MyDFIR)*\r\n\r\n#CyberSecurity #SOCAnalyst #MYDFIRChallenge #Day26 #HandsOnExperience #BruteForce ",
    "image": "/images/projects/30-day-soc-analyst-challenge.png",
    "technologies": [],
    "images": [
      {
        "src": "/images/projects/30-day-challenge/30-days-day-26.png",
        "alt": "30 Days MYDFIR SOC Analyst Challenge Day 26"
      }
    ],
    "series": {
      "name": "Project 3: 30-Day MYDFIR SOC Analyst Challenge",
      "part": 26,
      "totalParts": 30
    }
  },
  {
    "slug": "30-day-soc-analyst-challenge-part25",
    "title": "Part 25: Integrating OS Ticket with Elastic Stack",
    "description": "Day 25 of the 30-Day MYDFIR SOC Analyst Challenge: Setting up integration between OS Ticket and Elastic Stack for automated alert ticketing.",
    "date": "2024-11-25",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "",
    "solution": "",
    "results": [],
    "category": "blue",
    "tags": [
      "OS Ticket",
      "Elastic Stack",
      "SOC",
      "Security",
      "Integration"
    ],
    "content": "\r\n## Day 25 of the 30-Day MyDFIR SOC Analyst Challenge: Integrating OS Ticket with Elastic Stack\r\n\r\n## Overview\r\n\r\nOn Day 25 of the 30-Day MyDFIR SOC Analyst Challenge, I focused on integrating OS Ticket into my Elastic Stack environment. This integration allows for a more streamlined workflow, automatically creating tickets for alerts generated by Elastic. Here's how I approached it.\r\n\r\n## Setting Up the API Key in OS Ticket\r\n\r\nTo start, I accessed the OS Ticket control panel and created a new API key. Since both my OS Ticket and Elastic Stack servers are hosted within the same Virtual Private Cloud (VPC), I used the private IP address of my Elastic Stack server for this configuration. If your servers are in different environments, you'd use the public IP instead.\r\n\r\nOnce I had the correct IP address, I configured the API key to allow ticket creation. With the key ready, I copied it into a notepad for easy reference during the Elastic setup.\r\n\r\n## Configuring the Connector in Elastic Stack\r\n\r\nNext, I moved to the Elastic Stack interface. From Stack Management, I navigated to the Connectors section. To enable the integration, I needed to activate Elastic's 30-day free trial, which allows the use of APIs. Once the trial was active, I created a new webhook connector, giving it a name like \"OS Ticket.\"\r\n\r\nThe connector required:\r\n- The OS Ticket server's IP address\r\n- The API key I had generated earlier\r\n- Necessary authentication headers\r\n\r\nI added this information and then tested the connection. Initially, there was a network issue that required troubleshooting, but I later identified that the problem was with the private IP configuration on the OS Ticket server.\r\n\r\n## Resolving Network Issues\r\n\r\nUpon inspecting the OS Ticket server, I realized it was using a public IP rather than the private IP necessary for my setup. After correcting the network configuration and assigning the correct private IP address, the connection between Elastic Stack and OS Ticket was established successfully. A quick test confirmed that the integration was functioning as expected, with alerts now automatically generating tickets in OS Ticket.\r\n\r\n## Conclusion\r\n\r\nWith OS Ticket fully integrated into my Elastic environment, I've added another layer of automation to my SOC setup. This integration will improve incident tracking and alert management, making the process more efficient. In the coming days, I'll shift focus to investigating alerts, beginning with SSH brute force detection.\r\n\r\nHere's the link to follow along: [30-Day MYDFIR SOC Analyst Challenge](https://www.youtube.com/watch?v=P9YxutqWAF0&list=PLG6KGSNK4PuBWmX9NykU0wnWamjxdKhDJ&index=52)\r\n\r\n*Credit: This project was originally created by the MYDFIR YouTube channel. All structure and content was inspired by MYDFIR. Check his channel out: [@MyDFIR](https://www.youtube.com/@MyDFIR)*\r\n\r\n#CyberSecurity #SOCAnalyst #MYDFIRChallenge #HandsOnExperience #Day25 ",
    "image": "/images/projects/30-day-soc-analyst-challenge.png",
    "technologies": [],
    "images": [
      {
        "src": "/images/projects/30-day-challenge/1-30-days-day-25.png",
        "alt": "30 Days MYDFIR SOC Analyst Challenge Day 25"
      },
      {
        "src": "/images/projects/30-day-challenge/2-Screenshot-2024-09-25-204517.png",
        "alt": "OS Ticket API Configuration"
      },
      {
        "src": "/images/projects/30-day-challenge/3-Screenshot-2024-09-25-204554.png",
        "alt": "Elastic Stack Connector Setup"
      }
    ],
    "series": {
      "name": "Project 3: 30-Day MYDFIR SOC Analyst Challenge",
      "part": 25,
      "totalParts": 30
    }
  },
  {
    "slug": "30-day-soc-analyst-challenge-part24",
    "title": "Part 24: Setting Up and Configuring OS Ticket",
    "description": "Day 24 of the 30-Day MYDFIR SOC Analyst Challenge: Deploying and configuring OS Ticket on a Windows Server for efficient SOC alert management.",
    "date": "2024-11-24",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "",
    "solution": "",
    "results": [],
    "category": "blue",
    "tags": [
      "OS Ticket",
      "XAMPP",
      "SOC",
      "Security",
      "Windows Server"
    ],
    "content": "\r\n## Day 24 of the 30-Day MyDFIR SOC Analyst Challenge: Setting Up and Configuring OS Ticket\r\n\r\n## Overview\r\n\r\nOn Day 24 of the 30-Day MyDFIR SOC Analyst Challenge! I'll dive into OS Ticket, a ticketing system that will be an essential tool for my SOC operations. The aim is to set up OS Ticket successfully and configure it on a Windows Server. This system will streamline ticket management for the alerts we'll deal with throughout the challenge. Let's get started!\r\n\r\n## Deploying the Server\r\n\r\nThe first step in setting up OS Ticket is to deploy a server. I used Vulture for this process, selecting \"Cloud Compute\" with a shared CPU and Windows Server 2022. The server specifications don't need to be too powerful; I chose 1 CPU and 2 GB of memory. After selecting a location and setting up firewall configurations, the server was ready for Remote Desktop Protocol (RDP) access.\r\n\r\n## Setting Up the Web Server\r\n\r\nOnce connected to the server, I installed XAMPP, a free and open-source cross-platform web server solution. XAMPP makes it easy to set up Apache, MySQL, and PHP, all necessary for OS Ticket to function. After downloading XAMPP, I configured it by:\r\n\r\n- Changing the Apache domain name to my server's public IP address\r\n- Modifying the phpMyAdmin configuration to ensure secure access from my SOC analyst laptop\r\n\r\n## Configuring Firewall Rules\r\n\r\nBefore moving further, I created inbound firewall rules for ports 80 and 443. This ensures that only authorized devices can access the web server. With XAMPP running, I started both the Apache and MySQL services and verified that everything was configured correctly.\r\n\r\n## Installing OS Ticket\r\n\r\nNext, I downloaded OS Ticket from their official site, choosing the latest stable version. After extracting the files, I moved them to the XAMPP htdocs folder to be served by the Apache server. Once the web server was up and running, I accessed the OS Ticket setup page, which prompted me to configure the system. This included:\r\n\r\n- Renaming configuration files\r\n- Setting up a MySQL database for OS Ticket to store data\r\n\r\n## Finalizing the Installation\r\n\r\nWith the database created and the necessary configurations in place, the final step was to run the OS Ticket installation. After entering admin details and configuring the database connection, the OS Ticket was successfully installed. I also ensured file permissions were properly set for security.\r\n\r\n## Conclusion\r\n\r\nWith this system, I'll be able to manage SOC alerts efficiently. Up next, I'll explore how to integrate OS Ticket with my tech stack so that alerts automatically generate tickets.\r\n\r\nHere's the link to follow along: [30-Day MYDFIR SOC Analyst Challenge](https://www.youtube.com/watch?v=xgxQuLL33oU&list=PLG6KGSNK4PuBWmX9NykU0wnWamjxdKhDJ&index=51)\r\n\r\n*Credit: This project was originally created by the MYDFIR YouTube channel. All structure and content was inspired by MYDFIR. Check his channel out: [@MyDFIR](https://www.youtube.com/@MyDFIR)*\r\n\r\n#CyberSecurity #SOCAnalyst #OSSTicket #MyDFIRChallenge #Day24 ",
    "image": "/images/projects/30-day-soc-analyst-challenge.png",
    "technologies": [],
    "images": [
      {
        "src": "/images/projects/30-day-challenge/1-30-days-day-24.png",
        "alt": "30 Days MYDFIR SOC Analyst Challenge Day 24"
      },
      {
        "src": "/images/projects/30-day-challenge/2-Screenshott.png",
        "alt": "Server Deployment Configuration"
      },
      {
        "src": "/images/projects/30-day-challenge/3-Screenshot.png",
        "alt": "XAMPP Installation and Setup"
      },
      {
        "src": "/images/projects/30-day-challenge/4-Screenshot.png",
        "alt": "OS Ticket Installation Process"
      },
      {
        "src": "/images/projects/30-day-challenge/5-Screenshot.png",
        "alt": "OS Ticket Configuration"
      }
    ],
    "series": {
      "name": "Project 3: 30-Day MYDFIR SOC Analyst Challenge",
      "part": 24,
      "totalParts": 30
    }
  },
  {
    "slug": "building-cybersecurity-home-lab-part2",
    "title": "Part 2: Generating Telemetry and Analyzing Attacks",
    "description": "Generating telemetry and analyzing attacks in our cybersecurity home lab.",
    "date": "2024-11-23",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "Generate and analyze telemetry data to detect malicious activities.",
    "solution": "Used Nmap for reconnaissance, Metasploit for attack simulation, and Splunk for log analysis.",
    "results": [
      "Successfully generated attack telemetry",
      "Implemented attack detection capabilities",
      "Gained hands-on experience with security tools"
    ],
    "category": "blue",
    "tags": [
      "Blue Team",
      "Home Lab",
      "SIEM"
    ],
    "content": "\r\n# Part 2: Generating Telemetry and Analyzing Attacks\r\n\r\nMy focus has shifted to generating telemetry data for analysis, a critical step in detecting malicious activities.\r\n\r\n## Scanning with Nmap\r\n\r\nI started the telemetry generation process with Nmap. This enabled me to conduct a comprehensive scan of my Windows VM, identifying open ports and services that could be potential attack vectors. This reconnaissance phase helped me understand the attack surface and assess vulnerabilities within my environment.\r\n\r\nThe scan revealed several open ports, notably Port 3389, associated with Remote Desktop Protocol (RDP). Identifying such services is crucial as they can serve as entry points for attackers seeking to exploit system weaknesses.\r\n\r\n## Crafting Malware with Metasploit\r\n\r\nAfter reconnaissance, I shifted to creating a simulated attack using Metasploit, a widely used framework for penetration testing. I crafted a reverse shell payload, a common technique used by attackers to gain unauthorized access to target systems. This exercise provided insight into the attack lifecycle and how malicious actors exploit systems.\r\n\r\nWith the malicious executable ready, I set up a listener in Metasploit to capture any incoming connections from the reverse shell. This involved configuring the Metasploit environment for potential exploitation attempts from the crafted payload.\r\n\r\n## Executing the Malware\r\n\r\nOnce the payload and listener were in place, I set up an HTTP server using Python on my attacking OS. I accessed the server from my Windows machine to download the malware. To simulate a real-world scenario, I disabled Windows Defender to allow the payload to execute unhindered.\r\n\r\nAfter running the payload, I monitored my parrot machine for an incoming connection, indicating a successful exploit. I executed basic commands like SHELL, NET USER, and IP CONFIG to generate telemetry data.\r\n\r\n## Analyzing Telemetry with Splunk\r\n\r\nWith the simulated attack executed, I turned to analyzing the telemetry generated by the activities in my lab. I configured Splunk to ingest system logs from Sysmon, setting up an index dedicated to endpoint monitoring.\r\n\r\nBy correlating telemetry data with events from the attack simulation, I gained insights into the attack lifecycle. I reviewed logs for indicators of compromise, including the creation and execution of the reverse shell. This analysis is essential for developing effective detection strategies in a real-world Security Operations Center (SOC).\r\n\r\n## Conclusion\r\n\r\nThrough these exercises, I've deepened my understanding of the attack lifecycle and the importance of telemetry in incident response. Generating and analyzing telemetry data is fundamental for any aspiring SOC analyst. In the coming days, I plan to refine my detection capabilities further and explore additional avenues for generating and analyzing telemetry.\r\n\r\nHere's the link to follow along: [Building A Basic Home Lab](https://www.youtube.com/watch?v=-8X7Ay4YCoA&list=PLG6KGSNK4PuBWmX9NykU0wnWamjxdKhDJ&index=3)\r\n\r\n*Credit: This project was originally created by the MYDFIR YouTube channel. All structure and content was inspired by MYDFIR. Check his channel out: [@MyDFIR](https://www.youtube.com/@MyDFIR)*\r\n\r\n_#CyberSecurity #SOCAnalyst #MYDFIR #HandsOnExperience_ ",
    "image": "/images/projects/homelab-coding.jpg",
    "technologies": [
      "Nmap",
      "Metasploit",
      "Python",
      "Splunk"
    ],
    "images": [
      {
        "src": "/images/projects/homelab-part2/1 RDP Port Opened on windows 10 NMAP SCAN.png",
        "alt": "RDP Port Opened on Windows 10 - NMAP Scan"
      },
      {
        "src": "/images/projects/homelab-part2/2 MSFVEnoM.png",
        "alt": "MSFVenom Configuration"
      },
      {
        "src": "/images/projects/homelab-part2/3 msfvenom payload i will use.png",
        "alt": "MSFVenom Payload Selection"
      },
      {
        "src": "/images/projects/homelab-part2/4 Malware Creation RESUME.png",
        "alt": "Malware Creation Process"
      },
      {
        "src": "/images/projects/homelab-part2/5 msfconsole.png",
        "alt": "MSFConsole Interface"
      },
      {
        "src": "/images/projects/homelab-part2/6 payload options .png",
        "alt": "Payload Options Configuration"
      },
      {
        "src": "/images/projects/homelab-part2/7 Changing the payload options.png",
        "alt": "Modifying Payload Options"
      },
      {
        "src": "/images/projects/homelab-part2/8 Settings LHOST to Attacker IP.png",
        "alt": "Setting LHOST to Attacker IP"
      },
      {
        "src": "/images/projects/homelab-part2/9 Listening and waiting for test machine to execute malware.png",
        "alt": "Listener Waiting for Test Machine"
      },
      {
        "src": "/images/projects/homelab-part2/10 Http server setup for test machine to download malware.png",
        "alt": "HTTP Server Setup for Malware Download"
      },
      {
        "src": "/images/projects/homelab-part2/11 Disabling windows defender.png",
        "alt": "Disabling Windows Defender"
      },
      {
        "src": "/images/projects/homelab-part2/12 Accessing attacker server to download malware.png",
        "alt": "Accessing Attacker Server"
      },
      {
        "src": "/images/projects/homelab-part2/13 downloaded malware without file extension.png",
        "alt": "Downloaded Malware Without Extension"
      },
      {
        "src": "/images/projects/homelab-part2/14 Established connection between attacker and test machine after executing malware.png",
        "alt": "Established Connection After Malware Execution"
      },
      {
        "src": "/images/projects/homelab-part2/15 Confirmation of process running on task manager.png",
        "alt": "Process Confirmation in Task Manager"
      },
      {
        "src": "/images/projects/homelab-part2/16 Connection created at my handler.png",
        "alt": "Connection Created at Handler"
      },
      {
        "src": "/images/projects/homelab-part2/17 Commands ran on the test machine from the attacker machine SHELL then NET USER.png",
        "alt": "Commands Execution - SHELL and NET USER"
      },
      {
        "src": "/images/projects/homelab-part2/18 COMMAND NET LOCAL GROUP on shell .png",
        "alt": "NET LOCAL GROUP Command Execution"
      },
      {
        "src": "/images/projects/homelab-part2/19 COMMAND ipconfig on SHELL.png",
        "alt": "IPCONFIG Command Execution"
      },
      {
        "src": "/images/projects/homelab-part2/20 quering my attackig ip address on splunk.png",
        "alt": "Querying Attacker IP in Splunk"
      },
      {
        "src": "/images/projects/homelab-part2/21 Quering RESUMEdotPDFdotEXE.png",
        "alt": "Querying Malware Execution in Splunk"
      },
      {
        "src": "/images/projects/homelab-part2/22 Sticking with event code 1.png",
        "alt": "Event Code 1 Analysis"
      },
      {
        "src": "/images/projects/homelab-part2/23 Parentprocess SPLUNK.png",
        "alt": "Parent Process Analysis in Splunk"
      },
      {
        "src": "/images/projects/homelab-part2/24 what the parent process spawned cmd.exe.png",
        "alt": "Parent Process Spawning CMD.exe"
      },
      {
        "src": "/images/projects/homelab-part2/25 with process id.png",
        "alt": "Process ID Information"
      },
      {
        "src": "/images/projects/homelab-part2/26 Searching through processguid and structuring query.png",
        "alt": "Process GUID Search and Query Structure"
      },
      {
        "src": "/images/projects/homelab-part2/27 Searching through processguid and structuring query to know what exactly happened.png",
        "alt": "Detailed Query Structure Analysis"
      },
      {
        "src": "/images/projects/homelab-part2/28 Python http server to deply malware online for download.png",
        "alt": "Python HTTP Server for Malware Deployment"
      }
    ],
    "series": {
      "name": "Project 1: Building a Cybersecurity Home Lab",
      "part": 2,
      "totalParts": 2
    }
  },
  {
    "slug": "30-day-soc-analyst-challenge-part23",
    "title": "Part 23: Understanding and Implementing a Ticketing System",
    "description": "Day 23 of the 30-Day MYDFIR SOC Analyst Challenge: Exploring ticketing systems and their crucial role in tracking security alerts and managing SOC operations.",
    "date": "2024-11-23",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "",
    "solution": "",
    "results": [],
    "category": "blue",
    "tags": [
      "Ticketing",
      "OS Ticket",
      "SOC",
      "Security",
      "Incident Management"
    ],
    "content": "\r\n## Day 23 of the 30-Day MyDFIR SOC Analyst Challenge: Understanding and Implementing a Ticketing System\r\n\r\n## Overview\r\n\r\nOn Day 23 of the 30-Day MyDFIR SOC Analyst Challenge, I explored the significance of tracking security alerts and how a ticketing system plays a crucial role. Tracking an alert in any security tool is vital for identifying misconfigurations, and potential attacks, or understanding how it was handled. This is where a ticketing system comes in.\r\n\r\n## What Is a Ticketing System?\r\n\r\nA ticketing system is a tool designed to create and manage tickets for various tasks or incidents. These tickets can represent anything from security alerts to troubleshooting requests or customer complaints. The goal of a ticketing system is to provide an organized method to track issues, offer an audit trail, and ensure accountability. In the context of cybersecurity, having a ticketing system satisfies one of the three As of security: Authentication, Authorization, and Accounting (AAA).\r\n\r\nPopular ticketing systems used in real-world environments include:\r\n- Jira\r\n- ServiceNow\r\n- Freshdesk\r\n- Zendesk\r\n\r\nHowever, these are commercial products, and today, I'll introduce you to an open-source alternative that you can set up for free: OS Ticket.\r\n\r\n## Introducing OS Ticket\r\n\r\nOS Ticket, developed by Enhancesoft, is an open-source ticketing system that offers a wide range of features to fulfill core responsibilities found in commercial products. Some of the features include:\r\n\r\n- Customizable fields\r\n- Ticket filters for routing\r\n- Assigning and transferring tickets\r\n- Setting up a Service Level Agreement (SLA)\r\n\r\nBy integrating OS Ticket into your SOC workflow, you can begin mimicking the operations of a small SOC, gaining practical experience as you go.\r\n\r\nYou can choose to either self-host the OS Ticket (on-premise) or have the service managed for you, but the self-hosted option is completely free. While the free version only supports email integrations, this is sufficient for this challenge.\r\n\r\n## Getting Started with OS Ticket\r\n\r\nIn the next step of this challenge, I will be going through setting up and configuring OS Ticket, allowing us to integrate it into our SOC analyst workflow. By doing so, I'll gain firsthand experience in:\r\n\r\n- Tracking incidents\r\n- Improving my skills in audit trails\r\n- Understanding how ticketing systems contribute to security operations\r\n\r\n## Conclusion\r\n\r\nWith OS Ticket, you now have a powerful tool to manage alerts, track tasks, and enhance the efficiency of your SOC environment. As we move forward, I will continue to explore how to leverage this system in practical scenarios.\r\n\r\nHere's the link to follow along: [30-Day MYDFIR SOC Analyst Challenge](https://www.youtube.com/watch?v=kvTCA4FQET0&list=PLG6KGSNK4PuBWmX9NykU0wnWamjxdKhDJ&index=50)\r\n\r\n*Credit: This project was originally created by the MYDFIR YouTube channel. All structure and content was inspired by MYDFIR. Check his channel out: [@MyDFIR](https://www.youtube.com/@MyDFIR)*\r\n\r\n#CyberSecurity #SOCAnalyst #MYDFIRChallenge #HandsOnExperience #Day23 ",
    "image": "/images/projects/30-day-soc-analyst-challenge.png",
    "technologies": [],
    "images": [
      {
        "src": "/images/projects/30-day-challenge/30-days-day-23.png",
        "alt": "30 Days MYDFIR SOC Analyst Challenge Day 23"
      }
    ],
    "series": {
      "name": "Project 3: 30-Day MYDFIR SOC Analyst Challenge",
      "part": 23,
      "totalParts": 30
    }
  },
  {
    "slug": "30-day-soc-analyst-challenge-part22",
    "title": "Part 22: Creating Alerts and Dashboards for Mythic C2 Detection",
    "description": "Day 22 of the 30-Day MYDFIR SOC Analyst Challenge: Building alerts and dashboards to detect and monitor Mythic C2 activity in the SOC environment.",
    "date": "2024-11-22",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "",
    "solution": "",
    "results": [],
    "category": "blue",
    "tags": [
      "Alerts",
      "Dashboards",
      "SOC",
      "Security",
      "Threat Detection"
    ],
    "content": "\r\n## Day 22 of the 30-Day MyDFIR SOC Analyst Challenge: Creating Alerts and Dashboards for Mythic C2 Detection\r\n\r\n## Overview\r\n\r\nOn Day 22 of the 30-Day MyDFIR SOC Analyst Challenge, I focused on creating alerts and dashboards to detect Mythic C2 activity, building on the groundwork from Day 21. This step is crucial in setting up efficient monitoring and detection of suspicious activity within the SOC environment.\r\n\r\n## Creating the Alert\r\n\r\nI started by accessing the Elastic web UI, navigating to the Discover section, and resetting the view. To ensure I captured relevant events, I set the time range to 30 days. This gave me a clear view of the events linked to \"svchost-pilotvader.exe,\" which was triggered by our Mythic C2 agent in the previous exercise.\r\n\r\nThe next step was filtering the process creation events using Sysmon's event code 1. This allowed me to see details like the MD5 hash of the binary associated with Mythic C2. Using this information, I further investigated the event by cross-referencing the SHA-1 hash with VirusTotal for additional context. Since the agent was newly created, the results were limited but still useful.\r\n\r\nInterestingly, the original file name of the Mythic C2 agent was \"apollo.exe,\" even though it was executed as \"svchost-pilotvader.exe.\" This discrepancy helped pinpoint the activity more accurately, making it a prime candidate for alert creation.\r\n\r\n## Setting the Alert\r\n\r\nI created a query based on event code 1 for process creation. The query focused on the SHA-256 hash and the original file name \"apollo.exe.\" Once the alert was set, it was designed to trigger whenever Mythic C2 activity surfaced in the environment.\r\n\r\n## Building the Dashboard\r\n\r\nNext, I built a dashboard to visualize the Mythic C2 activity. By leveraging Elastic's Kibana features, I set up visualizations that track key metrics, such as:\r\n\r\n- Process creation events\r\n- File hashes\r\n- Network connections linked to Mythic C2\r\n\r\nThe dashboard provides real-time insights, allowing for faster detection and response to similar threats in the future.\r\n\r\n## Conclusion\r\n\r\nWith the alert and dashboard in place, I've taken an important step toward proactive monitoring of Mythic C2 activity. These tools will enhance the detection and visibility of malicious actions within the environment. Next, I'll refine my detection capabilities by expanding these alerts and dashboards to cover more complex threats.\r\n\r\nHere's the link to follow along: [30-Day MYDFIR SOC Analyst Challenge](https://www.youtube.com/watch?v=WcVuUamMApA&list=PLG6KGSNK4PuBWmX9NykU0wnWamjxdKhDJ&index=49)\r\n\r\n*Credit: This project was originally created by the MYDFIR YouTube channel. All structure and content was inspired by MYDFIR. Check his channel out: [@MyDFIR](https://www.youtube.com/@MyDFIR)*\r\n\r\n#CyberSecurity #SOCAnalyst #MYDFIRChallenge #HandsOnExperience #Day22 ",
    "image": "/images/projects/30-day-soc-analyst-challenge.png",
    "technologies": [],
    "images": [
      {
        "src": "/images/projects/30-day-challenge/1-30-days-day-22.png",
        "alt": "30 Days MYDFIR SOC Analyst Challenge Day 22"
      },
      {
        "src": "/images/projects/30-day-challenge/2-Mythic-C2-Apollo-Agent-Detection-Rule.png",
        "alt": "Mythic C2 Apollo Agent Detection Rule"
      },
      {
        "src": "/images/projects/30-day-challenge/3-Mythic-Alert.png",
        "alt": "Mythic Alert Configuration"
      },
      {
        "src": "/images/projects/30-day-challenge/4-MyDFIR-Suspicious-Activity.png",
        "alt": "MyDFIR Suspicious Activity Dashboard"
      }
    ],
    "series": {
      "name": "Project 3: 30-Day MYDFIR SOC Analyst Challenge",
      "part": 22,
      "totalParts": 30
    }
  },
  {
    "slug": "30-day-soc-analyst-challenge-part21",
    "title": "Part 21: Brute Force Attack & Establishing a C2 Session",
    "description": "Day 21 of the 30-Day MYDFIR SOC Analyst Challenge: Executing a brute force attack, generating a Mythic agent, and establishing a Command and Control session on a Windows Server.",
    "date": "2024-11-21",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "",
    "solution": "",
    "results": [],
    "category": "blue",
    "tags": [
      "Brute Force",
      "C2",
      "SOC",
      "Security",
      "Windows Security"
    ],
    "content": "\r\n## Day 21 of the 30-Day MyDFIR SOC Analyst Challenge: Brute Force Attack & Establishing a C2 Session\r\n\r\n## Overview\r\n\r\nToday, I focused on executing a brute force attack, generating a Mythic agent, and establishing a Command and Control (C2) session on a Windows Server.\r\n\r\n## Brute Force Attack on Windows Server\r\n\r\nI started by connecting to the target Windows server via Remote Desktop Protocol (RDP). For this, I intentionally set a weak password on the server: Winter2024! This allowed me to simulate a typical scenario where an attacker might exploit weak credentials.\r\n\r\nNext, I used the Crowbar tool on my Parrot OS machine to brute-force the RDP login. With the weak password added to a wordlist, I ran Crowbar, which quickly cracked the credentials. Using the recovered password, I accessed the server via xfreerdp, verifying the successful login by executing basic commands like Whoami and ipconfig.\r\n\r\n## Disabling Windows Defender for Defense Evasion\r\n\r\nOnce inside the Windows server, my first task was to disable its defenses. I navigated to the Windows Security settings and manually turned off real-time protection along with other key security features.\r\n\r\n## Generating the Mythic Agent\r\n\r\nWith the server exposed, I generated a Mythic C2 payload. Mythic is a popular Command and Control (C2) framework used by attackers to remotely control compromised systems. I installed the Apollo agent and the HTTP C2 Profile on my Mythic platform, customizing the settings to ensure the payload would effectively communicate back to my control server.\r\n\r\nAfter setting up the Mythic agent, I created a Windows executable payload. This payload would be used to establish a persistent connection between the compromised server and the Mythic C2 server.\r\n\r\n## Establishing the C2 Session\r\n\r\nTo deliver the payload to the Windows server, I used Python's http.server on port 9999 and PowerShell's Invoke-WebRequest to download it onto the target machine. Once the payload was executed on the server, it successfully connected to the Mythic C2 platform.\r\n\r\n## Data Exfiltration\r\n\r\nWith full control established, I moved on to exfiltrate data. Specifically, I retrieved a file named passwords.txt from the server's Documents folder. Using the download command in Mythic, I successfully downloaded the file, confirming the presence of the weak password, Winter2024!\r\n\r\n## Conclusion\r\n\r\nI simulated a brute force attack, compromised a Windows server, and used Mythic to establish a C2 session for remote control and data exfiltration. This activity demonstrates the methods attackers use to infiltrate systems and the importance of maintaining strong security practices, such as enforcing complex passwords and securing endpoints.\r\n\r\nNext, I'll focus on creating alerts and dashboards to detect Mythic activity and defend against similar attacks. Stay tuned!\r\n\r\nHere's the link to follow along: [30-Day MYDFIR SOC Analyst Challenge](https://www.youtube.com/watch?v=85x0NLj2zUo&list=PLG6KGSNK4PuBWmX9NykU0wnWamjxdKhDJ&index=48)\r\n\r\n*Credit: This project was originally created by the MYDFIR YouTube channel. All structure and content was inspired by MYDFIR. Check his channel out: [@MyDFIR](https://www.youtube.com/@MyDFIR)*\r\n\r\n#CyberSecurity #SOCAnalyst #MYDFIRChallenge #HandsOnExperience #Day21 ",
    "image": "/images/projects/30-day-soc-analyst-challenge.png",
    "technologies": [],
    "images": [
      {
        "src": "/images/projects/30-day-challenge/1-30-days-day-21.png",
        "alt": "30 Days MYDFIR SOC Analyst Challenge Day 21"
      },
      {
        "src": "/images/projects/30-day-challenge/2-Screenshot.png",
        "alt": "Initial Screenshot"
      },
      {
        "src": "/images/projects/30-day-challenge/3-rdp-windows-server-on-parrot.png",
        "alt": "RDP Connection to Windows Server from Parrot"
      },
      {
        "src": "/images/projects/30-day-challenge/4-running-command-on-windows-server.png",
        "alt": "Running Commands on Windows Server"
      },
      {
        "src": "/images/projects/30-day-challenge/5-turning-off-windows-defender-on-windows-server.png",
        "alt": "Disabling Windows Defender"
      },
      {
        "src": "/images/projects/30-day-challenge/6-established-connection.png",
        "alt": "Established Connection"
      },
      {
        "src": "/images/projects/30-day-challenge/7-mythic-dashboard-apollo-install.png",
        "alt": "Mythic Dashboard Apollo Installation"
      },
      {
        "src": "/images/projects/30-day-challenge/8-C2-install-on-Mythic.png",
        "alt": "C2 Installation on Mythic"
      },
      {
        "src": "/images/projects/30-day-challenge/9-command-and-control-stage.png",
        "alt": "Command and Control Stage"
      },
      {
        "src": "/images/projects/30-day-challenge/10-exfiltration.png",
        "alt": "Data Exfiltration"
      }
    ],
    "series": {
      "name": "Project 3: 30-Day MYDFIR SOC Analyst Challenge",
      "part": 21,
      "totalParts": 30
    }
  },
  {
    "slug": "30-day-soc-analyst-challenge-part20",
    "title": "Part 20: Setting Up Mythic C2",
    "description": "Day 20 of the 30-Day MYDFIR SOC Analyst Challenge: Deploying and configuring Mythic C2 framework on a cloud server with enhanced security settings.",
    "date": "2024-11-20",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "",
    "solution": "",
    "results": [],
    "category": "blue",
    "tags": [
      "Mythic",
      "C2",
      "SOC",
      "Security",
      "Cloud Security"
    ],
    "content": "\r\n## Day 20 of the 30-Day MyDFIR SOC Analyst Challenge: Setting Up Mythic C2\r\n\r\n## Overview\r\n\r\nOn Day 20 of the 30-Day MyDFIR SOC Analyst Challenge, I set up Mythic C2, a command-and-control (C2) framework. This day's challenge was focused on getting familiar with the Mythic interface, installing it on a cloud server, and tightening its security configurations.\r\n\r\n## Deploying Mythic on Vulture Cloud\r\n\r\nThe first step was logging into the Vulture cloud provider and deploying a new server. I opted for Cloud Compute with a shared CPU, choosing Ubuntu with 4GB of RAM. After naming the server and starting the deployment, I prepared to install Kali Linux on my machine.\r\n\r\n## Installing Kali Linux\r\n\r\nI headed to the official Kali site and downloaded the VMware version for the Kali Linux setup, as I would run it on a virtual machine. After extracting the download, I loaded the .vmx file into VMware Workstation, started Kali, and ensured it ran smoothly.\r\n\r\n## SSH Into Mythic Server\r\n\r\nWith the Mythic server ready on Vulture, I accessed it using SSH through PowerShell. After logging in, I updated the system repositories with apt-get update and apt-get upgrade. I then installed Docker, Docker Compose, and the make tool to ensure Mythic would run correctly.\r\n\r\n## Installing Mythic\r\n\r\nNext, I cloned the Mythic repository from GitHub and navigated into the directory. The installation process was initiated using a shell script designed for Docker on Ubuntu. Once the installation was completed, I encountered a minor issue with Docker not starting but resolved it by restarting the service.\r\n\r\n## Configuring Mythic\r\n\r\nWith Mythic running, I began configuring the system. To enhance security, I created a custom firewall rule that only allowed my machine and specific agents to communicate with the Mythic server. This step ensured that no unauthorized IPs could attempt to access the server.\r\n\r\n## Accessing Mythic's Web GUI\r\n\r\nFinally, I logged into Mythic's web GUI using the server's IP and port 7443. I retrieved the login credentials from the environment variables stored on the server and successfully accessed the dashboard, where I explored the various options for managing payloads, callbacks, and more.\r\n\r\n## Conclusion\r\n\r\nWith Mythic C2 set up and configured, I'm now ready to start generating payloads and testing them against our Windows server in future challenges. This setup is crucial for understanding C2 frameworks and is a key step for any SOC analyst. Stay tuned as I dive deeper into Mythic's capabilities in the upcoming challenges!\r\n\r\nHere's the link to follow along: [30-Day MYDFIR SOC Analyst Challenge](https://www.youtube.com/watch?v=JKO1pZ45_5I&list=PLG6KGSNK4PuBWmX9NykU0wnWamjxdKhDJ&index=47)\r\n\r\n*Credit: This project was originally created by the MYDFIR YouTube channel. All structure and content was inspired by MYDFIR. Check his channel out: [@MyDFIR](https://www.youtube.com/@MyDFIR)*\r\n\r\n#CyberSecurity #SOCAnalyst #MYDFIRChallenge #HandsOnExperience #Day20 ",
    "image": "/images/projects/30-day-soc-analyst-challenge.png",
    "technologies": [],
    "images": [
      {
        "src": "/images/projects/30-day-challenge/30-days-day-20.png",
        "alt": "30 Days MYDFIR SOC Analyst Challenge Day 20"
      },
      {
        "src": "/images/projects/30-day-challenge/Mythic-CLI.png",
        "alt": "Mythic Command Line Interface"
      },
      {
        "src": "/images/projects/30-day-challenge/mythic-dashboard.png",
        "alt": "Mythic Dashboard Interface"
      }
    ],
    "series": {
      "name": "Project 3: 30-Day MYDFIR SOC Analyst Challenge",
      "part": 20,
      "totalParts": 30
    }
  },
  {
    "slug": "30-day-soc-analyst-challenge-part19",
    "title": "Part 19: Creating an Attack Diagram",
    "description": "Day 19 of the 30-Day MYDFIR SOC Analyst Challenge: Mapping out a comprehensive attack plan using Draw.io, from initial access to data exfiltration.",
    "date": "2024-11-19",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "",
    "solution": "",
    "results": [],
    "category": "blue",
    "tags": [
      "Attack Diagram",
      "Draw.io",
      "SOC",
      "Security",
      "Threat Detection"
    ],
    "content": "\r\n## Day 19 of the 30-Day MyDFIR SOC Analyst Challenge: Creating an Attack Diagram\r\n\r\n## Overview\r\n\r\nThe focus for today is on using Draw.io, mapping out a plan to compromise a target machine, focusing on brute-forcing RDP credentials, disabling Windows Defender, and establishing a C2 connection.\r\n\r\n## Building the Attack Diagram\r\n\r\nThe essential components of our attack:\r\n\r\n- **Mythic C2 Server** – This is the command and control server that we'll use to manage our attack.\r\n- **Windows Server** – This will be our target machine.\r\n- **Attacker Laptop** – Running Kali Linux, this is the machine we'll be using for the attack.\r\n\r\nA cloud represents the internet and connects all the components accordingly. The Kali Linux laptop will be on a separate network, while the Mythic C2 server will run in the cloud.\r\n\r\n## Phase 1: Initial Access – Brute Force\r\n\r\nIn this phase, the attacker's laptop will attempt a brute force attack over Remote Desktop Protocol (RDP) to gain access to the Windows Server. This will serve as the initial access point. If successful, we will authenticate and proceed to the next phase.\r\n\r\n## Phase 2: Discovery – Gathering Information\r\n\r\nOnce inside the Windows Server, the next step is Discovery. The attacker will run a series of commands like:\r\n\r\n- whoami\r\n- ipconfig\r\n- net user\r\n- net group\r\n\r\nThese commands help us learn about the system, its users, and network settings. This information is crucial for planning our next moves.\r\n\r\n## Phase 3: Defense Evasion – Disabling Defender\r\n\r\nBefore executing any malicious payloads, we need to bypass Windows Defender. The focus of this phase is defense evasion. Using our elevated privileges, we will attempt to disable Windows Defender on the server to prevent it from detecting our actions.\r\n\r\n## Phase 4: Execution – Downloading and Running Mythic Agent\r\n\r\nOnce the defenses are down, we move to execution. In this phase, the Windows Server will reach out to our Mythic C2 server to download an agent. This will be done using PowerShell's Invoke-Expression (IEX) command to fetch and run the agent.\r\n\r\n## Phase 5: Command and Control – Establishing C2\r\n\r\nWith the Mythic agent successfully installed, we establish a C2 connection between the compromised Windows Server and the Mythic C2 server. At this point, the attacker has full control over the target machine, enabling further malicious actions.\r\n\r\n## Phase 6: Exfiltration – Stealing Data\r\n\r\nThe final phase is exfiltration. Creating a fake password file called passwords.txt on the Windows Server. Using the established C2 session, we'll download this file from the compromised server, mimicking a data theft scenario.\r\n\r\n## Conclusion\r\n\r\nThis attack diagram is a simplified blueprint of how to compromise a machine, which is strictly for educational purposes only. Next, we'll go over how to set up the Mythic server and begin executing these steps. Stay tuned!\r\n\r\nHere's the link to follow along: [30-Day MYDFIR SOC Analyst Challenge](https://www.youtube.com/watch?v=jv-qiugJGHg&list=PLG6KGSNK4PuBWmX9NykU0wnWamjxdKhDJ&index=46)\r\n\r\n*Credit: This project was originally created by the MYDFIR YouTube channel. All structure and content was inspired by MYDFIR. Check his channel out: [@MyDFIR](https://www.youtube.com/@MyDFIR)*\r\n\r\n#CyberSecurity #SOCAnalyst #MYDFIRChallenge #HandsOnExperience #Day19 ",
    "image": "/images/projects/30-day-soc-analyst-challenge.png",
    "technologies": [],
    "images": [
      {
        "src": "/images/projects/30-day-challenge/30-days-day-19.png",
        "alt": "30 Days MYDFIR SOC Analyst Challenge Day 19"
      },
      {
        "src": "/images/projects/30-day-challenge/attack-diagram-1.png",
        "alt": "Attack Diagram Overview"
      },
      {
        "src": "/images/projects/30-day-challenge/attack-diagram-22.png",
        "alt": "Attack Diagram Phase 22"
      },
      {
        "src": "/images/projects/30-day-challenge/attack-diagram-3.png",
        "alt": "Attack Diagram Phase 3"
      }
    ],
    "series": {
      "name": "Project 3: 30-Day MYDFIR SOC Analyst Challenge",
      "part": 19,
      "totalParts": 30
    }
  },
  {
    "slug": "30-day-soc-analyst-challenge-part18",
    "title": "Part 18: Understanding Command and Control (C2)",
    "description": "Day 18 of the 30-Day MYDFIR SOC Analyst Challenge: Exploring C2 frameworks, their importance in cyberattacks, and preparing for Mythic implementation.",
    "date": "2024-11-18",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "",
    "solution": "",
    "results": [],
    "category": "blue",
    "tags": [
      "C2",
      "Mythic",
      "Security",
      "SOC",
      "Threat Detection"
    ],
    "content": "\r\n## Day 18 of the 30-Day MyDFIR SOC Analyst Challenge: Understanding Command and Control (C2)\r\n\r\n## Overview\r\n\r\nWelcome to Day 18 of the 30-Day MyDFIR SOC Analyst Challenge. Today, our focus would be on an essential part of cyberattacks, Command and Control (C2). In this blog, we'll go over what C2 is, why it's crucial for attackers, and the common tools they use. We'll also look at one particular framework, Mythic, which we will use later in this challenge.\r\n\r\n## What is Command and Control?\r\n\r\nCommand and Control (C2) refers to the techniques attackers use to communicate with systems they have compromised in a victim's network. According to the MITRE ATT&CK framework, C2 allows attackers to maintain control over the compromised system, enabling them to perform various malicious activities.\r\n\r\nOnce attackers gain access to a victim's machine, they need a way to interact with it remotely. C2 helps them move closer to their end goal, stealing credentials, exfiltrating data, or deploying ransomware.\r\n\r\n## Why is Establishing C2 Important?\r\n\r\nThe importance of C2 for attackers cannot be overstated. Without it, they couldn't perform further actions on the compromised network. C2 is a gateway for attackers to escalate privileges, move laterally, steal sensitive information, or even disrupt services.\r\n\r\nFor attackers to cause harm, they must maintain access to the network, which they do through C2 channels. The MITRE ATT&CK framework lists 18 different techniques attackers use to establish C2, and understanding these techniques is crucial for any SOC analyst.\r\n\r\n## Common Tools and Frameworks for C2\r\n\r\nSeveral C2 frameworks are used in the wild. Let's focus on four of the most common:\r\n\r\n### 1. Metasploit\r\nMetasploit is a popular framework used for vulnerability exploitation. It's widely available and often used in ethical hacking environments, but attackers also use it to exploit vulnerable systems.\r\n\r\n### 2. Cobalt Strike\r\nCobalt Strike is a commercial adversary emulation tool. Though it's legitimate software, attackers frequently use it in real-world breaches. Fortunately, because it's so widely used, there are many detection methods available.\r\n\r\n### 3. Sliver\r\nSliver is an open-source alternative to Cobalt Strike, developed by Bishop Fox. It supports multiple protocols like HTTP, HTTPS, and DNS, making it a versatile tool for attackers.\r\n\r\n### 4. Mythic\r\nMythic is the framework I'll be using in this challenge. Built with GoLang and Docker, Mythic provides a user-friendly interface for managing payloads and C2 profiles. This flexibility makes it a favorite for adversary emulation.\r\n\r\n## Conclusion\r\n\r\nIn the next part of the challenge, I'll dive deeper into crafting attacks on our Windows Server and setting up a Mythic C2 server. Stay tuned as we explore how to deploy agents and establish a successful C2 session.\r\n\r\nHere's the link to follow along: [30-Day MYDFIR SOC Analyst Challenge](https://www.youtube.com/watch?v=WnOkhGNPmyA&list=PLG6KGSNK4PuBWmX9NykU0wnWamjxdKhDJ&index=45)\r\n\r\n*Credit: This project was originally created by the MYDFIR YouTube channel. All structure and content was inspired by MYDFIR. Check his channel out: [@MyDFIR](https://www.youtube.com/@MyDFIR)*\r\n\r\n#CyberSecurity #SOCAnalyst #MYDFIRChallenge #HandsOnExperience #Day18 ",
    "image": "/images/projects/30-day-soc-analyst-challenge.png",
    "technologies": [],
    "images": [
      {
        "src": "/images/projects/30-day-challenge/30-days-day-18.png",
        "alt": "30 Days MYDFIR SOC Analyst Challenge Day 18"
      }
    ],
    "series": {
      "name": "Project 3: 30-Day MYDFIR SOC Analyst Challenge",
      "part": 18,
      "totalParts": 30
    }
  },
  {
    "slug": "30-day-soc-analyst-challenge-part17",
    "title": "Part 17: Building a Dashboard for RDP And SSH Activity",
    "description": "Day 17 of the 30-Day MYDFIR SOC Analyst Challenge: Creating comprehensive dashboards to monitor and analyze RDP and SSH authentication attempts.",
    "date": "2024-11-17",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "",
    "solution": "",
    "results": [],
    "category": "blue",
    "tags": [
      "RDP",
      "SSH",
      "Dashboards",
      "SOC",
      "Security Monitoring"
    ],
    "content": "\r\n## Day 17 of the 30-Day MyDFIR SOC Analyst Challenge: Building a Dashboard for RDP And SSH Activity\r\n\r\n## Overview\r\n\r\nToday I focused on creating a dashboard to monitor Remote Desktop Protocol (RDP) and Secure Shell (SSH) activity. This is critical for understanding authentication attempts on the Windows Server set up earlier in the challenge. Here's how I did it.\r\n\r\n## Querying for Failed RDP Authentication Attempts\r\n\r\nThe first step was to log into the Elastic web GUI. I navigated to the \"Maps\" section by clicking the hamburger icon on the left sidebar. Since I needed to query for failed RDP attempts, I returned to the \"Discover\" tab to check a previous query. Using the search for failed authentication attempts, I retrieved a query using the event code 4625, which represents failed logon events in Windows.\r\n\r\nWith the query set, I added a new layer to my map. I chose \"world countries\" as the boundary and the country ISO code as the join field, allowing me to see where the failed RDP attempts were coming from. The results were striking, over 131,276 failed attempts from Ukraine alone!\r\n\r\n## Querying for Successful RDP Authentication Attempts\r\n\r\nNext, I needed to monitor successful RDP logins. I used the event code 4624, which represents successful logons. However, to specifically track RDP logins, I focused on logon types 10 and 7, which are associated with RDP connections. I updated the query to look for successful authentications of these types.\r\n\r\nAfter running the query in the \"Discover\" tab, I saved it and moved it to the dashboard. I duplicated the earlier failed authentication dashboard and updated the query with my new one for successful RDP logins. Once saved, the dashboard displayed successful RDP connections, including their geographical origin — in my case, the United Kingdom.\r\n\r\n## Adding a Table for Easier Analysis\r\n\r\nTo enhance my dashboard, I added a table showing the username, source IP, and country for each failed and successful RDP attempt. In the \"Discover\" tab, I created a new search query for failed attempts using event code 4625 and then did the same for successful attempts.\r\n\r\nI added these saved searches to the dashboard and arranged them as tables beneath the maps. This gave me a clearer view of which usernames were being targeted and from which countries. Finally, I sorted the data to display the top values, showing the most frequent IP addresses and usernames involved in failed and successful logins.\r\n\r\n## Conclusion\r\n\r\nBy setting up dashboards for both failed and successful RDP and SSH attempts, I can now better monitor authentication activity on my Windows Server. With this visibility, I am equipped to detect potential threats, particularly from brute force attacks on RDP and SSH. Next, I'll dive into command and control (C2) techniques using Mythic's framework.\r\n\r\nHere's the link to follow along: [30-Day MYDFIR SOC Analyst Challenge](https://www.youtube.com/watch?v=pAfIi6Z6a2g&list=PLG6KGSNK4PuBWmX9NykU0wnWamjxdKhDJ&index=44)\r\n\r\n*Credit: This project was originally created by the MYDFIR YouTube channel. All structure and content was inspired by MYDFIR. Check his channel out: [@MyDFIR](https://www.youtube.com/@MyDFIR)*\r\n\r\n#CyberSecurity #SOCAnalyst #MYDFIRChallenge #HandsOnExperience #Day17 ",
    "image": "/images/projects/30-day-soc-analyst-challenge.png",
    "technologies": [],
    "images": [
      {
        "src": "/images/projects/30-day-challenge/30-days-day-17.png",
        "alt": "30 Days MYDFIR SOC Analyst Challenge Day 17"
      },
      {
        "src": "/images/projects/30-day-challenge/Dashboard-1.png",
        "alt": "RDP Authentication Dashboard Overview"
      },
      {
        "src": "/images/projects/30-day-challenge/Dashboard-2.png",
        "alt": "Detailed Authentication Analysis Dashboard"
      }
    ],
    "series": {
      "name": "Project 3: 30-Day MYDFIR SOC Analyst Challenge",
      "part": 17,
      "totalParts": 30
    }
  },
  {
    "slug": "30-day-soc-analyst-challenge-part16",
    "title": "Part 16: Windows Authentication Logs and RDP/SSH Brute Force Alerts",
    "description": "Day 16 of the 30-Day MYDFIR SOC Analyst Challenge: Analyzing Windows authentication logs and creating sophisticated alerts for brute force detection.",
    "date": "2024-11-16",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "",
    "solution": "",
    "results": [],
    "category": "blue",
    "tags": [
      "Windows",
      "Authentication",
      "Alerts",
      "SOC",
      "Security Monitoring"
    ],
    "content": "\r\n## Day 16 of the 30-Day MYDFIR SOC Analyst Challenge: Windows Authentication Logs and RDP/SSH Brute Force Alerts\r\n\r\n## Overview\r\n\r\nOn Day 16 of our challenge, I delved into the task of analyzing Windows authentication logs and creating alerts for RDP and SSH Brute Force attempts. This exercise built upon our previous work, further improving my skills as a SOC analyst.\r\n\r\n## Analyzing Windows Authentication Logs\r\n\r\nI began by accessing the Elastic web GUI and filtering events specifically for my Windows RDP server. My primary objective was to identify failed authentication attempts, which are key indicators of potential Brute Force activities. Through my research, I discovered that Event ID 4625 is associated with failed logon attempts on Windows systems, providing me with a specific marker to focus on.\r\n\r\n## Customizing Data View\r\n\r\nTo gain a comprehensive understanding of these failed attempts, I tailored my data view in Elastic. I focused on three critical pieces of information:\r\n- The failed attempts themselves (represented by Event ID 4625)\r\n- The source IP address of the login attempt\r\n- The username being targeted\r\n\r\nThis customized view allowed me to quickly assess the nature and scope of potential attacks. I then verified my setup by performing a test login attempt, ensuring that my system accurately captured RDP-specific events.\r\n\r\n## Creating RDP And SSH Brute Force Alerts\r\n\r\nMy initial approach involved setting up a basic alert that would trigger when Event ID 4625 occurred more than five times within a five-minute window. However, I quickly realized that this alert lacked the detail necessary for effective threat analysis.\r\n\r\nTo address this, I developed an enhanced custom rule. This improved alert incorporated specific usernames, such as \"administrator,\" and grouped events by both source IP and username. I also increased the frequency of our checks, configuring the system to analyze data every minute while looking back over five minutes.\r\n\r\n## Conclusion\r\n\r\nThrough this exercise, I gained several valuable insights:\r\n- The importance of fine-tuning alerts to provide truly actionable information\r\n- A deeper understanding of various authentication event IDs and their significance in Windows environments\r\n- The value of correlating events across multiple data points for a more comprehensive picture\r\n- The need for continuous refinement of alert systems to minimize false positives\r\n\r\nAs I move forward, our next session will focus on creating dashboards to visualize the sources of these authentication attempts, further enhancing my ability to detect and respond to threats efficiently.\r\n\r\nHere's the link to follow along: [30-Day MYDFIR SOC Analyst Challenge](https://www.youtube.com/watch?v=11eBIfDeZ7k&list=PLG6KGSNK4PuBWmX9NykU0wnWamjxdKhDJ&index=43)\r\n\r\n*Credit: This project was originally created by the MYDFIR YouTube channel. All structure and content was inspired by MYDFIR. Check his channel out: [@MyDFIR](https://www.youtube.com/@MyDFIR)*\r\n\r\n#CyberSecurity #SOCAnalyst #MYDFIRChallenge #HandsOnExperience #Day16 ",
    "image": "/images/projects/30-day-soc-analyst-challenge.png",
    "technologies": [],
    "images": [
      {
        "src": "/images/projects/30-day-challenge/30-days-day-16.png",
        "alt": "30 Days MYDFIR SOC Analyst Challenge Day 16"
      },
      {
        "src": "/images/projects/30-day-challenge/Elastisearch-query-breached.png",
        "alt": "Elasticsearch Query for Breached Attempts"
      },
      {
        "src": "/images/projects/30-day-challenge/overview.png",
        "alt": "Overview of Authentication Monitoring"
      },
      {
        "src": "/images/projects/30-day-challenge/RDP-brute-force-attempt.png",
        "alt": "RDP Brute Force Attempt Detection"
      },
      {
        "src": "/images/projects/30-day-challenge/SSH-brute-for-attempt.png",
        "alt": "SSH Brute Force Attempt Detection"
      }
    ],
    "series": {
      "name": "Project 3: 30-Day MYDFIR SOC Analyst Challenge",
      "part": 16,
      "totalParts": 30
    }
  },
  {
    "slug": "30-day-soc-analyst-challenge-part15",
    "title": "Part 15: Remote Desktop Protocol Introduction",
    "description": "Day 15 of the 30-Day MYDFIR SOC Analyst Challenge: Understanding RDP vulnerabilities, detection tools, and security best practices.",
    "date": "2024-11-15",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "",
    "solution": "",
    "results": [],
    "category": "blue",
    "tags": [
      "RDP",
      "Remote Access",
      "Security",
      "SOC",
      "Network Security"
    ],
    "content": "\r\n## Day 15 of the 30-Day MYDFIR SOC Analyst Challenge: Remote Desktop Protocol Introduction\r\n\r\n## Overview\r\n\r\nOn Day 15 of the MyDFIR SOC Analyst Challenge, I dove into Remote Desktop Protocol (RDP), a commonly used but frequently abused protocol. According to Sophos, RDP was involved in 90% of ransomware breaches in 2023. This session focused on understanding RDP, its vulnerabilities, and how to secure it.\r\n\r\n## The Risks of RDP\r\n\r\nRDP allows users to remotely access machines over the internet, operating on Port 3389. While this offers convenience, especially for remote work or troubleshooting, the same accessibility makes RDP a prime target for attackers. They exploit open RDP services via brute-force attacks or use stolen credentials, to gain access to an organization's internal systems. Once inside, attackers can escalate privileges, steal data, or deploy ransomware.\r\n\r\n## Tools for Detecting Exposed RDP\r\n\r\nI learned about Shodan and Censys, two powerful search engines for internet-connected devices. By searching for Port 3389, I identified millions of devices with RDP exposed to the internet. Organizations should regularly use these tools to audit their exposure and assess whether sensitive services are unnecessarily open to the public.\r\n\r\n## Securing RDP\r\n\r\nTo mitigate the risks associated with RDP, I learned five key measures:\r\n\r\n1. Disable RDP when not in use to limit exposure.\r\n2. Enable multi-factor authentication (MFA) for an added layer of security.\r\n3. Restrict access by using firewalls or VPNs, limiting RDP to trusted networks.\r\n4. Enforce strong passwords, ideally with a privileged access management (PAM) tool.\r\n5. Disable default accounts and create custom admin accounts to reduce attack vectors.\r\n\r\n## Importance of Auditing and Monitoring\r\n\r\nAuditing authentication logs is crucial for identifying suspicious activity, such as login attempts from unusual geographic locations. Early detection of unauthorized access can prevent further exploitation.\r\n\r\n## Conclusion\r\n\r\nDay 15 emphasized the critical nature of RDP security. RDP is a convenient tool, but its vulnerabilities require careful management. By following these best practices, organizations can significantly reduce the risk of RDP-based attacks and stay ahead of emerging threats.\r\n\r\nHere's the link to follow along: [30-Day MYDFIR SOC Analyst Challenge](https://www.youtube.com/watch?v=tNhGxtKZo7c&list=PLG6KGSNK4PuBWmX9NykU0wnWamjxdKhDJ&index=42)\r\n\r\n*Credit: This project was originally created by the MYDFIR YouTube channel. All structure and content was inspired by MYDFIR. Check his channel out: [@MyDFIR](https://www.youtube.com/@MyDFIR)*\r\n\r\n#CyberSecurity #SOCAnalyst #MYDFIRChallenge #HandsOnExperience #Day15 ",
    "image": "/images/projects/30-day-soc-analyst-challenge.png",
    "technologies": [],
    "images": [
      {
        "src": "/images/projects/30-day-challenge/30-days-day-15.png",
        "alt": "30 Days MYDFIR SOC Analyst Challenge Day 15"
      }
    ],
    "series": {
      "name": "Project 3: 30-Day MYDFIR SOC Analyst Challenge",
      "part": 15,
      "totalParts": 30
    }
  },
  {
    "slug": "30-day-soc-analyst-challenge-part14",
    "title": "Part 14: Creating an SSH Brute Force Alert and Dashboard",
    "description": "Day 14 of the 30-Day MYDFIR SOC Analyst Challenge: Setting up real-time alerts and dashboards to monitor and visualize SSH brute-force attacks.",
    "date": "2024-11-14",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "",
    "solution": "",
    "results": [],
    "category": "blue",
    "tags": [
      "SSH",
      "Alerts",
      "Dashboards",
      "SOC",
      "Security Monitoring"
    ],
    "content": "\r\n## Day 14 of the 30-Day MYDFIR SOC Analyst Challenge: Creating an SSH Brute Force Alert and Dashboard\r\n\r\n## Overview\r\n\r\nToday, I focused on setting up real-time alerts and dashboards to monitor brute-force activity from unauthorized sources. This exercise taught me how to visualize, monitor, and respond to SSH brute-force attacks more efficiently.\r\n\r\n## Querying SSH Logs\r\n\r\nThe first task involved querying logs from my SSH server, which had already been ingested into ElasticSearch. By accessing the Discover tab, I could filter out logs specific to my SSH server. I found it crucial to focus on specific fields like `system.auth.ssh.event` and `user.name` to track failed authentication attempts. The process began by filtering for failed SSH authentication attempts. This was accomplished by searching for logs where the `system.auth.ssh.event` field indicated failed attempts, giving me an initial view of how many attempts were occurring and from where.\r\n\r\n## Building the Brute Force Alert\r\n\r\nNext, I focused on creating an alert for SSH brute-force attempts. The goal was to automate the detection process and trigger an alert based on predefined thresholds. Using ElasticSearch's alert feature, I created a search-based threshold rule. My rule was set to trigger if more than five failed login attempts occurred within five minutes, a common indicator of brute-force activity.\r\n\r\nI also configured how frequently the rule should check for new logs. To ensure near real-time monitoring, I set it to check every minute. While this was a basic alert configuration, it showcased the power of automating log analysis in detecting potential threats. Though this particular rule may not be perfect, it sets a solid foundation for building more sophisticated alerts later.\r\n\r\n## Visualizing with Dashboards\r\n\r\nTo complement the alert system, I created a visual dashboard to track the geographical origins of these brute-force attempts. By navigating to the Maps section in ElasticSearch, I built a dashboard that plotted failed authentication attempts based on their source IP geolocation. This allowed me to see patterns of attack, such as which regions were targeting my SSH server the most.\r\n\r\nFor example, I noticed most failed attempts came from countries like North Korea and China. Using the choropleth layer in the map, I visualized these locations, providing an easy-to-understand view of attack origins.\r\n\r\n## Conclusion\r\n\r\nBy the end of Day 14, I had successfully created both an alert system and a dashboard for monitoring SSH brute-force attacks. The combination of real-time alerts and visualization tools has significantly improved my ability to detect and respond to these types of attacks quickly.\r\n\r\nHere's the link to follow along: [30-Day MYDFIR SOC Analyst Challenge](https://www.youtube.com/watch?v=AdUMhT1l1eY&list=PLG6KGSNK4PuBWmX9NykU0wnWamjxdKhDJ&index=41)\r\n\r\n*Credit: This project was originally created by the MYDFIR YouTube channel. All structure and content was inspired by MYDFIR. Check his channel out: [@MyDFIR](https://www.youtube.com/@MyDFIR)*\r\n\r\n#CyberSecurity #SOCAnalyst #MYDFIRChallenge #HandsOnExperience #Day14 ",
    "image": "/images/projects/30-day-soc-analyst-challenge.png",
    "technologies": [],
    "images": [
      {
        "src": "/images/projects/30-day-challenge/30-days-day-14.png",
        "alt": "30 Days MYDFIR SOC Analyst Challenge Day 14"
      },
      {
        "src": "/images/projects/30-day-challenge/Alert-creation-and-dashboard-on-Kibana-day-14.png",
        "alt": "Alert Creation and Dashboard Configuration in Kibana"
      }
    ],
    "series": {
      "name": "Project 3: 30-Day MYDFIR SOC Analyst Challenge",
      "part": 14,
      "totalParts": 30
    }
  },
  {
    "slug": "30-day-soc-analyst-challenge-part13",
    "title": "Part 13: Installing Elastic Agent On Ubuntu",
    "description": "Day 13 of the 30-Day MYDFIR SOC Analyst Challenge: Setting up Elastic Agent for centralized log collection and analysis from our SSH server.",
    "date": "2024-11-13",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "",
    "solution": "",
    "results": [],
    "category": "blue",
    "tags": [
      "Elastic Agent",
      "Log Collection",
      "Security Monitoring",
      "SOC",
      "Ubuntu"
    ],
    "content": "\r\n## Day 13 of the 30-Day MYDFIR SOC Analyst Challenge: Installing Elastic Agent On Ubuntu\r\n\r\n## Overview\r\n\r\nThe focus for today was on installing the Elastic agent on the SSH server created on Day 12, which enables us to ingest logs from the server into our Elasticsearch instance, allowing for centralized log querying and analysis.\r\n\r\n## Creating an Agent Policy in Elasticsearch\r\n\r\nI began by logging into the Elasticsearch web GUI and navigating to Fleet under the Management section. Here, I created a new agent policy named \"my-dfir-linux-policy\". This policy is crucial as it defines what logs the Elastic agent will collect and forward to Elasticsearch.\r\n\r\nWithin the policy, I selected the system-3 integration, which is designed to collect system logs from `/var/log/auth.log`.\r\n\r\n## Installing the Elastic Agent\r\n\r\nWith the policy in place, I proceeded to add a new agent. I selected the newly created \"my-dfir-linux-policy\" and chose the Linux operating system. Elasticsearch provided a command to install the agent, which I copied and pasted into my SSH session on the Linux server.\r\n\r\nInitially, the installation failed due to certificate issues, as we're using a self-signed certificate. To resolve this, I added the `--insecure` flag to the installation command, allowing it to bypass certificate validation.\r\n\r\nAfter confirming the installation, the Elastic agent was successfully installed and enrolled in our Fleet.\r\n\r\n## Verifying Agent Installation and Data Ingestion\r\n\r\nReturning to the Elasticsearch GUI, I confirmed that the agent enrollment was successful and that incoming data was being received. To verify this further, I used the Discover page in Elasticsearch to query the incoming logs.\r\n\r\nI filtered the events by the agent name \"my-dfir-linux-pilotvader\" to focus on logs from our newly connected SSH server. This immediately showed me that log ingestion was working correctly.\r\n\r\n## Analyzing Authentication Failures\r\n\r\nI investigated authentication failures to demonstrate the power of centralized log analysis. From our previous day's exploration, I knew that many failed login attempts were coming from a specific IP address (110.44.50.140). Using Elasticsearch's query capabilities, I searched for events with \"authentication failure\" from this IP address. This returned 6744 events, which I could easily view and analyze within the Elasticsearch interface.\r\n\r\nTo improve readability, I added the \"message\" field to the table view in Elasticsearch. This allowed me to quickly scan the authentication failure messages, providing a clear view of the attempted breaches.\r\n\r\n## Conclusion\r\n\r\nIn the next part of this challenge, we'll explore creating alerts for brute force activities and develop dashboards to visualize attack origins. These steps will further enhance our ability to detect and respond to potential security threats efficiently.\r\n\r\nHere's the link to follow along: [30-Day MYDFIR SOC Analyst Challenge](https://www.youtube.com/watch?v=QHJr2-Kav4k&list=PLG6KGSNK4PuBWmX9NykU0wnWamjxdKhDJ&index=40)\r\n\r\n*Credit: This project was originally created by the MYDFIR YouTube channel. All structure and content was inspired by MYDFIR. Check his channel out: [@MyDFIR](https://www.youtube.com/@MyDFIR)*\r\n\r\n#CyberSecurity #SOCAnalyst #MYDFIRChallenge #HandsOnExperience #Day13 ",
    "image": "/images/projects/30-day-soc-analyst-challenge.png",
    "technologies": [],
    "images": [
      {
        "src": "/images/projects/30-day-challenge/30-days-day-13.png",
        "alt": "30 Days MYDFIR SOC Analyst Challenge Day 13"
      },
      {
        "src": "/images/projects/30-day-challenge/Image-for-day-13-elastic-agent-install-for-ubuntu.png",
        "alt": "Elastic Agent Installation Process for Ubuntu"
      }
    ],
    "series": {
      "name": "Project 3: 30-Day MYDFIR SOC Analyst Challenge",
      "part": 13,
      "totalParts": 30
    }
  },
  {
    "slug": "30-day-soc-analyst-challenge-part12",
    "title": "Part 12: Setting Up an SSH Server and Monitoring Authentication Logs in Real-Time",
    "description": "Day 12 of the 30-Day MYDFIR SOC Analyst Challenge: Deploying a cloud server and analyzing real-time authentication logs to detect brute force attempts.",
    "date": "2024-11-12",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "",
    "solution": "",
    "results": [],
    "category": "blue",
    "tags": [
      "SSH",
      "Log Analysis",
      "Server Security",
      "SOC",
      "Security Monitoring"
    ],
    "content": "\r\n## Day 12 of the 30-Day MYDFIR SOC Analyst Challenge: Setting Up an SSH Server and Monitoring Authentication Logs in Real-Time\r\n\r\n## Overview\r\n\r\nOn Day 12 of the 30-Day MYDFIR SOC Analyst Challenge, I focused on setting up an SSH server in the cloud and learning how to review authentication logs in real time. This exercise provides practical experience in server management and log analysis, crucial skills for aspiring SOC analysts.\r\n\r\n## SSH Server Setup\r\n\r\nI logged into Vultr and deployed a cloud computing instance with Ubuntu 24.04. This lightweight server (1 CPU and 1GB RAM) was perfect for our needs. I then connected via PowerShell, updated the repositories, and ensured my server was fully up to date.\r\n\r\n## Exploring Authentication Logs\r\n\r\nThe next step involved navigating to the directory where authentication logs are stored: `/var/log/auth.log`. These logs provide a view of login attempts on the server. Initially, there was no activity since the server had just been deployed, but I left it running for about 45 minutes. When I returned, I noticed several failed login attempts exactly as MYDFIR predicted.\r\n\r\nUsing a simple grep command, I filtered the logs to find entries containing the term \"failed.\" Additionally, I isolated attempts that targeted the \"root\" user, allowing me to focus on the most important data.\r\n\r\n## Identifying Attackers\r\n\r\nMYDFIR also talked about how to extract IP addresses from these failed login attempts. By using the cut command, I was able to isolate the specific IP addresses responsible for trying to break into the server. It was amazing to see how quickly the logs filled up with attempts to compromise the server.\r\n\r\n## Conclusion\r\n\r\nBy following MYDFIR's guidance, I was able to set up and secure my SSH server, and I gained insight into real-world attack patterns by observing authentication logs. This hands-on experience is invaluable for anyone looking to understand how brute force attacks happen and how to detect them. In the next step, I'll install the Elastic Agent to forward these logs to ElasticSearch for even deeper analysis.\r\n\r\nHere's the link to follow along: [30-Day MYDFIR SOC Analyst Challenge](https://www.youtube.com/watch?v=qsMhmXIqWfc&list=PLG6KGSNK4PuBWmX9NykU0wnWamjxdKhDJ&index=39)\r\n\r\n*Credit: This project was originally created by the MYDFIR YouTube channel. All structure and content was inspired by MYDFIR. Check his channel out: [@MyDFIR](https://www.youtube.com/@MyDFIR)*\r\n\r\n#CyberSecurity #SOCAnalyst #MYDFIRChallenge #HandsOnExperience #Day12 ",
    "image": "/images/projects/30-day-soc-analyst-challenge.png",
    "technologies": [],
    "images": [
      {
        "src": "/images/projects/30-day-challenge/30-days-day-12.png",
        "alt": "30 Days MYDFIR SOC Analyst Challenge Day 12"
      },
      {
        "src": "/images/projects/30-day-challenge/failed-login-attempts-f-9-10-11.png",
        "alt": "Failed Login Attempts Filtered by Date"
      },
      {
        "src": "/images/projects/30-day-challenge/failed-login-attempts-i-failed.png",
        "alt": "Failed Login Attempts Filtered by 'failed' Keyword"
      },
      {
        "src": "/images/projects/30-day-challenge/failed-login-attempts-i-root.png",
        "alt": "Failed Login Attempts Targeting Root User"
      }
    ],
    "series": {
      "name": "Project 3: 30-Day MYDFIR SOC Analyst Challenge",
      "part": 12,
      "totalParts": 30
    }
  },
  {
    "slug": "30-day-soc-analyst-challenge-part11",
    "title": "Part 11: Brute Force Attacks – Techniques, Tools, and Defense Strategies",
    "description": "Day 11 of the 30-Day MYDFIR SOC Analyst Challenge: Understanding brute force attacks and implementing effective defense strategies.",
    "date": "2024-11-11",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "",
    "solution": "",
    "results": [],
    "category": "blue",
    "tags": [
      "Brute Force",
      "Security Defense",
      "Attack Prevention",
      "SOC",
      "Security Monitoring"
    ],
    "content": "\r\n## Day 11 of the 30-Day MYDFIR SOC Analyst Challenge: Brute Force Attacks – Techniques, Tools, and Defense Strategies\r\n\r\n## What I Learned About Brute Force Attacks\r\n\r\nMYDFIR explained that a brute force attack is essentially trying every password combination until the correct one is found, much like forgetting the combination to a luggage lock. Attackers typically target services like Remote Desktop Protocol (RDP) that are exposed to the internet, making these attacks quite common.\r\n\r\n## Key Types of Brute Force Attacks\r\n\r\nWe focused on three main types of brute force attacks:\r\n\r\nSimple Brute Force Attack: \r\nLike cracking a lock, attackers try various combinations of characters to guess a password.\r\n\r\nDictionary Attack:\r\nThis involves using word lists that contain common passwords or phrases from known credential dumps.\r\n\r\nCredential Stuffing:\r\nAttackers use stolen username-password pairs from previous breaches and test them on various systems to gain access.\r\n\r\n## Defending Against Brute Force Attacks\r\n\r\nMYDFIR taught me three essential ways to defend against brute force attacks:\r\n\r\nLonger Passwords or Passphrases: The longer and more complex a password, the harder it is for an attacker to crack. Tools like password managers can help create and store strong passwords.\r\n\r\nMultifactor Authentication (MFA): Enabling MFA provides an additional layer of security. Even if an attacker guesses my password, they'll need another form of verification, like a code sent via an app.\r\n\r\nAwareness and Vigilance: MYDFIR emphasized the importance of being cautious, especially when receiving suspicious emails or login requests. Signing up for alerts if my email is compromised is also a good practice.\r\n\r\n## Common Brute Force Tools in the Wild\r\n\r\nI was introduced to three popular tools used for brute force attacks:\r\n- Hydra\r\n- Hashcat\r\n- John the Ripper\r\n\r\nThese tools, often found in ethical hacking distributions like Kali Linux, can be used to simulate brute force attacks, but only in a controlled environment where I have permission.\r\n\r\n## Conclusion\r\n\r\nTomorrow, I will set up an SSH server in the cloud, allowing me to observe brute-force attacks in real-time. It's an exciting opportunity to see how these attacks manifest and learn how to detect and stop them.\r\n\r\nHere's the link to follow along: [30-Day MYDFIR SOC Analyst Challenge](https://www.youtube.com/watch?v=eOie0SDMuGA&list=PLG6KGSNK4PuBWmX9NykU0wnWamjxdKhDJ&index=37)\r\n\r\n*Credit: This project was originally created by the MYDFIR YouTube channel. All structure and content was inspired by MYDFIR. Check his channel out: [@MyDFIR](https://www.youtube.com/@MyDFIR)*\r\n\r\n#CyberSecurity #SOCAnalyst #MYDFIRChallenge #HandsOnExperience #Day11 ",
    "image": "/images/projects/30-day-soc-analyst-challenge.png",
    "technologies": [],
    "images": [
      {
        "src": "/images/projects/30-day-challenge/30-days-day-11.png",
        "alt": "30 Days MYDFIR SOC Analyst Challenge Day 11"
      }
    ],
    "series": {
      "name": "Project 3: 30-Day MYDFIR SOC Analyst Challenge",
      "part": 11,
      "totalParts": 30
    }
  },
  {
    "slug": "30-day-soc-analyst-challenge-part10",
    "title": "Part 10: Ingesting Sysmon and Microsoft Defender Logs",
    "description": "Day 10 of the 30-Day MYDFIR SOC Analyst Challenge: Setting up log ingestion from Windows Server to Elasticsearch for enhanced security monitoring.",
    "date": "2024-11-10",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "",
    "solution": "",
    "results": [],
    "category": "blue",
    "tags": [
      "Sysmon",
      "Windows Defender",
      "Log Ingestion",
      "SOC",
      "Security Monitoring"
    ],
    "content": "\r\n## Day 10 of the 30-Day MYDFIR SOC Analyst Challenge: Ingesting Sysmon and Microsoft Defender Logs\r\n\r\nOn Day 10 of the 30-Day MYDFIR SOC Analyst Challenge, I focused on ingesting both Sysmon and Microsoft Defender event logs from the Windows Server into my Elasticsearch instance. This step is crucial for centralizing log data and enhancing my ability to detect and analyze potential security threats.\r\n\r\n## Setting Up Custom Windows Event Log Integrations\r\n\r\nI began by logging into the Elasticsearch instance and navigating to the Integrations page. I searched for and selected the \"Custom Windows Event log\" integration, which allows ingesting events from any Windows Event log channel.\r\n\r\nFor Sysmon, I created an integration named \"my-dfir-win-sysmon\" with the channel name \"Microsoft-Windows-Sysmon/Operational\". For Windows Defender, I set up another integration named \"my-dfir-win-defender\" with the channel \"Microsoft-Windows-Windows Defender/Operational\". In the Defender integration, I specified event IDs 1116, 1117, and 5001 to focus on malware detection and real-time protection status.\r\n\r\n## Troubleshooting Connectivity Issues\r\n\r\nInitially, no logs appeared in Elasticsearch. Upon investigating, I discovered that the Elastic agent on the Windows Server couldn't communicate with the Elasticsearch instance. The solution was to add a firewall rule allowing incoming connections to port 9200 on the Elasticsearch server. After implementing this change and restarting the Elastic agent service, logs began flowing into Elasticsearch.\r\n\r\n## Verifying Log Ingestion\r\n\r\nTo confirm successful log ingestion, I used Elasticsearch's Discover page. I searched for Sysmon events with the query \"winlog.event_id: 1\" and for Windows Defender events with \"winlog.event_id: 5001\". Both queries returned results, confirming that the logs were being correctly ingested and indexed.\r\n\r\n## Conclusion\r\n\r\nWith Sysmon and Microsoft Defender logs now being successfully ingested into Elasticsearch, I have significantly improved my ability to monitor and analyze security events on my Windows Server. This centralized log collection will be instrumental in detecting and investigating potential security incidents in the future.\r\n\r\nIn the next part of this challenge, I'll explore how to effectively query and analyze these logs within Elasticsearch, further enhancing my SOC analysis capabilities.\r\n\r\nHere's the link to follow along: [30-Day MYDFIR SOC Analyst Challenge](https://www.youtube.com/watch?v=eOie0SDMuGA&list=PLG6KGSNK4PuBWmX9NykU0wnWamjxdKhDJ&index=37)\r\n\r\n*Credit: This project was originally created by the MYDFIR YouTube channel. All structure and content was inspired by MYDFIR. Check his channel out: [@MyDFIR](https://www.youtube.com/@MyDFIR)* \r\n\r\n#CyberSecurity #SOCAnalyst #MYDFIRChallenge #HandsOnExperience #Day10\r\n\r\n",
    "image": "/images/projects/30-day-soc-analyst-challenge.png",
    "technologies": [],
    "images": [
      {
        "src": "/images/projects/30-day-challenge/30-days-day-10.png",
        "alt": "30 Days MYDFIR SOC Analyst Challenge Day 10"
      },
      {
        "src": "/images/projects/30-day-challenge/Elasticsearch-Ingest-Data-Image.png",
        "alt": "Elasticsearch Data Ingestion Process"
      }
    ],
    "series": {
      "name": "Project 3: 30-Day MYDFIR SOC Analyst Challenge",
      "part": 10,
      "totalParts": 30
    }
  },
  {
    "slug": "30-day-soc-analyst-challenge-part9",
    "title": "Part 9: Installing and Configuring Sysmon on Windows Server",
    "description": "Day 9 of the 30-Day MYDFIR SOC Analyst Challenge: Setting up Sysmon for enhanced endpoint monitoring and security logging.",
    "date": "2024-11-09",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "",
    "solution": "",
    "results": [],
    "category": "blue",
    "tags": [
      "Sysmon",
      "Windows Server",
      "Endpoint Security",
      "SOC",
      "Security Monitoring"
    ],
    "content": "\r\n## Day 9 of the 30-Day MYDFIR SOC Analyst Challenge: Installing and Configuring Sysmon on Windows Server\r\n\r\nOn Day 9 of the 30-Day MyDFIR SOC Analyst Challenge, I focused on setting up Sysmon on the Windows Server created on Day 5. Sysmon is a powerful tool from Microsoft's Sysinternals suite that enhances endpoint visibility by logging key activities such as process creation, network connections, and more. Here's how I did it.\r\n\r\n## Downloading and Installing Sysmon\r\n\r\nFirst, I connected to the Windows Server via Remote Desktop Protocol (RDP). Once connected, I opened Microsoft Edge and searched for Sysmon on the Microsoft Learn site. I then downloaded the latest version of Sysmon (version 15.15 as of this writing) and extracted the contents to a directory on the server.\r\n\r\nWith the files extracted, I turned my attention to configuring Sysmon. I opted to use Olaf Hartong's popular Sysmon configuration file, which can be found on GitHub. This configuration file is widely used and highly customizable, allowing me to specify which events Sysmon should monitor.\r\n\r\n## Configuring Sysmon\r\n\r\nAfter downloading the configuration file (sysmonconfig.xml), I saved it in the Sysmon directory. I then opened PowerShell as an administrator and navigated to the directory where Sysmon was installed.\r\n\r\nTo install Sysmon with the configuration file, I used the following command in PowerShell:\r\n```\r\nsysmon64.exe -i sysmonconfig.xml\r\n```\r\n\r\nThis command installs Sysmon and applies the configuration file. Once installed, Sysmon immediately begins logging events as per the configuration.\r\n\r\n## Verifying Installation\r\n\r\nTo confirm that Sysmon was successfully installed, I checked both the Windows Services and Event Viewer. Sysmon appeared as a running service in the Services application. In Event Viewer, under Applications and Services Logs > Microsoft > Windows > Sysmon, I verified that Sysmon was actively generating logs, starting with Event ID 3, which logs network connections.\r\n\r\n## Conclusion\r\n\r\nWith Sysmon now installed and logging critical events, the Windows Server is better equipped for monitoring and detecting malicious activities. In the next step of this challenge, I will learn how to push both Sysmon and Microsoft Defender logs to my Elasticsearch instance, enhancing my visibility and analysis capabilities.\r\n\r\nHere's the link to follow along: [30-Day MYDFIR SOC Analyst Challenge](https://www.youtube.com/watch?v=nzZY9OSfkeg&list=PLG6KGSNK4PuBWmX9NykU0wnWamjxdKhDJ&index=36)\r\n\r\n*Credit: This project was originally created by the MYDFIR YouTube channel. All structure and content was inspired by MYDFIR. Check his channel out: [@MyDFIR](https://www.youtube.com/@MyDFIR)* ",
    "image": "/images/projects/30-day-soc-analyst-challenge.png",
    "technologies": [],
    "images": [
      {
        "src": "/images/projects/30-day-challenge/30-days-day-9.png",
        "alt": "30 Days MYDFIR SOC Analyst Challenge Day 9"
      },
      {
        "src": "/images/projects/30-day-challenge/Sysmon-Installation.png",
        "alt": "Sysmon Installation Process"
      }
    ],
    "series": {
      "name": "Project 3: 30-Day MYDFIR SOC Analyst Challenge",
      "part": 9,
      "totalParts": 30
    }
  },
  {
    "slug": "building-cybersecurity-home-lab",
    "title": "Part 1: Setting Up My Virtual Home Lab Environment",
    "description": "Establishing a home lab to gain hands-on experience in cybersecurity.",
    "date": "2024-11-08",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "Create a safe, controlled environment to explore cybersecurity tools and techniques.",
    "solution": "Set up virtual machines, implemented telemetry with Sysmon, and integrated Splunk for log analysis.",
    "results": [
      "Established an isolated cybersecurity lab",
      "Enabled telemetry generation and analysis",
      "Built foundational skills in monitoring and detection"
    ],
    "category": "blue",
    "tags": [
      "Blue Team",
      "Home Lab",
      "SIEM"
    ],
    "content": "\r\n# Part 1: Setting Up My Virtual Home Lab Environment\r\n\r\n## Home Lab Setup\r\n\r\nI embarked on an exciting journey to establish a cybersecurity home lab aimed at creating a controlled environment for hands-on experimentation and skill development.\r\n\r\n### Setting Up Virtual Machines\r\n\r\nTo begin, I chose VirtualBox as my virtualization platform, which allows me to run multiple virtual machines (VMs) for specific tasks. I set up two VMs: one running Parrot Security OS, favored for penetration testing, and another with Windows for defensive security tasks and telemetry generation.\r\n\r\nCreating the virtual machines was straightforward. I allocated sufficient resources, including CPU and RAM, to ensure optimal performance. For Parrot Security OS, I configured the network settings to facilitate communication with the Windows machine. By selecting an Internal Network type, I established a private network between the VMs, isolating my lab from the internet and reducing the risk of exposure during testing.\r\n\r\n### Setting Up Sysmon for Telemetry Generation\r\n\r\nTo enhance telemetry on the Windows machine, I installed Sysmon (System Monitor), a tool that logs detailed system activity. After downloading Sysmon from the Microsoft Sysinternals website, I executed it with a configuration to capture key events, including process creation and network connections. This setup allows effective monitoring and analysis of activities, providing rich telemetry data for examination.\r\n\r\n### Integrating Splunk for Analysis\r\n\r\nNext, I installed Splunk on the Windows VM to analyze the telemetry data generated by Sysmon. Splunk is a powerful platform for searching and analyzing machine-generated data, essential for incident response. After installation, I configured Splunk to ingest the Sysmon logs by setting up a new data input and specifying the log directory. Initial searches confirmed that Splunk was capturing the data correctly.\r\n\r\nWith Sysmon and Splunk operational, my telemetry generation setup was complete, enabling analysis of security events and improving my skills in detecting and responding to potential threats.\r\n\r\n### Testing Connectivity\r\n\r\nAfter the VMs were running, I conducted connectivity tests using basic network commands like PING to ensure effective communication between them. This step confirmed that my network configuration was functioning as intended, allowing seamless data sharing. Establishing this successful connection provided a sense of accomplishment, laying the groundwork for exploring various cybersecurity tools and techniques in a controlled environment.\r\n\r\n## Conclusion\r\n\r\nWith the initial setup complete, I now have a solid foundation for my cybersecurity home lab. This environment will provide hands-on experience and help develop the skills necessary for my future as a SOC analyst. In the next part of this blog, I will explore generating telemetry data and analyzing it to uncover valuable security insights.\r\n\r\nStay Tuned!\r\n\r\nHere's the link to follow along: [Building A Basic Home Lab](https://www.youtube.com/watch?v=5iafC6vj7kM&list=PLG6KGSNK4PuBWmX9NykU0wnWamjxdKhDJ&index=2)\r\n\r\n*Credit: This project was originally created by the MYDFIR YouTube channel. All structure and content was inspired by MYDFIR. Check his channel out: [@MyDFIR](https://www.youtube.com/@MyDFIR)*\r\n\r\n_#CyberSecurity #SOCAnalyst #MYDFIR #HandsOnExperience_\r\n",
    "image": "/images/projects/homelab-coding.jpg",
    "technologies": [
      "VirtualBox",
      "Parrot Security OS",
      "Sysmon",
      "Splunk"
    ],
    "images": [],
    "series": {
      "name": "Project 1: Building a Cybersecurity Home Lab",
      "part": 1,
      "totalParts": 2
    }
  },
  {
    "slug": "30-day-soc-analyst-challenge-part8",
    "title": "Part 8: Sysmon",
    "description": "Day 8 of the 30-Day MYDFIR SOC Analyst Challenge: Enhancing endpoint visibility with Microsoft's System Monitor (Sysmon).",
    "date": "2024-11-08",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "",
    "solution": "",
    "results": [],
    "category": "blue",
    "tags": [
      "Sysmon",
      "Endpoint Monitoring",
      "Windows Security",
      "SOC",
      "Threat Detection"
    ],
    "content": "\r\n## Day 8 of the 30-Day MYDFIR SOC Analyst Challenge: Sysmon\r\n\r\nDay 8 of the 30-day My DFIR SOC Analyst Challenge focuses on improving endpoint visibility using Sysmon (System Monitor). Sysmon is a powerful tool from Microsoft's Sysinternals suite that provides detailed logging capabilities, such as tracking process creation, network connections, and file modifications—critical for effective incident response and threat detection.\r\n\r\n## Understanding Sysmon's Role\r\n\r\nThe default logging settings in Windows are insufficient for capturing vital events like process creations. Sysmon fills this gap, offering extensive telemetry that enhances my ability to detect and investigate malicious activities. With Sysmon, I can track important event IDs, such as:\r\n\r\n## Key Event IDs and Their Significance\r\n\r\nEvent ID 1 (Process Creation): Logs any new processes, along with their command lines, which helps identify suspicious activities. It also records file hashes for further analysis.\r\n\r\nEvent ID 3 (Network Connections): Logs details of network connections made by processes, including source and destination IP addresses, and ports—useful for spotting unusual outbound connections.\r\n\r\nEvent IDs 6, 7, 8 (Driver, Image Load, Create Remote Thread): These event IDs help detect advanced attack techniques, like process injection but can generate noise, so proper filtering is essential.\r\n\r\nEvent ID 10 (Process Access): Monitors potential credential access attempts, especially against critical processes like LSASS (Local Security Authority Subsystem Service), which attackers often target to extract credentials.\r\n\r\nEvent ID 22 (DNS Query): Tracks DNS requests made by endpoints, allowing me to detect suspicious domain lookups, such as those generated by malware using domain generation algorithms (DGA).\r\n\r\n## Configuration Considerations\r\n\r\nWhile Sysmon greatly enhances visibility, it's crucial to fine-tune the configuration to balance logging depth with noise reduction. I'll learn how to install and configure Sysmon in future sessions to optimize my endpoint monitoring capabilities. This step is vital for elevating my skills in threat detection and incident response within a SOC environment.\r\n\r\n## Conclusion\r\n\r\nThe next phase of the challenge will guide me through installing Sysmon with a recommended configuration to start analyzing Sysmon logs and improve my cybersecurity analysis proficiency.\r\n\r\nHere's the link to follow along: [30-Day MYDFIR SOC Analyst Challenge](https://www.youtube.com/watch?v=hpUnKjEFCoU&list=PLG6KGSNK4PuBWmX9NykU0wnWamjxdKhDJ&index=35)\r\n\r\n*Credit: This project was originally created by the MYDFIR YouTube channel. All structure and content was inspired by MYDFIR. Check his channel out: [@MyDFIR](https://www.youtube.com/@MyDFIR)* ",
    "image": "/images/projects/30-day-soc-analyst-challenge.png",
    "technologies": [],
    "images": [
      {
        "src": "/images/projects/30-day-challenge/30-days-day-8.png",
        "alt": "30 Days MYDFIR SOC Analyst Challenge Day 8"
      }
    ],
    "series": {
      "name": "Project 3: 30-Day MYDFIR SOC Analyst Challenge",
      "part": 8,
      "totalParts": 30
    }
  },
  {
    "slug": "30-day-soc-analyst-challenge-part7",
    "title": "Part 7: Installing Elastic Agent and Setting Up Fleet Server",
    "description": "Day 7 of the 30-Day MYDFIR SOC Analyst Challenge: Setting up Elastic Agent and Fleet Server for centralized log management.",
    "date": "2024-11-07",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "",
    "solution": "",
    "results": [],
    "category": "blue",
    "tags": [
      "Elastic Agent",
      "Fleet Server",
      "Log Management",
      "SOC",
      "Security Monitoring"
    ],
    "content": "\r\n## Day 7 of the 30-Day MYDFIR SOC Analyst Challenge: Installing Elastic Agent and Setting Up Fleet Server\r\n\r\nWelcome to Day 7 of the 30-Day My DFIR SOC Analyst Challenge, I took critical steps toward building a robust monitoring system by installing the Elastic Agent on a Windows Server and setting up a Fleet server for centralized management. This process is vital for SOC analysts to efficiently manage logs across multiple endpoints.\r\n\r\n## Deploying the Fleet Server\r\n\r\nI began with deploying an Ubuntu server to act as the Fleet server. This server plays a pivotal role by allowing me to manage multiple Elastic Agents from a single location. By centralizing the management of these agents, I can easily push updates, modify policies, and ensure all endpoints are correctly configured without needing to access each one individually.\r\n\r\n## Setting Up in Kibana\r\n\r\nNext, I moved into Kibana's interface, where I configured the Fleet server. This step involved generating enrollment tokens and policies that would allow the Elastic Agents to communicate securely with the Fleet server and Elasticsearch. In a real-world SOC environment, getting these configurations right is crucial, as they dictate how data flows between my endpoints and my central log management system.\r\n\r\n## Overcoming Connectivity Challenges.\r\n\r\nA key part of this process was troubleshooting connectivity issues. The initial setup ran into problems due to restrictive firewall rules that blocked the necessary communication between the Fleet server and the Elasticsearch instance. Adjusting both the VPC and server-level firewall rules allowed for the proper connections to be established. This scenario underscored the delicate balance I must strike between securing my systems and maintaining operational functionality.\r\n\r\n## Installing the Elastic Agent on Windows Server\r\n\r\nOnce the Fleet server was configured, the next task was to install the Elastic Agent on my Windows Server. This agent is essential for collecting logs and metrics, and forwarding them to my Elasticsearch instance via the Fleet server. During this step, I encountered a few errors related to certificate validation and network connectivity. However, by utilizing the --insecure flag and ensuring the correct firewall ports were open, I successfully enrolled the Windows Server into the Fleet.\r\n\r\n## Conclusion\r\n\r\nDay 7 was all about setting up the infrastructure needed for effective log management. By successfully installing the Elastic Agent and configuring a Fleet server, I laid the groundwork for a scalable, manageable, and secure logging environment. In the next session, I'll dive deeper into system activity monitoring by installing Sysmon on my Windows Server, further enhancing my ability to detect and respond to threats.\r\n\r\nHere's the link to follow along: [30-Day MYDFIR SOC Analyst Challenge](https://www.youtube.com/watch?v=P2SFC6Kwae0&list=PLG6KGSNK4PuBWmX9NykU0wnWamjxdKhDJ&index=34)\r\n\r\n*Credit: This project was originally created by the MYDFIR YouTube channel. All structure and content was inspired by MYDFIR. Check his channel out: [@MyDFIR](https://www.youtube.com/@MyDFIR)* ",
    "image": "/images/projects/30-day-soc-analyst-challenge.png",
    "technologies": [],
    "images": [
      {
        "src": "/images/projects/30-day-challenge/30-days-day-7.png",
        "alt": "30 Days MYDFIR SOC Analyst Challenge Day 7"
      },
      {
        "src": "/images/projects/30-day-challenge/Elastic-agent-Installation-on-fleet-server.png",
        "alt": "Elastic Agent Installation on Fleet Server"
      },
      {
        "src": "/images/projects/30-day-challenge/Elastic-agent-installation-on-windows-server.png",
        "alt": "Elastic Agent Installation on Windows Server"
      },
      {
        "src": "/images/projects/30-day-challenge/Fleet-Installed-Image-on-elastic-gui.png",
        "alt": "Fleet Installation on Elastic GUI"
      },
      {
        "src": "/images/projects/30-day-challenge/Logs-Captured-from-Elastic-GUI.png",
        "alt": "Logs Captured from Elastic GUI"
      }
    ],
    "series": {
      "name": "Project 3: 30-Day MYDFIR SOC Analyst Challenge",
      "part": 7,
      "totalParts": 30
    }
  },
  {
    "slug": "30-day-soc-analyst-challenge-part6",
    "title": "Part 6: Centralized Management with Fleet Server and Elastic Agent",
    "description": "Day 6 of the 30-Day MYDFIR SOC Analyst Challenge: Exploring centralized management solutions for security agents across multiple endpoints.",
    "date": "2024-11-06",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "",
    "solution": "",
    "results": [],
    "category": "blue",
    "tags": [
      "Fleet Server",
      "Elastic Agent",
      "Centralized Management",
      "SOC",
      "Security Monitoring"
    ],
    "content": "\r\n## Day 6 of the 30-Day MYDFIR SOC Analyst Challenge: Centralized Management with Fleet Server and Elastic Agent\r\n\r\nOn Day 6 of the 30-Day My Def for SOC Analyst Challenge, I explored the importance of centralized management for security agents across multiple endpoints. Imagine the hassle of manually configuring 100 machines. This is where Fleet Server and Elastic Agent come into play, making life much easier for a SOC analyst.\r\n\r\n## Understanding Elastic Agent\r\n\r\nThe Elastic Agent is a key component in my setup, allowing me to monitor logs, metrics, and various types of data from different endpoints. It simplifies what used to be a complex process by acting as a single unified agent that can manage multiple data types. With Elastic Agent, I no longer have to deploy numerous Beats (specialized agents) on a single host. Instead, the Elastic Agent can handle it all, whether it's logs from applications, system metrics, or even security-related data.\r\n\r\nThis agent can be installed in two modes: Standalone or Fleet-managed. For this challenge, I'm focusing on Fleet-managed mode because it allows centralized management. This will enable me to push updates, manage configurations, and control all my agents from one place.\r\n\r\n## Fleet Server: Centralized Control\r\n\r\nThe Fleet Server acts as the central hub where I manage all the Elastic Agents. This is crucial because it lets me update policies, add integrations, and adjust configurations from one place. Without it, I'd be stuck making changes manually on each endpoint, which is impractical and error-prone.\r\n\r\nFor instance, if I want to configure my agents to collect PowerShell logs, I can push that update through the Fleet Server instead of manually touching each machine. Similarly, if I want to change where my logs are being sent—whether to ElasticSearch or Logstash—I can do that centrally through Fleet. This flexibility is invaluable for managing a large environment.\r\n\r\n## Elastic Agent vs. Beats\r\n\r\nBeats are specialized agents that collect specific data types, like Filebeat for log files or Metricbeat for metrics. While Beats are great for specific tasks, the Elastic Agent consolidates all these capabilities into a single package, making it more versatile and easier to manage.\r\n\r\nChoosing between Beats and Elastic Agent depends on the specific needs of my environment. However, Elastic Agent often provides a more streamlined approach, especially when managing multiple data types across numerous endpoints.\r\n\r\n## Conclusion\r\n\r\nConcluding Day 6, I had a solid understanding of how to use Fleet Server and Elastic Agent to simplify and centralize my SOC environment's management. In the next session, I'll dive deeper into setting up Elastic Agent and configuring Fleet Server, ensuring all my endpoints are ready for centralized management.\r\n\r\nHere's the link to follow along: [30-Day MYDFIR SOC Analyst Challenge](https://www.youtube.com/watch?v=0WklP6ZsP1g&list=PLG6KGSNK4PuBWmX9NykU0wnWamjxdKhDJ&index=33)\r\n\r\n*Credit: This project was originally created by the MYDFIR YouTube channel. All structure and content was inspired by MYDFIR. Check his channel out: [@MyDFIR](https://www.youtube.com/@MyDFIR)* ",
    "image": "/images/projects/30-day-soc-analyst-challenge.png",
    "technologies": [],
    "images": [
      {
        "src": "/images/projects/30-day-challenge/30-days-day-6.png",
        "alt": "30 Days MYDFIR SOC Analyst Challenge Day 6"
      }
    ],
    "series": {
      "name": "Project 3: 30-Day MYDFIR SOC Analyst Challenge",
      "part": 6,
      "totalParts": 30
    }
  },
  {
    "slug": "30-day-soc-analyst-challenge-part5",
    "title": "Part 5: Deploying Windows Server in the Cloud",
    "description": "Day 5 of the 30-Day MYDFIR SOC Analyst Challenge: Setting up a Windows Server instance in the cloud for security analysis.",
    "date": "2024-11-05",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "",
    "solution": "",
    "results": [],
    "category": "blue",
    "tags": [
      "Windows Server",
      "Cloud Security",
      "Network Architecture",
      "SOC",
      "Security Analysis"
    ],
    "content": "\r\n## Day 5 of the 30-Day MYDFIR SOC Analyst Challenge: Deploying Windows Server in the Cloud.\r\n\r\nDay 5 of the challenge focused on deploying a Windows Server instance in the cloud, with a particular emphasis on network security and architecture decisions. This setup would serve as a target machine for generating security logs and analyzing potential threats.\r\n\r\n## Initial Setup and Network Architecture\r\n\r\nI began by logging into my Vultr account and preparing to set up a new Windows Server instance. The first crucial decision involved determining whether to include this server in our previously configured Virtual Private Cloud (VPC). Our instructor provided valuable insights into network architecture, highlighting the importance of network segmentation and security.\r\n\r\n## Security Considerations\r\n\r\nThe core concept we explored was network isolation and its role in security. By keeping the Windows Server separate from the VPC, we could better protect our internal network from potential threats. This isolation is particularly crucial because internet exposure increases the server's risk profile, and separation prevents lateral movement in case of compromise. It effectively reduces the overall attack surface and provides better damage control in case of a breach.\r\n\r\n## Deployment Configuration\r\n\r\nWith these security considerations in mind, I proceeded with the deployment. I deployed the server outside the VPC, configuring it without private IP address space connection. The server was set up with public IP access only, and I accessed it through Vultr's console. This configuration aligned with our security-first approach to the deployment.\r\n\r\n## Remote Access Setup\r\n\r\nThe next critical step was configuring Remote Desktop Protocol (RDP) access. I exposed RDP to the internet for remote management, fully acknowledging the increased attack surface this would create. This setup was intentional, as it would allow the server to generate security logs from various access attempts. After configuration, I verified that RDP functionality was working as expected.\r\n\r\n## Next Steps\r\n\r\nThe server is now operational and will begin accumulating logs from various access attempts. These logs will be crucial for analyzing unauthorized access attempts, identifying potential threats, and developing security monitoring strategies. This data will form the foundation for our future analysis exercises.\r\n\r\n## Conclusion\r\n\r\nThis day's work established a crucial component of our security lab - a Windows Server instance that will generate real-world security logs. The careful consideration of network architecture and security implications provided valuable insights into enterprise security practices. In the next session, I'll be configuring a Fleet Server to enhance our lab's endpoint management capabilities.\r\n\r\nHere's the link to follow along: [30-Day MYDFIR SOC Analyst Challenge](https://www.youtube.com/watch?v=nBlCuLMq-zA&list=PLG6KGSNK4PuBWmX9NykU0wnWamjxdKhDJ&index=32)\r\n\r\n*Credit: This project was originally created by the MYDFIR YouTube channel. All structure and content was inspired by MYDFIR. Check his channel out: [@MyDFIR](https://www.youtube.com/@MyDFIR)* ",
    "image": "/images/projects/30-day-soc-analyst-challenge.png",
    "technologies": [],
    "images": [
      {
        "src": "/images/projects/30-day-challenge/Windows-server-image.png",
        "alt": "Windows Server Deployment"
      },
      {
        "src": "/images/projects/30-day-challenge/30-days-day-5.png",
        "alt": "30 Days MYDFIR SOC Analyst Challenge Day 5"
      }
    ],
    "series": {
      "name": "Project 3: 30-Day MYDFIR SOC Analyst Challenge",
      "part": 5,
      "totalParts": 30
    }
  },
  {
    "slug": "30-day-soc-analyst-challenge-part4",
    "title": "Part 4: Setting Up Kibana",
    "description": "Day 4 of the 30-Day MYDFIR SOC Analyst Challenge: Setting up Kibana for powerful data visualization and analysis.",
    "date": "2024-11-04",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "",
    "solution": "",
    "results": [],
    "category": "blue",
    "tags": [
      "Kibana",
      "Visualization",
      "Elastic Stack",
      "SOC",
      "Security Analysis"
    ],
    "content": "\r\n# Day 4 of the 30-Day MYDFIR SOC Analyst Challenge: Setting Up Kibana\r\n\r\n## Overview\r\n\r\nToday's focus was on setting up Kibana, a powerful data visualization tool. So I started by downloading Kibana from Elastic's website and installing it on my server. Once installed, I dove into configuring Kibana to ensure it was accessible from any device, not just the local host. This required updating the kibana.yml configuration file and replacing the default localhost setting with my server's public IP.\r\n\r\n## Service Configuration\r\n\r\nAfter configuration, I needed to ensure Kibana would start automatically whenever my server rebooted. This involved enabling and starting the Kibana service. Once everything was running, I verified the service status to confirm that it was active.\r\n\r\n## Secure Connection to Elasticsearch\r\n\r\nNext, I generated an Elasticsearch enrollment token, a crucial step for securely connecting Kibana to Elasticsearch. This token was stored safely for later use.\r\n\r\n## Troubleshooting Access\r\n\r\nWhile attempting to access Kibana through my browser, I encountered a connection timeout error. This led me to adjust my firewall settings both on Vultr, my cloud provider and on the Ubuntu server itself. Once these adjustments were made, I successfully accessed the Kibana web interface.\r\n\r\n## Security Settings and Final Steps\r\n\r\nInside Kibana, I proceeded to configure security settings, adding encryption keys for saved objects to ensure data integrity and security. With everything set up and running smoothly, Kibana was fully operational, marking a successful completion of Day 4.\r\n\r\n## Conclusion\r\n\r\nThis day was essential in setting up the foundation for future data analysis. Kibana is the gateway to visualizing and interacting with data stored in Elasticsearch, making it an indispensable tool for any SOC analyst. Next, I'll be focusing on setting up a Windows server to act as a target machine for further exploration.\r\n\r\nHere's the link to follow along: [30-Day MYDFIR SOC Analyst Challenge](https://www.youtube.com/watch?v=nBlCuLMq-zA&list=PLG6KGSNK4PuBWmX9NykU0wnWamjxdKhDJ&index=32)\r\n\r\n*Credit: This project was originally created by the MYDFIR YouTube channel. All structure and content was inspired by MYDFIR. Check his channel out: [@MyDFIR](https://www.youtube.com/@MyDFIR)*\r\n\r\n#CyberSecurity #SOCAnalyst #MYDFIRChallenge #HandsOnExperience #Day4 ",
    "image": "/images/projects/30-day-soc-analyst-challenge.png",
    "technologies": [],
    "images": [
      {
        "src": "/images/projects/30-day-challenge/Kibana-Interface.png",
        "alt": "Kibana Interface"
      },
      {
        "src": "/images/projects/30-day-challenge/30-Days-Day-4.png",
        "alt": "30 Days MYDFIR SOC Analyst Challenge Day 4"
      }
    ],
    "series": {
      "name": "Project 3: 30-Day MYDFIR SOC Analyst Challenge",
      "part": 4,
      "totalParts": 30
    }
  },
  {
    "slug": "30-day-soc-analyst-challenge-part3",
    "title": "Part 3: Setting up Elastic Search",
    "description": "Day 3 of the 30-Day MYDFIR SOC Analyst Challenge: Setting up your own Elastic Search instance for foundational security analysis.",
    "date": "2024-11-03",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "",
    "solution": "",
    "results": [],
    "category": "blue",
    "tags": [
      "Elastic Search",
      "Vultr",
      "Cloud",
      "SOC",
      "Security Analysis"
    ],
    "content": "\r\n# Day 3 of the 30-Day MYDFIR SOC Analyst Challenge: Setting up Elastic Search\r\n\r\n## Overview\r\n\r\nThe focus for today was on setting up my own Elastic Search instance, following practical steps to build a foundational environment for security analysis.\r\n\r\n## Cloud Environment Setup\r\n\r\nFirst, I signed up on Vultr, a cloud service provider, which was used to create a Virtual Private Cloud (VPC) network. To avoid connectivity issues, I ensured that all resources, including virtual machines (VMs), were in the same location as my VPC. For instance, I created the VPC in Manchester, so I deployed my VM in the same region.\r\n\r\nAfter configuring my VPC, I deployed a server on Vultr with Ubuntu as the operating system. The server had 4 virtual CPUs and 16 GB of RAM to run Elastic Search. I opted out of unnecessary features like auto-backups and IPv6, keeping the setup streamlined, I then associated the VM with my VPC network to ensure it could communicate internally.\r\n\r\n## Elastic Search Installation\r\n\r\nNext, I accessed the server via SSH, using PowerShell to connect to my VM through its public IP address. Inside the VM, I updated the repositories and installed Elastic Search. During the installation, I was provided with critical security information, including a password for the built-in superuser account. I stored this information securely for future reference.\r\n\r\n## Security Configuration\r\n\r\nOne essential step was configuring Elastic Search to be accessible beyond the local host. By modifying the network settings in the elasticsearch.yml configuration file, I allowed remote access from my SOC analyst laptop, making sure it was securely configured.\r\n\r\nTo tighten security, I created a firewall group in Vultr, limiting access to only trusted IP addresses, in this case, I gave access to my IP alone. This ensured that only authorized connections could reach the Elastic Search instance.\r\n\r\n## Final Steps\r\n\r\nFinally, I started the Elastic Search service and confirmed it was running smoothly. This marked the completion of setting up the Elastic Search instance, laying the groundwork for the next step—configuring Kibana, the visualization tool for Elastic Search.\r\n\r\nHere's the link to follow along: [30-Day MYDFIR SOC Analyst Challenge](https://www.youtube.com/watch?v=ypXARA5Uk4I&list=PLG6KGSNK4PuBWmX9NykU0wnWamjxdKhDJ&index=30)\r\n\r\n*Credit: This project was originally created by the MYDFIR YouTube channel. All structure and content was inspired by MYDFIR. Check his channel out: [@MyDFIR](https://www.youtube.com/@MyDFIR)*\r\n\r\n#CyberSecurity #SOCAnalyst #MYDFIRChallenge #HandsOnExperience #Day3 ",
    "image": "/images/projects/30-day-soc-analyst-challenge.png",
    "technologies": [],
    "images": [
      {
        "src": "/images/projects/30-day-challenge/30-days-day-3.png",
        "alt": "30 Days MYDFIR SOC Analyst Challenge Day 3"
      },
      {
        "src": "/images/projects/30-day-challenge/Elasticsearch-Installation.png",
        "alt": "Elasticsearch Installation"
      }
    ],
    "series": {
      "name": "Project 3: 30-Day MYDFIR SOC Analyst Challenge",
      "part": 3,
      "totalParts": 30
    }
  },
  {
    "slug": "30-day-soc-analyst-challenge-part2",
    "title": "Part 2: Diving into the ELK Stack",
    "description": "Explore the powerful ELK stack—Elasticsearch, Logstash, and Kibana—and understand their crucial roles in security operations and log management.",
    "date": "2024-11-02",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "",
    "solution": "",
    "results": [],
    "category": "blue",
    "tags": [
      "ELK Stack",
      "Elasticsearch",
      "Logstash",
      "Kibana",
      "Log Management"
    ],
    "content": "\r\n## Introduction\r\n\r\nOn Day 2 of the 30-Days MYDFIR SOC Analyst Challenge, I delved into the ELK stack, a powerful trio of tools—Elasticsearch, Logstash, and Kibana—widely used in security operations. Together, they form the backbone of log management and analysis, crucial for any Security Operations Center (SOC).\r\n\r\n## Understanding Elasticsearch\r\n\r\nElasticsearch is the heart of the stack. It's a robust search engine that stores and indexes massive amounts of log data. This data can range from Windows event logs to firewall logs and beyond. What makes Elasticsearch particularly valuable is its querying power. It uses Elasticsearch Query Language (ESQL), which allows users to search through large datasets quickly and efficiently. The flexibility of Elasticsearch, especially with its RESTful APIs and JSON support, means you can programmatically interact with it from other tools, enhancing its integration into diverse environments.\r\n\r\n## The Power of Logstash\r\n\r\nNext is Logstash, the powerhouse that processes and transforms incoming data before feeding it into Elasticsearch. Logstash is vital because it allows you to refine your log data, filtering out unnecessary information and only retaining what's critical. This reduces the load on Elasticsearch and helps you manage storage costs more effectively. Additionally, Logstash's ability to parse log fields is a game-changer. For example, you can extract specific details from logs, such as IP addresses, and map them to fields that can be easily queried later. This capability is crucial for security analysts who need to drill down into specific events during investigations.\r\n\r\n## Visualizing with Kibana\r\n\r\nFinally, Kibana is the interface where all the magic happens. It provides a user-friendly web console for querying data stored in Elasticsearch. Beyond simple querying, Kibana's visualization tools enable the creation of detailed dashboards that can display trends, alert patterns, and more. These dashboards are not only useful for real-time monitoring but also for reporting to executives, who often rely on visual data to understand security posture.\r\n\r\n## Conclusion\r\n\r\nThe ELK stack offers centralized logging, customizable data processing, and scalable architecture, making it an essential tool for SOC analysts. Its integration with various telemetry sources and the ability to create visualizations make it a powerful platform for both real-time monitoring and incident response.\r\n\r\nHere's the link to follow along: [30-Day MYDFIR SOC Analyst Challenge](https://www.youtube.com/watch?v=4AwBhXAW90Q&list=PLG6KGSNK4PuBWmX9NykU0wnWamjxdKhDJ&index=29)\r\n\r\n*Credit: This project was originally created by the MYDFIR YouTube channel. All structure and content was inspired by MYDFIR. Check his channel out: [@MyDFIR](https://www.youtube.com/@MyDFIR)*\r\n\r\n#CyberSecurity #SOCAnalyst #MYDFIRChallenge #HandsOnExperience #Day2 ",
    "image": "/images/projects/30-day-soc-analyst-challenge.png",
    "technologies": [],
    "images": [
      {
        "src": "/images/projects/30-day-challenge/Day-2-mydfir-soc-analyst-challenge.png",
        "alt": "Day 2 MYDFIR SOC Analyst Challenge"
      }
    ],
    "series": {
      "name": "Project 3: 30-Day MYDFIR SOC Analyst Challenge",
      "part": 2,
      "totalParts": 30
    }
  },
  {
    "slug": "30-day-soc-analyst-challenge-part1",
    "title": "Part 1: Foundation, A Logical Network Diagram",
    "description": "Learn how to create a comprehensive logical network diagram for your SOC environment, establishing the foundation for my 30-day security monitoring journey.",
    "date": "2024-11-01",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "",
    "solution": "",
    "results": [],
    "category": "blue",
    "tags": [
      "Network Diagram",
      "SOC",
      "Architecture",
      "Documentation"
    ],
    "content": "\r\n## Introduction\r\n\r\nToday marks the beginning of my hands-on journey in the 30-Day MYDFIR SOC Analyst Challenge. I'm starting with the most fundamental aspect: creating a logical network diagram that will serve as the blueprint for my entire SOC environment.\r\n\r\n\r\n\r\n## Environment Overview\r\n\r\nAt the heart of my SOC environment lies a carefully planned infrastructure consisting of six key servers. The core components include my Elastic Server for comprehensive log aggregation and analysis, paired with a Kibana Server that handles visualization and dashboard creation. To manage my agents effectively, I've incorporated a Fleet Server into the design. Additionally, a C2 Server has been included to facilitate realistic attack scenario simulations, alongside other supporting infrastructure components that complete my robust environment.\r\n\r\n## Implementation Details\r\n\r\nThe implementation process began with draw.io as my diagramming tool of choice. Through careful consideration, I mapped out the complete environment with attention to detail. The process involved strategic placement of each server component within the network topology, ensuring optimal communication paths. I dedicated significant attention to configuring the private network structure and establishing clear data flow connections between components. Special consideration was given to defining security zones and boundaries, ensuring a secure and well-organized infrastructure.\r\n\r\n## Key Insights\r\n\r\nThrough the process of creating this network diagram, I've gained valuable insights into the practical aspects of SOC architecture. Understanding how components interact within a security operations environment has proven crucial, as this setup mirrors real-world scenarios. The exercise has deepened my understanding of data flow patterns and the importance of comprehensive security monitoring coverage. This foundation will prove invaluable as I progress through the challenge.\r\n\r\n## Future Direction\r\n\r\nWhile this network diagram may appear straightforward, it represents the cornerstone of my 30-day journey. This blueprint will guide me through the configuration of monitoring tools, implementation of log forwarding mechanisms, and setup of alert management systems. As I progress, I'll use this foundation to simulate and detect security threats, turning theoretical knowledge into practical experience.\r\n\r\nHere's the link to follow along: [30-Day MYDFIR SOC Analyst Challenge](https://www.youtube.com/watch?v=VAE3aVZi0Go&list=PLG6KGSNK4PuBWmX9NykU0wnWamjxdKhDJ&index=28)\r\n\r\n*Credit: This project was originally created by the MYDFIR YouTube channel. All structure and content was inspired by MYDFIR. Check his channel out: [@MyDFIR](https://www.youtube.com/@MyDFIR)* \r\n\r\n#CyberSecurity #SOCAnalyst #MYDFIRChallenge #HandsOnExperience #MYDFIRChallenge #Day1 \r\n\r\n",
    "image": "/images/projects/30-day-soc-analyst-challenge.png",
    "technologies": [],
    "images": [
      {
        "src": "/images/projects/30-day-challenge/1-30Days-MYDFIR-Day-1.png",
        "alt": "30 Days MYDFIR Challenge Day 1"
      },
      {
        "src": "/images/projects/30-day-challenge/2-Day-1-work-with-draw-io.png",
        "alt": "Working with Draw.io on Day 1"
      }
    ],
    "series": {
      "name": "Project 3: 30-Day MYDFIR SOC Analyst Challenge",
      "part": 1,
      "totalParts": 30
    }
  },
  {
    "slug": "30-day-mydfir-soc-analyst-challenge-part0",
    "title": "Introduction to the MYDFIR SOC Analyst Challenge",
    "description": "An introduction to the comprehensive 30-day challenge for aspiring SOC analysts.",
    "date": "2024-10-31",
    "author": "Samson Otori",
    "client": "Personal Project",
    "challenge": "",
    "solution": "",
    "results": [],
    "category": "blue",
    "tags": [
      "Blue Team",
      "SOC",
      "Security Monitoring",
      "Training"
    ],
    "content": "\r\n# Introduction to the 30-Days MYDFIR SOC Analyst Challenge\r\n\r\nI'm thrilled to announce that I'll be taking on the 30-Days MYDFIR SOC Analyst Challenge! If you're like me, eager to gain hands-on experience in cybersecurity, this challenge is a perfect opportunity.\r\n\r\nOver the next 30 days, I'll be learning how to set up and configure the ELK Stack, investigate security incidents, and create dashboards and alerts. Each week focuses on a specific skill, from brute force attack detection to setting up a C2 server.\r\n\r\nThis challenge is all about turning theory into practice, and by the end, I'll have honed the skills that are crucial for a SOC analyst role. I'll be sharing my progress and insights along the way, so stay tuned for updates.\r\n\r\nJoin me on this journey as I aim to strengthen my skills and prepare for the real-world demands of cybersecurity. Let's get started!\r\n\r\nHere's the link to follow along: [30-Day MYDFIR SOC Analyst Challenge](https://www.youtube.com/watch?v=W3ExS2m6B24)\r\n\r\n*Credit: This project was originally created by the MYDFIR YouTube channel. All structure and content was inspired by MYDFIR. Check his channel out: [@MyDFIR](https://www.youtube.com/@MyDFIR)*\r\n\r\n#Cybersecurity #SOCAnalyst #30DayChallenge #PracticalExperience ",
    "image": "/images/projects/30-day-soc-analyst-challenge.png",
    "technologies": [
      "ELK Stack",
      "SIEM",
      "Security Tools",
      "Monitoring"
    ],
    "images": [
      {
        "src": "/images/projects/30-day-challenge/30Days-MYDFIR-Challenge.png",
        "alt": "30 Days MYDFIR SOC Analyst Challenge Overview"
      }
    ],
    "series": {
      "name": "Project 3: 30-Day MYDFIR SOC Analyst Challenge",
      "part": 0,
      "totalParts": 30
    }
  }
]